{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get reg_df\n",
      "get reg_df\n",
      "get Y\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   n 0\n",
      "new score = 9.74\n",
      "0 / 23 = 0.0% complete, elapsed = 0.0 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   n 1\n",
      "new score = 8.93\n",
      "old score = 9.74\n",
      "replacing\n",
      "0 / 22 = 0.0% complete, elapsed = 0.0 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   n 2\n",
      "new score = 9.96\n",
      "old score = 8.93\n",
      "keeping\n",
      "0 / 21 = 0.0% complete, elapsed = 0.0 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   n 3\n",
      "new score = 9.4\n",
      "old score = 8.93\n",
      "keeping\n",
      "0 / 20 = 0.0% complete, elapsed = 0.1 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   t 0\n",
      "new score = 11.69\n",
      "0 / 19 = 0.0% complete, elapsed = 0.1 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   t 1\n",
      "new score = 10.75\n",
      "old score = 11.69\n",
      "replacing\n",
      "0 / 18 = 0.0% complete, elapsed = 0.1 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   t 2\n",
      "new score = 6.4\n",
      "old score = 10.75\n",
      "replacing\n",
      "0 / 17 = 0.0% complete, elapsed = 0.1 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   t 3\n",
      "new score = 6.41\n",
      "old score = 6.4\n",
      "keeping\n",
      "0 / 16 = 0.0% complete, elapsed = 0.1 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   r 0\n",
      "new score = 4.72\n",
      "0 / 15 = 0.0% complete, elapsed = 0.1 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   r 1\n",
      "new score = 13.21\n",
      "old score = 4.72\n",
      "keeping\n",
      "0 / 14 = 0.0% complete, elapsed = 0.2 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   r 2\n",
      "new score = 20.37\n",
      "old score = 4.72\n",
      "keeping\n",
      "0 / 13 = 0.0% complete, elapsed = 0.2 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "_total   r 3\n",
      "new score = 9.42\n",
      "old score = 4.72\n",
      "keeping\n",
      "0 / 12 = 0.0% complete, elapsed = 0.2 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 n 0\n",
      "new score = 15.16\n",
      "0 / 11 = 0.0% complete, elapsed = 0.2 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 n 1\n",
      "new score = 17.21\n",
      "old score = 15.16\n",
      "keeping\n",
      "0 / 10 = 0.0% complete, elapsed = 0.2 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 n 2\n",
      "new score = 14.69\n",
      "old score = 15.16\n",
      "replacing\n",
      "0 / 9 = 0.0% complete, elapsed = 0.2 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 n 3\n",
      "new score = 13.47\n",
      "old score = 14.69\n",
      "replacing\n",
      "0 / 8 = 0.0% complete, elapsed = 0.3 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 t 0\n",
      "new score = 90.0\n",
      "0 / 7 = 0.0% complete, elapsed = 0.3 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 t 1\n",
      "new score = 87.3\n",
      "old score = 90.0\n",
      "replacing\n",
      "0 / 6 = 0.0% complete, elapsed = 0.3 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 t 2\n",
      "new score = 100.0\n",
      "old score = 87.3\n",
      "keeping\n",
      "0 / 5 = 0.0% complete, elapsed = 0.3 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 t 3\n",
      "new score = 46.67\n",
      "old score = 87.3\n",
      "replacing\n",
      "0 / 4 = 0.0% complete, elapsed = 0.3 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 r 0\n",
      "new score = 100.0\n",
      "0 / 3 = 0.0% complete, elapsed = 0.3 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 r 1\n",
      "new score = 100.0\n",
      "old score = 100.0\n",
      "keeping\n",
      "0 / 2 = 0.0% complete, elapsed = 0.4 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 r 2\n",
      "new score = 100.0\n",
      "old score = 100.0\n",
      "keeping\n",
      "0 / 1 = 0.0% complete, elapsed = 0.4 min, remaining = 0 min @ 0 min per model\n",
      "\n",
      "========================================================================================================\n",
      "\n",
      "engl1301 r 3\n",
      "new score = 100.0\n",
      "old score = 100.0\n",
      "keeping\n",
      "0 / 0 = 100% complete, elapsed = 0.4 min, remaining = 0 min @ 0 min per model\n"
     ]
    }
   ],
   "source": [
    "# fix multiindex problem for 202406 flags\n",
    "from LiveAMP import *\n",
    "# FLAGS().run()\n",
    "# df = FLAGS().combine()\n",
    "self = AMP(**kwargs)\n",
    "self.preprocess()\n",
    "self.main()#styp_codes='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input must be a DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m I \u001b[38;5;241m=\u001b[39m X[[]]\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mprep_number()\u001b[38;5;241m.\u001b[39mprep_string()\n\u001b[1;32m      3\u001b[0m I\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# pd.MultiIndex.from_frame(X[[]].reset_index().prep_number().prep_string())\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# df.prep()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.11/lib/python3.11/site-packages/pandas/core/indexes/multi.py:750\u001b[0m, in \u001b[0;36mMultiIndex.from_frame\u001b[0;34m(cls, df, sortorder, names)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03mMake a MultiIndex from a DataFrame.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m           names=['state', 'observation'])\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, ABCDataFrame):\n\u001b[0;32m--> 750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    752\u001b[0m column_names, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mdf\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    753\u001b[0m names \u001b[38;5;241m=\u001b[39m column_names \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m names\n",
      "\u001b[0;31mTypeError\u001b[0m: Input must be a DataFrame"
     ]
    }
   ],
   "source": [
    "X = pd.read_parquet('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/flags/sheet/202406/flg_202406_2023-08-07.parq')\n",
    "I = X[[]].reset_index().prep_number().prep_string()\n",
    "I\n",
    "pd.MultiIndex.from_frame(I)\n",
    "\n",
    "# pd.MultiIndex.from_frame(X[[]].reset_index().prep_number().prep_string())\n",
    "# df.prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = df['hs_gpa']#.astype('string')\n",
    "pd.api.types.is_string_dtype(ser)\n",
    "pd.api.types.is_object_dtype(ser)\n",
    "ser.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd_ext\n",
    "def prep_number(ser, dtype_backend='numpy_nullable'):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    if pd.api.types.is_string_dtype(ser) or pd.api.types.is_object_dtype(ser):\n",
    "        ser = ser.astype('string')\n",
    "        try:\n",
    "            ser = pd.to_datetime(ser)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                ser = pd.to_numeric(ser, downcast='integer')\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return ser.astype('Int64') if pd.api.types.is_integer_dtype(ser) else ser.convert_dtypes(dtype_backend)\n",
    "\n",
    "@pd_ext\n",
    "def prep_string(ser, cap=\"casefold\"):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    ser = ser.prep_number()\n",
    "    return getattr(ser.str, cap)().replace('',pd.NA) if pd.api.types.is_string_dtype(ser) else ser\n",
    "\n",
    "@pd_ext\n",
    "def prep_category(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    ser = ser.prep_string()\n",
    "    return ser.astype('category') if pd.api.types.is_string_dtype(ser) else ser\n",
    "\n",
    "@pd_ext\n",
    "def prep_bool(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    ser = ser.prep_string()\n",
    "    vals = ser.dropna().unique()\n",
    "    if len(vals) in [1, 2]:\n",
    "        vals = set(vals)\n",
    "        for s in [['false','true'], ['n','y'], [0, 1]]:\n",
    "            if vals.issubset(s):\n",
    "                ser = (ser == s[1]).astype('boolean').fillna(False)\n",
    "    return ser\n",
    "\n",
    "@pd_ext\n",
    "def prep(X, cap='casefold'):\n",
    "    if isinstance(X, str):\n",
    "        if cap:\n",
    "            X = getattr(X, cap)()\n",
    "        return X.strip()\n",
    "    elif isinstance(X, (list, tuple, set, np.ndarray, pd.Index)):\n",
    "        return type(X)((prep(x, cap) for x in X))\n",
    "    elif isinstance(X, dict):\n",
    "        return {prep(k,cap):prep(v,cap) for k,v in X.items()}\n",
    "    elif isinstance(X, pd.DataFrame):\n",
    "        g = lambda x: prep(x, cap).replace(' ','_').replace('-','_') if isinstance(x, str) else x\n",
    "        X = X.rename(columns=g).rename_axis(index=g)\n",
    "        idx = pd.MultiIndex.from_frame(X[[]].reset_index().prep_number().prep_string())\n",
    "        return X.prep_number().prep_string().set_index(idx).rename_axis(X.index.names)\n",
    "    elif isinstance(X, pd.Series):\n",
    "        assert 1==2\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "X = df.prep()\n",
    "\n",
    "# write(dst, pd.concat(L).prep())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>current_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camp_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camp_desc</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_name</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mi</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pref_fname</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street1</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary_phone</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_em_all</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dob</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>styp_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>styp_desc</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_code</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_source</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admt_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admt_desc</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majr_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majr_desc</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_name</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_code</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mou_hs</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_grad_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_pctl</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_rank</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonrank_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftic_gap_score</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_gap_score</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_class_size</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_gpa</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_gpa_scale</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_coll/univ_attended</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfer_hours</th>\n",
       "      <td>Float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_hours</th>\n",
       "      <td>Float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_gpa</th>\n",
       "      <td>Float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3p_flag</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orientation_hold_exists</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsi_holds_exist</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u7_tsi_hold_exists</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u7_from_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u4_tsi_hold_exists</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u4_from_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_holds_flag</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_holds</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_holds</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_holds</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacmen_hold_exists</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immu_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immu_code.1</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imst_desc</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imst_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immu_date</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiver_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiver_desc</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts_q1</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts_q2</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts_q3</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h2</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h4</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h5</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h6</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ht</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apst_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apst_desc</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apdc_code</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apdc_desc</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apdc_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_new_comp_score</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat10_total_score</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college_ready</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writing</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reading</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnic_category</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_ethnicity_tf</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_ethnicity_desc_tf</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legacy</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssb_last_accessed</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report_run_dte</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uf_resd_aff_hold_exists</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uf_from_date</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schlship_app</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gobintl_birth_nation</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inst_hours</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inst_gpa</th>\n",
       "      <td>Float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsu_prior_term</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsu_prior_termcode</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uc_citz_docs_hold_exists</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uc_from_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_entry_ind</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_total_score</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur_resd_proof_hold_exists</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur_from_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street2</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ul_les_hold_exists</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ul_from_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_comp_score</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orien_sess</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuition_plan</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>international_flag</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sabsupl_admt_country</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reup_ind</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psa</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psa_attribute</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rtp</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>declined_schlrship</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>registered</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hrs_registered</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_hours</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re_only_flag</th>\n",
       "      <td>string[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rw_hours</th>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pd_ext\n",
    "def disp(df, max_rows=4, max_cols=200, **kwargs):\n",
    "    display(HTML(df.to_html(max_rows=max_rows, max_cols=max_cols, **kwargs)))\n",
    "\n",
    "\n",
    "X.convert_dtypes().dtypes.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    write(self[key], self.optimal[key], index=False)\n",
    "# target_url = 'https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M'\n",
    "# with open(self.summary, 'rb') as target_file:\n",
    "#     response = requests.post(target_url, files = {\"amp_summary.csv\": target_file})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    A = pd.concat([S[key] for crse, C in self.optimal.items() for styp_code, S in C.items() if isinstance(S, dict) and key in S.keys()])\n",
    "    if key == 'summary':\n",
    "        B = A.copy().reset_index().assign(styp_code=A.reset_index()['styp_code'].replace({'n':'new first time','t':'transfer','r':'returning'}))\n",
    "        C = B.assign(styp_code='all').groupby(A.index.names)[['pred','true','err']].sum().reset_index()\n",
    "        C['err_pct'] = C['err'] / C['true'] * 100\n",
    "        A = pd.concat([B,C])\n",
    "    self.optimal[key] = A\n",
    "    write(self[key], self.optimal[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    A = pd.concat([S[key] for crse, C in self.optimal.items() for styp_code, S in C.items() if isinstance(S, dict) and key in S.keys()])\n",
    "    if key == 'summary':\n",
    "        B = A.copy().reset_index().assign(styp_code=A.reset_index()['styp_code'].replace({'n':'new first time','t':'transfer','r':'returning'}))\n",
    "        C = B.assign(styp_code='all').groupby(A.index.names)[['pred','true','err']].sum().reset_index()\n",
    "        C['err_pct'] = C['err'] / C['true'] * 100\n",
    "        A = pd.concat([B,C])\n",
    "    self.optimal[key] = A\n",
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    A = pd.concat([S[key] for crse, C in self.optimal.items() for styp_code, S in C.items() if isinstance(S, dict) and key in S.keys()])\n",
    "    if key == 'summary':\n",
    "        B = A.copy().reset_index().assign(styp_code=A.reset_index()['styp_code'].replace({'n':'new first time','t':'transfer','r':'returning'}))\n",
    "        C = B.assign(styp_code='all').groupby(A.index.names)[['pred','true','err']].sum()\n",
    "        C['err_pct'] = C['err'] / C['true'] * 100\n",
    "        A = pd.concat([B.set_index(A.index.names),C])\n",
    "    self.optimal[key] = A\n",
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = self.optimal['summary'][[]].droplevel('styp_code').reset_index()\n",
    "A.drop_duplicates().shape\n",
    "108/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = self.optimal['summary'].index.names\n",
    "A = self.optimal['summary'].reset_index()\n",
    "A['styp_code'] = A['styp_code'].replace({'n':'FTIC','t':'Transfer','r':'Returning'})\n",
    "B = A.copy().assign(styp_code='all').groupby(idx)[['pred','true','err']].sum().reset_index()\n",
    "B['err_pct'] = B['err'] / B['true'] * 100\n",
    "C = pd.concat([A,B])\n",
    "\n",
    "# C.vc('styp_code')\n",
    "# C\n",
    "# B\n",
    "# idx = [n for n in df.index.names if n != 'styp_code']\n",
    "# B = (\n",
    "#     A.groupby(idx)[['pred','true','err']].sum()\n",
    "#     .assign(styp_code='all', err_pct=lambda x:x['err']/x['true']*100)\n",
    "#     .reset_index().set_index(df.index.names)\n",
    "# )\n",
    "# B\n",
    "\n",
    "# n.\n",
    "# list(n)\n",
    "# remove('styp_code')\n",
    "# A = df.droplevel('styp_code')\n",
    "# A = A.groupby(A.index.names).sum()\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.vc('styp_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = self.optimal['summary']\n",
    "B = (\n",
    "    A.copy().reset_index()\n",
    "    .assign(styp_code='all')\n",
    "    .groupby(A.index.names)\n",
    "    [['pred','true','err']].sum()\n",
    ")\n",
    "B['err_pct'] = B['err'] / B['true'] * 100\n",
    "pd.concat([A,B]).reset_index()\n",
    "B\n",
    "# idx = [n for n in df.index.names if n != 'styp_code']\n",
    "# B = (\n",
    "#     A.groupby(idx)[['pred','true','err']].sum()\n",
    "#     .assign(styp_code='all', err_pct=lambda x:x['err']/x['true']*100)\n",
    "#     .reset_index().set_index(df.index.names)\n",
    "# )\n",
    "# B\n",
    "\n",
    "# n.\n",
    "# list(n)\n",
    "# remove('styp_code')\n",
    "# A = df.droplevel('styp_code')\n",
    "# A = A.groupby(A.index.names).sum()\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "target_url = 'https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M'\n",
    "with open(self.summary, 'rb') as target_file:\n",
    "    response = requests.post(target_url, files = {\"amp_summary.csv\": target_file})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([b['summary'] for a in self.optimal.values() for b in a.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['engl1301']['n']['summary']#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = nest(path, self.pred)\n",
    "Y.keys()\n",
    "for k in ['details', 'summary']:\n",
    "    Y[k] = pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(self.pred.values())[0]['n'].values())[0][202108]['summary']#.keys()#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]).prep() for k in ['cur','end']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(202208, self.term_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "d.setdefault('a', dict()).setdefault('b',4)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal = dict()\n",
    "stat = 'err_pct'\n",
    "for params, v in self.pred.items():\n",
    "    A = v['summary'].query(\"pred_term in @self.term_codes & train_term in @self.term_codes & pred_term!=train_term\")[stat]\n",
    "    B = A.abs().groupby(['crse','styp_code']).median()\n",
    "    for key, val in B.items():\n",
    "        new = {'params':params, stat:val}\n",
    "        optimal.setdefault(key, new)\n",
    "        if val < optimal[key][stat]:\n",
    "            optimal[key] = new\n",
    "for key, val in optimal.items():\n",
    "    print(key[0])\n",
    "    self.pred[val['params']][key[0]][key[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in C[0].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C[0].ge(C[1])\n",
    "# np.minimum(*C[:2])\n",
    "C[0].to_dict('list')\n",
    "\n",
    "# (orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v['rslt']['err_pct']..disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "import miceforest as mf\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer, KBinsDiscretizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, iteration=None, normalize=True):\n",
    "    targ = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    feat = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=targ, columns=feat).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "mf.ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "def inspect(self, **kwargs):\n",
    "    self.plot_imputed_distributions(wspace=0.3,hspace=0.3)\n",
    "    plt.show()\n",
    "    self.plot_mean_convergence(wspace=0.3, hspace=0.4)\n",
    "    plt.show()\n",
    "    I = self.feature_importance_df(**kwargs)\n",
    "    I.disp(100)\n",
    "    return I\n",
    "mf.ImputationKernel.inspect = inspect\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer_term: int\n",
    "    crse: typing.List\n",
    "    attr: typing.List\n",
    "    fill: typing.Dict = None\n",
    "    trf_grid: typing.Dict = None\n",
    "    imp_grid: typing.Dict = None\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "    inspect: bool = False\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.rslt = root_path / f\"resources/rslt/{rjust(self.cycle_day,3,0)}/rslt2.pkl\"\n",
    "        D = {'trm':False, 'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'raw_df':False, 'reg_df':False, 'X':False, 'Y':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.overwrite['raw_df'] |= self.overwrite['term']\n",
    "        self.overwrite['reg_df'] |= self.overwrite['term']\n",
    "        self.overwrite['X'] |= self.overwrite['raw_df']\n",
    "        self.overwrite['Y'] |= self.overwrite['reg_df'] | self.overwrite['X']\n",
    "        self.overwrite['pred'] |= self.overwrite['Y']\n",
    "\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        print(self.__dict__.keys())\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['fill','term','pred','trf_grid','imp_grid']:\n",
    "            if k not in self:\n",
    "                self[k] = dict()\n",
    "\n",
    "        self.term_codes = uniquify([*listify(self.term_codes), self.infer_term])\n",
    "        self.crse = uniquify(['_total', *listify(self.crse)])\n",
    "        self.mlt_grp = ['crse','levl_code','styp_code','term_code']\n",
    "        self.trf_list = cartesian({k: sorted(setify(v), key=str) for k,v in self.trf_grid.items()})\n",
    "        self.trf_list = [mysort({k:v for k,v in t.items() if v not in ['drop',None,'']}) for t in self.trf_list]\n",
    "        imp_default = {'iterations':3, 'mmc':0, 'mmf':'mean_match_default', 'datasets':5, 'tune':True}\n",
    "        self.imp_list = cartesian(self.imp_grid)\n",
    "        self.imp_list = [mysort(imp_default | v) for v in self.imp_list]\n",
    "        self.params_list = sorted([mysort({'imp':imp, 'trf':trf}) for trf, imp in it.product(self.trf_list,self.imp_list)], key=str)\n",
    "        return self\n",
    "\n",
    "    def get_terms(self):\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "\n",
    "\n",
    "    def preprocess(self):\n",
    "        def get(nm):\n",
    "            if nm in self:\n",
    "                return False\n",
    "            print(f'get {nm}')\n",
    "            return True\n",
    "\n",
    "        if get('raw_df') or get('reg_df'):\n",
    "            self.get_terms()\n",
    "\n",
    "        if get('raw_df'):\n",
    "            with warnings.catch_warnings(action='ignore'):\n",
    "                self.raw_df = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "\n",
    "        if get('reg_df'):\n",
    "            with warnings.catch_warnings(action='ignore'):\n",
    "                self.reg_df = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]).prep() for k in ['cur','end']}\n",
    "\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        if get('X'):\n",
    "            R = self.raw_df.copy()\n",
    "            repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "            R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "            R['remote'] = R['camp_code'] != 's'\n",
    "            R['resd'] = R['resd_code'] == 'r'\n",
    "            R['lgcy'] = ~R['lgcy_code'].isin(['n','o'])\n",
    "            R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "            R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm', '00':pd.NA})\n",
    "            R['coll_desc'] = R['coll_desc'].replace({\n",
    "                'ag & environmental_sciences':'ag & natural_resources',\n",
    "                'education & human development':'education',\n",
    "                'health science & human_service':'health sciences',\n",
    "                'science & technology':'science & mathematics'})\n",
    "            majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "            S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "            X = where(R.drop(columns=majr).merge(S, on='majr_code', how='left')).prep().prep_bool()\n",
    "\n",
    "            checks = [\n",
    "                'cycle_day >= 0',\n",
    "                'apdc_day >= cycle_day',\n",
    "                'appl_day >= apdc_day',\n",
    "                'birth_day >= appl_day',\n",
    "                'birth_day >= 5000',\n",
    "                'distance >= 0',\n",
    "                'hs_pctl >=0',\n",
    "                'hs_pctl <= 100',\n",
    "                'hs_qrtl >= 0',\n",
    "                'hs_qrtl <= 4',\n",
    "                'act_equiv >= 1',\n",
    "                'act_equiv <= 36',\n",
    "                'gap_score >= 0',\n",
    "                'gap_score <= 100',\n",
    "            ]\n",
    "            for check in checks:\n",
    "                mask = X.eval(check)\n",
    "                assert mask.all(), [check,X[~mask].disp(5)]\n",
    "            \n",
    "            for k, v in self.fill.items():\n",
    "                X[k] = X.impute(k, *listify(v))\n",
    "            self.X = X.prep().prep_bool().set_index(self.attr, drop=False).rename(columns=lambda x:'__'+x)\n",
    "            self.X.missing().disp(100)\n",
    "\n",
    "        if get('Y'):\n",
    "            Y = {k: self.X[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in self.reg_df.items()}\n",
    "            agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "            A = agg(self.reg_df['end'])\n",
    "            B = agg(Y['end'])\n",
    "            M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(f\"term_code != {self.infer_term}\").prep()\n",
    "            N = M.assign(term_code=self.infer_term)\n",
    "            self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "            Y = {k: y.squeeze().unstack().dropna(how='all', axis=1).fillna(0) for k, y in Y.items()}\n",
    "            self.Y = Y['cur'].rename(columns=lambda x:x+'_cur').join(Y['end']>0).prep()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, params, crse, train_term, styp_code='all'):\n",
    "        # for p, P in self.pred.items():\n",
    "        #     if p == str(params):\n",
    "        #         for c, C in P.items():\n",
    "        #             if c == crse:\n",
    "        #                 for t, T in C.items():\n",
    "        #                     if t == train_term:\n",
    "        #                         for s, S in T.items():\n",
    "        #                             if s == styp_code:\n",
    "        #                                 # print(ljust(crse,8), train_term, styp_code, 'reusing')\n",
    "        #                                 return S, False\n",
    "\n",
    "        print(ljust(crse,8), train_term, styp_code, 'creating')\n",
    "        X = self.X.copy()\n",
    "        if styp_code != 'all':\n",
    "            X = X.query(f\"styp_code==@styp_code\")\n",
    "        trf = ColumnTransformer([(c,t,[\"__\"+c]) for c,t in params['trf'].items()], remainder='drop', verbose_feature_names_out=False)\n",
    "        cols = uniquify(['_total_cur',crse+'_cur',crse])\n",
    "        Z = trf.fit_transform(X).join(self.Y[cols]).prep().prep_bool().prep_category().sort_index()\n",
    "        y = Z[crse].copy().rename('true').to_frame()\n",
    "        Z.loc[Z.eval(\"term_code!=@train_term\"), crse] = pd.NA\n",
    "\n",
    "        iterations = params['imp'].pop('iterations')\n",
    "        datasets = params['imp'].pop('datasets')\n",
    "        tune = params['imp'].pop('tune')\n",
    "        mmc = params['imp'].pop('mmc')\n",
    "        mmf = params['imp'].pop('mmf')\n",
    "        if mmc > 0 and mmf is not None:\n",
    "            params['imp']['mean_match_scheme'] = getattr(mf, mmf).copy()\n",
    "            params['imp']['mean_match_scheme'].set_mean_match_candidates(mmc)\n",
    "        \n",
    "        if tune:\n",
    "            # print('tuning')\n",
    "            imp = mf.ImputationKernel(Z, datasets=1, **params['imp'])\n",
    "            imp.mice(iterations=1)\n",
    "            optimal_parameters, losses = imp.tune_parameters(dataset=0, optimization_steps=5)\n",
    "        else:\n",
    "            # print('not tuning')\n",
    "            optimal_parameters = None\n",
    "        imp = mf.ImputationKernel(Z, datasets=datasets, **params['imp'])\n",
    "        imp.mice(iterations=iterations, variable_parameters=optimal_parameters)\n",
    "        if self.inspect:\n",
    "            imp.inspect()\n",
    "\n",
    "        Z.loc[:, crse] = pd.NA\n",
    "        P = imp.impute_new_data(Z)\n",
    "        details = pd.concat([y\n",
    "                .assign(pred=P.complete_data(k)[crse], train_term=train_term, crse=crse, sim=k)\n",
    "                .set_index(['train_term','crse','sim'], append=True)\n",
    "            for k in range(P.dataset_count())]).prep_bool()\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse_pct': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv_pct': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        summary = details.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            summary[x] = summary[x] * summary['mlt']\n",
    "        summary.insert(2, 'err', summary['pred'] - summary['true'])\n",
    "        summary.insert(3, 'err_pct', (summary['err'] / summary['true']).clip(-1, 1) * 100)\n",
    "        S = {'details':details, 'summary':summary.drop(columns='mlt').prep()}#, 'trf':trf, 'imp':imp}\n",
    "        # S['summary'].disp(5)\n",
    "        return S\n",
    "        # return S, True\n",
    "\n",
    "\n",
    "    def analyze(self, df):\n",
    "        def pivot(df, val):\n",
    "            Y = (\n",
    "                df\n",
    "                .reset_index()\n",
    "                .pivot_table(columns='train_term', index=['crse','styp_code','pred_term'], values=val, aggfunc=['count',pctl(0),pctl(25),pctl(50),pctl(75),pctl(100)])\n",
    "                .rename_axis(columns=[val,'train_term'])\n",
    "                .stack(0, future_stack=True)\n",
    "                .assign(abs_mean = lambda x: x.abs().mean(axis=1))\n",
    "            )\n",
    "            return Y\n",
    "        mask = df.eval(f\"pred_term!={self.infer_term}\")\n",
    "        return {stat: pivot(df[mask], stat) for stat in [\"pred\",\"err\",\"err_pct\",\"mse_pct\",\"f1_inv_pct\"]} | {\"proj\": pivot(df[~mask], \"pred\")}\n",
    "\n",
    "    def main(self, styp_codes=('n','t','r')):\n",
    "        self = self.preprocess()\n",
    "        g = lambda Y: {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "        start_time = time.perf_counter()\n",
    "        L = len(self.params_list)\n",
    "        k = 0\n",
    "        for params in self.params_list:\n",
    "            new = False\n",
    "            Y = []\n",
    "            for crse in self.crse:\n",
    "                for train_term in self.term_codes:\n",
    "                    for styp_code in listify(styp_codes):\n",
    "                        path = [str(params),crse,train_term,styp_code]\n",
    "                        try:\n",
    "                            y = nest(path, self.pred)\n",
    "                        except:\n",
    "                            if not new:\n",
    "                                print(str(params))\n",
    "                            y = self.predict(copy.deepcopy(params), crse, train_term, styp_code)\n",
    "                            nest(path, self.pred, y)\n",
    "                            new = True\n",
    "                        Y.append(y)\n",
    "            P = self.pred[str(params)]\n",
    "            if new:\n",
    "                for key in ['details', 'summary']:\n",
    "                    P[key] = pd.concat([y[key] for y in Y])\n",
    "                P['rslt'] = self.analyze(P['summary'])\n",
    "                self.dump()\n",
    "                k += 1\n",
    "            else:\n",
    "                L -= 1\n",
    "            P['rslt']['err_pct'].query(\"err_pct == ' 50%'\").disp(100)\n",
    "            P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "            elapsed = (time.perf_counter() - start_time) / 60\n",
    "            complete = k / L if L > 0 else 1\n",
    "            rate = elapsed / k if k > 0 else 0\n",
    "            remaining = rate * (L - k)\n",
    "            print(f\"{k} / {L} = {round(complete*100,1)}% complete, elapsed = {round(elapsed,1)} min, remaining = {round(remaining,1)} min @ {round(rate,1)} min per model\")\n",
    "            print(\"\\n========================================================================================================\\n\")\n",
    "        # return self\n",
    "    \n",
    "\n",
    "    # def main(self, styp_codes=('n','t','r')):\n",
    "    #     self = self.preprocess()\n",
    "    #     g = lambda Y: {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "    #     start_time = time.perf_counter()\n",
    "    #     L = len(self.params_list)\n",
    "    #     k = 0\n",
    "    #     for params in self.params_list:\n",
    "    #         # print(str(params))\n",
    "    #         try:\n",
    "    #             P = self.pred[str(params)]\n",
    "    #             S = P['summary']\n",
    "    #             L -= 1\n",
    "    #         except:\n",
    "    #             print(str(params))\n",
    "    #             P = dict()\n",
    "    #             for crse in self.crse:\n",
    "    #                 for train_term in self.term_codes:\n",
    "    #                     for styp_code in listify(styp_codes):\n",
    "    #                         S = self.predict(copy.deepcopy(params), crse, train_term, styp_code)\n",
    "    #                         path = [crse,train_term,styp_code]\n",
    "    #                         nest(path, P, S)\n",
    "    #                     path.pop(-1)\n",
    "    #                     nest(path, P, g(nest(path, P)))\n",
    "    #                 path.pop(-1)\n",
    "    #                 nest(path, P, g(nest(path, P)))\n",
    "    #             P = g(P)\n",
    "    #             S = P['summary']\n",
    "    #             k += 1\n",
    "    #         if 'rslt' not in P:\n",
    "    #             P['rslt'] = self.analyze(S)\n",
    "    #             self.pred[str(params)] = P\n",
    "    #             self.dump()\n",
    "    #         S.query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "    #         elapsed = (time.perf_counter() - start_time) / 60\n",
    "    #         complete = k / L if L > 0 else 1\n",
    "    #         rate = elapsed / k if k > 0 else 0\n",
    "    #         remaining = rate * (L - k)\n",
    "    #         print(f\"{k} / {L} = {round(complete*100,1)}% complete, elapsed = {round(elapsed,1)} min, remaining = {round(remaining,1)} min @ {round(rate,1)} min per model\")\n",
    "    #         print(\"\\n========================================================================================================\\n\")\n",
    "    #     return self\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "passthru = ['passthrough']\n",
    "passdrop = ['passthrough', 'drop']\n",
    "# passthru = passdrop\n",
    "bintrf = lambda n_bins: KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform', subsample=None)\n",
    "pwrtrf = make_pipeline(StandardScaler(), PowerTransformer())\n",
    "kwargs = {\n",
    "    # 'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'term_codes': np.arange(2021,2025)*100+8,\n",
    "    'infer_term': 202408,\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    'fill': {\n",
    "        'birth_day': ['median',['term_code','styp_code']],\n",
    "        'remote': False,\n",
    "        'international': False,\n",
    "        **{f'race_{r}': False for r in ['american_indian','asian','black','pacific','white','hispanic']},\n",
    "        'lgcy': False,\n",
    "        'resd': False,\n",
    "        'waiver': False,\n",
    "        'fafsa_app': False,\n",
    "        'schlship_app': False,\n",
    "        'finaid_accepted': False,\n",
    "        'ssb': False,\n",
    "        'math': False,\n",
    "        'reading': False,\n",
    "        'writing': False,\n",
    "        'gap_score': 0,\n",
    "        'oriented': 'n',\n",
    "    },\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        *code_desc('resd'),\n",
    "        *code_desc('lgcy'),\n",
    "        'international',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_qrtl',\n",
    "    ],\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    'cycle_day': 184,\n",
    "    'crse': [\n",
    "        'engl1301',\n",
    "        'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'trf_grid': {\n",
    "        'appl_day': passdrop,\n",
    "        'apdc_day': passdrop,\n",
    "        'birth_day': [*passthru, pwrtrf],#, ],\n",
    "        # 'levl_code': passthru,\n",
    "        # 'styp_code': passthru,\n",
    "        # 'admt_code': passdrop,\n",
    "        # 'camp_code': passdrop,\n",
    "        'remote': passthru,\n",
    "        'coll_code': passdrop,\n",
    "        'international': passthru,\n",
    "        **{f'race_{r}': passthru for r in ['american_indian','asian','black','pacific','white','hispanic']},\n",
    "        'gender': passthru,\n",
    "        'lgcy': passdrop,\n",
    "        'resd': passthru,\n",
    "        'waiver': passdrop,\n",
    "        # 'fafsa_app': passthru,\n",
    "        'schlship_app': passthru,\n",
    "        # 'finaid_accepted': passthru,\n",
    "        'ssb': passthru,\n",
    "        'math': passthru,\n",
    "        'reading': passthru,\n",
    "        'writing': passthru,\n",
    "        'gap_score': passthru,\n",
    "        'oriented': passthru,\n",
    "        'hs_qrtl': passthru,\n",
    "        'act_equiv': passthru,\n",
    "        'distance': [*passthru, pwrtrf],#, bintrf(5)],\n",
    "        },\n",
    "    'imp_grid': {\n",
    "        'mmc': 10,\n",
    "        # 'datasets': 25,\n",
    "        'datasets': 1,\n",
    "        'iterations': 1,\n",
    "        'tune': False,\n",
    "    },\n",
    "    'overwrite': {\n",
    "        # # 'trm':True,\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'raw_df': True,\n",
    "        'reg_df': True,\n",
    "        # 'X': True,\n",
    "        # 'Y': True,\n",
    "        # 'pred': True,\n",
    "    },\n",
    "    # 'inspect': True,\n",
    "}\n",
    "\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "self = self.preprocess()\n",
    "# self.term_codes.remove(self.infer_term)\n",
    "self.params_list = self.params_list[1:2]\n",
    "self.main(styp_codes='n')\n",
    "# len(self.params_list)\n",
    "# for x in self.params_list:\n",
    "#     print(x)\n",
    "# T = TERM(202008, cycle_day=184, show={'adm':True}).get_adm(184)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['A'] = [1,2,3]\n",
    "df['B'] = ['a','b','c']\n",
    "fn = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/admitted_matriculation_predictor/test.csv'\n",
    "df.to_csv(fn)\n",
    "with open(fn, 'rb') as f:\n",
    "    r = requests.post('https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M', files={'test.csv': f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# define the relative path of the sample file\n",
    "file_path = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/admitted_matriculation_predictor/test.csv'\n",
    "target_url = 'https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M'\n",
    "with open(file_path, \"rb\") as target_file:\n",
    "    response = requests.post(target_url, files = {\"form_field_name\": target_file})\n",
    "if response.ok:\n",
    "    print(\"Upload complete\")\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl'\n",
    "fn = pathlib.Path(fn)\n",
    "with open(fn, 'rb') as f:\n",
    "    # return joblib.load(f, **kwargs)\n",
    "    s = pickle.load(f)\n",
    "\n",
    "# s = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl')\n",
    "# s.X\n",
    "# self.term_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.pred.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M\n",
    "with open('report.xls', 'rb') as f:\n",
    "    r = requests.post('http://httpbin.org/post', files={'report.xls': f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl', 'rb') as f:\n",
    "    A = pickle.load(f)\n",
    "list(A.pred.values())[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('report.xls', 'rb') as f:\n",
    "    r = requests.post('https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M', files={'report.xls': f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl'\n",
    "fn = pathlib.Path(fn)\n",
    "fn.unlink(missing_ok=True)\n",
    "with open(fn, 'wb') as f:\n",
    "    joblib.dump(self, f)\n",
    "with open(fn, 'rb') as f:\n",
    "    Q = joblib.load(f)\n",
    "print(Q.pred)\n",
    "Q.pred['hi'] = 3\n",
    "with open(fn, 'wb') as f:\n",
    "    joblib.dump(Q, f)\n",
    "with open(fn, 'rb') as f:\n",
    "    R = joblib.load(f)\n",
    "print(Q.pred)\n",
    "\n",
    "# self.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl'\n",
    "# f2 = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt2.pkl'\n",
    "A = read(f)\n",
    "print(A.pred)\n",
    "A.pred['hi'] = 3\n",
    "# print(A.pred)\n",
    "# write(f, A, overwrite=True)\n",
    "# B = read(f)\n",
    "# print(B.pred)\n",
    "# A.pred\n",
    "# len(self.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, pickle, joblib\n",
    "def write(fn, obj, overwrite=False, **kwargs):\n",
    "    fn = pathlib.Path(fn)\n",
    "    suf = ['.parq','.parquet','.pkl','.csv']\n",
    "    assert fn.suffix in suf, f'Unknown suffix {fn.suffix} - must be one of {suf}'\n",
    "    if overwrite:\n",
    "        fn.unlink(missing_ok=True)\n",
    "    if not fn.is_file():\n",
    "        mkdir(fn.parent)\n",
    "        if fn.suffix == '.pkl':\n",
    "            with open(fn, 'wb') as f:\n",
    "                joblib.dump(obj, f, **kwargs)\n",
    "                # pickle.dump(obj, f, **kwargs)\n",
    "        else:\n",
    "            obj = pd.DataFrame(obj).prep()\n",
    "            if fn.suffix in ['.parq','.parquet']:\n",
    "                obj.to_parquet(fn, **kwargs)\n",
    "            elif fn.suffix == '.csv':\n",
    "                obj.to_csv(fn, **kwargs)\n",
    "    return obj\n",
    "\n",
    "def read(fn, overwrite=False, **kwargs):\n",
    "    fn = pathlib.Path(fn)\n",
    "    suf = ['.parq','.parquet','.pkl','.csv']\n",
    "    assert fn.suffix in suf, f'Unknown suffix {fn.suffix} - must be one of {suf}'\n",
    "    if overwrite:\n",
    "        fn.unlink(missing_ok=True)\n",
    "    try:\n",
    "        with open(fn, 'rb') as f:\n",
    "            return joblib.load(f, **kwargs)\n",
    "            # return pickle.load(f, **kwargs)\n",
    "    except:\n",
    "        try:\n",
    "            return pd.read_parquet(fn, **kwargs).prep()\n",
    "        except:\n",
    "            try:\n",
    "                return pd.read_csv(fn, **kwargs).prep()\n",
    "            except:\n",
    "                return None\n",
    "            \n",
    "f = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = list(self.pred.values())[0]\n",
    "P['rslt']['err_pct'].query(\"err_pct==' 50%'\")#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, p in enumerate(self.params_list):\n",
    "    if str(p) == q:\n",
    "        j = k\n",
    "        print(j)\n",
    "str(self.params_list[j]) == q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params, P in self.pred.items():\n",
    "    A = P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().median()#.describe()[].to_frame().T.disp(200)\n",
    "    if A < 3:\n",
    "        P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "        q = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.params_list[0] == q\n",
    "str(self.params_list[0]) == q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, (params, P) in enumerate(self.pred.items()):\n",
    "    A = P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().median()#.describe()[].to_frame().T.disp(200)\n",
    "    if A < 3:\n",
    "        P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "        q = params\n",
    "\n",
    "# str(self.params_list[26]) == q\n",
    "[k for k, p in enumerate(self.params_list) if str(p)==q]\n",
    "# for s in self.params_list:\n",
    "#     print(str(s)==q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = str(list(self.pred.keys())[25])\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, (params, P) in enumerate(self.pred.items()):\n",
    "    A = P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().median()#.describe()[].to_frame().T.disp(200)\n",
    "    if A < 3:\n",
    "        print(k)\n",
    "        P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "        q = params\n",
    "    \n",
    "    # print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.params_list[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = {\n",
    "    '_total': {\n",
    "        202008: {\n",
    "            'n': {\n",
    "                'summary': 1,\n",
    "                'full': 2,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 3,\n",
    "                'full': 4,\n",
    "            },\n",
    "        },\n",
    "        202108: {\n",
    "            'n': {\n",
    "                'summary': 5,\n",
    "                'full': 6,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 7,\n",
    "                'full': 8,\n",
    "            },\n",
    "        },\n",
    "        202208: {\n",
    "            'n': {\n",
    "                'summary': 9,\n",
    "                'full': 10,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 11,\n",
    "                'full': 12,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    'engl1301': {\n",
    "        202008: {\n",
    "            'n': {\n",
    "                'summary': 21,\n",
    "                'full': 22,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 23,\n",
    "                'full': 24,\n",
    "            },\n",
    "        },\n",
    "        202108: {\n",
    "            'n': {\n",
    "                'summary': 25,\n",
    "                'full': 26,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 27,\n",
    "                'full': 28,\n",
    "            },\n",
    "        },\n",
    "        202208: {\n",
    "            'n': {\n",
    "                'summary': 29,\n",
    "                'full': 30,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 31,\n",
    "                'full': 32,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "d = np.array(0)\n",
    "n/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(self.pred.keys())[10]\n",
    "self.pred[k].keys()#['rslt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.raw_df.query('pidm==1121725').disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in self.pred.values():\n",
    "    print(v.keys())\n",
    "    # pass\n",
    "# A = list(self.pred.values())[0]\n",
    "# A.keys()\n",
    "# self.analyze(A['summary'])\n",
    "# v['rslt']['proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "train_term = 202308\n",
    "styp_code = 'n'\n",
    "A = list(self.pred.values())[0]['summary'].query(f\"crse==@crse & train_term==@train_term & styp_code==@styp_code & pred_term!=202408\")\n",
    "A['err_pct'].abs().describe().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda Y: {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "Q = dict()\n",
    "for params, P in self.pred.items():\n",
    "    print(str(params))\n",
    "    for crse, C in P.items():\n",
    "        if crse in self.crse:\n",
    "            for train_term, T in C.items():\n",
    "                if train_term in self.term_codes:\n",
    "                    for styp_code, S in T.items():\n",
    "                        if styp_code in ['n','r','t']:\n",
    "                            path = [str(params),crse,train_term,styp_code]\n",
    "                            nest(path, Q, S)\n",
    "                    path.pop(-1)\n",
    "                    nest(path, Q, g(nest(path, Q)))\n",
    "            path.pop(-1)\n",
    "            nest(path, Q, g(nest(path, Q)))\n",
    "    path.pop(-1)\n",
    "    nest(path, Q, g(nest(path, Q)))\n",
    "    # nest(path, self.pred[params], g(nest(path, Q)))\n",
    "    # self.pred[params] = g(Q)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda Y: {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "for params, P in self.pred.items():\n",
    "    print(str(params))\n",
    "    for crse in self.crse:\n",
    "        for train_term in self.term_codes:\n",
    "            for styp_code in ['n']:\n",
    "                S, new = self.predict(copy.deepcopy(params), crse, train_term, styp_code)\n",
    "                assert new is False\n",
    "                path = [str(params),crse,train_term,styp_code]\n",
    "                P = nest(path, P, S)\n",
    "                dump |= new\n",
    "            path.pop(-1)\n",
    "            P = nest(path, P, g(nest(path, P)))\n",
    "        path.pop(-1)\n",
    "        P = nest(path, P, g(nest(path, P)))\n",
    "    path.pop(-1)\n",
    "    self.pred[str(params)] = nest(path, P, g(nest(path, P)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25\n",
    "params = list(self.pred.keys())[k]\n",
    "rslt = self.pred[params]\n",
    "rslt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25\n",
    "params = list(self.pred.keys())[k]\n",
    "rslt = self.pred[params]\n",
    "df = rslt['summary']\n",
    "# df.query(f\"train_term==202308 & pred_term!=202408\")['err_pct'].abs().describe().to_frame().T.disp(200)\n",
    "\n",
    "def analyze(df):\n",
    "    def pivot(df, val):\n",
    "        Y = (\n",
    "            df\n",
    "            .reset_index()\n",
    "            .pivot_table(columns='train_term', index=['crse','styp_code','pred_term'], values=val, aggfunc=['count',pctl(0),pctl(25),pctl(50),pctl(75),pctl(100)])\n",
    "            .rename_axis(columns=[val,'train_term'])\n",
    "            .stack(0, future_stack=True)\n",
    "            .assign(abs_mean = lambda x: x.abs().mean(axis=1))\n",
    "        )\n",
    "        return Y\n",
    "    # v = self.pred[params]\n",
    "    # df = v['summary']\n",
    "    mask = df.eval(f\"pred_term!={self.infer_term}\")\n",
    "    rslt = {stat: pivot(df[mask], stat) for stat in [\"pred\",\"err\",\"err_pct\",\"mse_pct\",\"f1_inv_pct\"]} | {'pred': pivot(df[~mask], \"pred\")}\n",
    "    \n",
    "    return rslt\n",
    "    # R = v['rslt']['err_pct'].query(\"err_pct in [' 50%']\")\n",
    "    # R.disp(200)\n",
    "    # # R[['abs_mean']].describe().T.disp(200)\n",
    "    # # df.query(f\"crse==@crse & train_term==@train_term & styp_code==@styp_code & pred_term!=202408\")\n",
    "    # df.query(f\"train_term==202308 & pred_term!=202408\")['err_pct'].abs().describe().to_frame().T.disp(200)\n",
    "    # return self.dump()\n",
    "\n",
    "rslt = analyze(df)\n",
    "rslt['pred']\n",
    "# rslt.keys()\n",
    "# for k, (params, rslt) in enumerate(self.pred.items()):\n",
    "#     print(k, params)\n",
    "#     df = rslt['summary']\n",
    "#     df.query(f\"train_term==202308 & pred_term!=202408\")['err_pct'].abs().describe().to_frame().T.disp(200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
