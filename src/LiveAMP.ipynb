{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 2, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.41</td>\n",
       "      <td>7.54</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.91</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.24</td>\n",
       "      <td>5.11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-3.32</td>\n",
       "      <td>-21.05</td>\n",
       "      <td>-19.15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.51</td>\n",
       "      <td>14.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.54</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>3.75</td>\n",
       "      <td>10.86</td>\n",
       "      <td>9.13</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 5, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.79</td>\n",
       "      <td>7.17</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.05</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.05</td>\n",
       "      <td>6.43</td>\n",
       "      <td>6.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.24</td>\n",
       "      <td>4.36</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.45</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-2.19</td>\n",
       "      <td>-21.86</td>\n",
       "      <td>-18.78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.28</td>\n",
       "      <td>14.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.46</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>-3.57</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>3.92</td>\n",
       "      <td>10.34</td>\n",
       "      <td>8.95</td>\n",
       "      <td>8.57</td>\n",
       "      <td>7.94</td>\n",
       "      <td>7.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 8, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.92</td>\n",
       "      <td>8.35</td>\n",
       "      <td>5.64</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>7.32</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.07</td>\n",
       "      <td>9.96</td>\n",
       "      <td>6.11</td>\n",
       "      <td>6.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.42</td>\n",
       "      <td>6.29</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.95</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-2.81</td>\n",
       "      <td>-22.23</td>\n",
       "      <td>-17.98</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.34</td>\n",
       "      <td>14.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.31</td>\n",
       "      <td>-3.67</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.18</td>\n",
       "      <td>11.15</td>\n",
       "      <td>9.13</td>\n",
       "      <td>8.18</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 11, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.72</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>7.43</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.45</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.46</td>\n",
       "      <td>2.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-5.51</td>\n",
       "      <td>-22.04</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.79</td>\n",
       "      <td>14.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.13</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.8</td>\n",
       "      <td>10.52</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 14, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.69</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7.32</td>\n",
       "      <td>7.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.38</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.39</td>\n",
       "      <td>8.9</td>\n",
       "      <td>6.23</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.46</td>\n",
       "      <td>2.93</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.08</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-3.15</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-13.75</td>\n",
       "      <td>13.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.23</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.33</td>\n",
       "      <td>9.94</td>\n",
       "      <td>8.79</td>\n",
       "      <td>8.38</td>\n",
       "      <td>7.86</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 17, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.79</td>\n",
       "      <td>7.49</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.67</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.46</td>\n",
       "      <td>9.36</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.36</td>\n",
       "      <td>2.24</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.08</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-3.15</td>\n",
       "      <td>-20.92</td>\n",
       "      <td>-18.83</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.3</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.63</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.73</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 20, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.89</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>7.65</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.27</td>\n",
       "      <td>9.55</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.19</td>\n",
       "      <td>3.42</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.09</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-4.67</td>\n",
       "      <td>-21.54</td>\n",
       "      <td>-18.35</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.86</td>\n",
       "      <td>14.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>8.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.84</td>\n",
       "      <td>10.36</td>\n",
       "      <td>8.63</td>\n",
       "      <td>8.64</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 23, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.54</td>\n",
       "      <td>7.76</td>\n",
       "      <td>6.47</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.32</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.59</td>\n",
       "      <td>2.12</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.86</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-4.56</td>\n",
       "      <td>-21.42</td>\n",
       "      <td>-20.39</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-15.45</td>\n",
       "      <td>15.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.12</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>5.16</td>\n",
       "      <td>9.69</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.21</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 26, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.23</td>\n",
       "      <td>6.47</td>\n",
       "      <td>7.07</td>\n",
       "      <td>5.93</td>\n",
       "      <td>5.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.12</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.53</td>\n",
       "      <td>3.24</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-3.55</td>\n",
       "      <td>-21.17</td>\n",
       "      <td>-17.71</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.14</td>\n",
       "      <td>14.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.64</td>\n",
       "      <td>-4.57</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>5.01</td>\n",
       "      <td>9.55</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.12</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 29, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.28</td>\n",
       "      <td>6.31</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.93</td>\n",
       "      <td>8.95</td>\n",
       "      <td>5.86</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.69</td>\n",
       "      <td>2.99</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.77</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-2.25</td>\n",
       "      <td>-20.61</td>\n",
       "      <td>-17.17</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-13.35</td>\n",
       "      <td>13.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.04</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-2.98</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>3.55</td>\n",
       "      <td>10.63</td>\n",
       "      <td>8.47</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 32, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.16</td>\n",
       "      <td>8.77</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>7.48</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.37</td>\n",
       "      <td>9.59</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.03</td>\n",
       "      <td>5.35</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10.23</td>\n",
       "      <td>5.87</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-2.42</td>\n",
       "      <td>-21.11</td>\n",
       "      <td>-17.23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-13.59</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.36</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1.42</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>3.98</td>\n",
       "      <td>10.88</td>\n",
       "      <td>8.79</td>\n",
       "      <td>9.22</td>\n",
       "      <td>8.22</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 35, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.23</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.48</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>6.92</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.39</td>\n",
       "      <td>9.55</td>\n",
       "      <td>5.95</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.27</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-4.61</td>\n",
       "      <td>-21.61</td>\n",
       "      <td>-19.58</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-15.27</td>\n",
       "      <td>15.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.92</td>\n",
       "      <td>-4.71</td>\n",
       "      <td>-3.76</td>\n",
       "      <td>8.77</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>9.29</td>\n",
       "      <td>8.77</td>\n",
       "      <td>7.94</td>\n",
       "      <td>7.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 38, 'mean_match_function': <function mean_match_kdtree_classification at 0x7fe54a0c99e0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.11</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.02</td>\n",
       "      <td>5.98</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.84</td>\n",
       "      <td>9.36</td>\n",
       "      <td>6.77</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>3.11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.81</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-5.46</td>\n",
       "      <td>-20.36</td>\n",
       "      <td>-18.46</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.76</td>\n",
       "      <td>14.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.84</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.56</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.36</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.88</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 2, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.41</td>\n",
       "      <td>7.54</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.91</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.24</td>\n",
       "      <td>5.11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-3.32</td>\n",
       "      <td>-21.05</td>\n",
       "      <td>-19.15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.51</td>\n",
       "      <td>14.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.54</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>3.75</td>\n",
       "      <td>10.86</td>\n",
       "      <td>9.13</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 5, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.79</td>\n",
       "      <td>7.17</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.05</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.05</td>\n",
       "      <td>6.43</td>\n",
       "      <td>6.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.24</td>\n",
       "      <td>4.36</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.45</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-2.19</td>\n",
       "      <td>-21.86</td>\n",
       "      <td>-18.78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.28</td>\n",
       "      <td>14.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.46</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>-3.57</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>3.92</td>\n",
       "      <td>10.34</td>\n",
       "      <td>8.95</td>\n",
       "      <td>8.57</td>\n",
       "      <td>7.94</td>\n",
       "      <td>7.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 8, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.92</td>\n",
       "      <td>8.35</td>\n",
       "      <td>5.64</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>7.32</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.07</td>\n",
       "      <td>9.96</td>\n",
       "      <td>6.11</td>\n",
       "      <td>6.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.42</td>\n",
       "      <td>6.29</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.95</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-2.81</td>\n",
       "      <td>-22.23</td>\n",
       "      <td>-17.98</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.34</td>\n",
       "      <td>14.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.31</td>\n",
       "      <td>-3.67</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.18</td>\n",
       "      <td>11.15</td>\n",
       "      <td>9.13</td>\n",
       "      <td>8.18</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 11, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.72</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>7.43</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.45</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.46</td>\n",
       "      <td>2.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-5.51</td>\n",
       "      <td>-22.04</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.79</td>\n",
       "      <td>14.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.13</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.8</td>\n",
       "      <td>10.52</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 14, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.69</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7.32</td>\n",
       "      <td>7.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.38</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.39</td>\n",
       "      <td>8.9</td>\n",
       "      <td>6.23</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.46</td>\n",
       "      <td>2.93</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.08</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-3.15</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-13.75</td>\n",
       "      <td>13.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.23</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.33</td>\n",
       "      <td>9.94</td>\n",
       "      <td>8.79</td>\n",
       "      <td>8.38</td>\n",
       "      <td>7.86</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 17, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.79</td>\n",
       "      <td>7.49</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.67</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.46</td>\n",
       "      <td>9.36</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.36</td>\n",
       "      <td>2.24</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.08</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-3.15</td>\n",
       "      <td>-20.92</td>\n",
       "      <td>-18.83</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.3</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.63</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.73</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 20, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.89</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>7.65</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.27</td>\n",
       "      <td>9.55</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.19</td>\n",
       "      <td>3.42</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.09</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-4.67</td>\n",
       "      <td>-21.54</td>\n",
       "      <td>-18.35</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.86</td>\n",
       "      <td>14.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>8.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>4.84</td>\n",
       "      <td>10.36</td>\n",
       "      <td>8.63</td>\n",
       "      <td>8.64</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 23, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.54</td>\n",
       "      <td>7.76</td>\n",
       "      <td>6.47</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.32</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.59</td>\n",
       "      <td>2.12</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.86</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-4.56</td>\n",
       "      <td>-21.42</td>\n",
       "      <td>-20.39</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-15.45</td>\n",
       "      <td>15.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.12</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>5.16</td>\n",
       "      <td>9.69</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.21</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 26, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.23</td>\n",
       "      <td>6.47</td>\n",
       "      <td>7.07</td>\n",
       "      <td>5.93</td>\n",
       "      <td>5.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>8.95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.12</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.53</td>\n",
       "      <td>3.24</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-3.55</td>\n",
       "      <td>-21.17</td>\n",
       "      <td>-17.71</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-14.14</td>\n",
       "      <td>14.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.64</td>\n",
       "      <td>-4.57</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>5.01</td>\n",
       "      <td>9.55</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.12</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 29, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.28</td>\n",
       "      <td>6.31</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.93</td>\n",
       "      <td>8.95</td>\n",
       "      <td>5.86</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>1.69</td>\n",
       "      <td>2.99</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.77</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-2.25</td>\n",
       "      <td>-20.61</td>\n",
       "      <td>-17.17</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-13.35</td>\n",
       "      <td>13.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.04</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-2.98</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>3.55</td>\n",
       "      <td>10.63</td>\n",
       "      <td>8.47</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 32, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n",
      "_total 202308 n: creating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>err%</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_term</th>\n",
       "      <th>202008</th>\n",
       "      <th>202108</th>\n",
       "      <th>202208</th>\n",
       "      <th>202308</th>\n",
       "      <th>mean</th>\n",
       "      <th>abs_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.16</td>\n",
       "      <td>8.77</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202108</th>\n",
       "      <td>7.48</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.37</td>\n",
       "      <td>9.59</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202208</th>\n",
       "      <td>2.03</td>\n",
       "      <td>5.35</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10.23</td>\n",
       "      <td>5.87</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202308</th>\n",
       "      <td>-2.42</td>\n",
       "      <td>-21.11</td>\n",
       "      <td>-17.23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-13.59</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.36</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1.42</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_mean</th>\n",
       "      <td>3.98</td>\n",
       "      <td>10.88</td>\n",
       "      <td>8.79</td>\n",
       "      <td>9.22</td>\n",
       "      <td>8.22</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': 5, 'mean_match_candidates': 35, 'mean_match_function': <function default_mean_match at 0x7fe54bea04a0>, 'random_state': 42, 'save_all_iterations': False}\n",
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 435\u001b[0m\n\u001b[1;32m    433\u001b[0m opts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_match_candidates\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cand\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28mprint\u001b[39m(mysort(opts))\n\u001b[0;32m--> 435\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstyp_codes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m R[\u001b[38;5;28;01mFalse\u001b[39;00m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrslt\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_total\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merr\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdisp(\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    440\u001b[0m tune\u001b[38;5;241m.\u001b[39mappend(R)\n",
      "Cell \u001b[0;32mIn[3], line 289\u001b[0m, in \u001b[0;36mAMP.train\u001b[0;34m(self, styp_codes, train_terms, iterations, opts)\u001b[0m\n\u001b[1;32m    286\u001b[0m     r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproj\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pivot(df\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_term==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m, q) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m75\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[0;32m--> 289\u001b[0m P \u001b[38;5;241m=\u001b[39m {(crse, styp_code, train_term): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyp_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m crse \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrse \u001b[38;5;28;01mfor\u001b[39;00m styp_code \u001b[38;5;129;01min\u001b[39;00m listify(styp_codes) \u001b[38;5;28;01mfor\u001b[39;00m train_term \u001b[38;5;129;01min\u001b[39;00m listify(train_terms)}\n\u001b[1;32m    290\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m P\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[3], line 225\u001b[0m, in \u001b[0;36mAMP.predict\u001b[0;34m(self, crse, styp_code, train_term, iterations, opts)\u001b[0m\n\u001b[1;32m    223\u001b[0m ampute(X, qry)\n\u001b[1;32m    224\u001b[0m model \u001b[38;5;241m=\u001b[39m ImputationKernel(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[0;32m--> 225\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# with warnings.catch_warnings(action='ignore'):\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m#     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# assert 1==2\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# S.insert(2, 'err', S['pred'] - S['true'])\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\u001b[39;00m\n\u001b[1;32m    249\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m df, nm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m: df\u001b[38;5;241m.\u001b[39mfilter(like\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_end\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x:x[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\u001b[38;5;241m.\u001b[39mmelt(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrse\u001b[39m\u001b[38;5;124m'\u001b[39m, value_name\u001b[38;5;241m=\u001b[39mnm)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrse\u001b[39m\u001b[38;5;124m'\u001b[39m, append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/miceforest/ImputationKernel.py:844\u001b[0m, in \u001b[0;36mImputationKernel.mice\u001b[0;34m(self, iterations, verbose, variable_parameters, **kwlgb)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_order:\n\u001b[1;32m    838\u001b[0m     bachelor_features \u001b[38;5;241m=\u001b[39m _subset_data(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworking_data,\n\u001b[1;32m    840\u001b[0m         row_ind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_where[var],\n\u001b[1;32m    841\u001b[0m         col_ind\u001b[38;5;241m=\u001b[39mpredictor_variables,\n\u001b[1;32m    842\u001b[0m     )\n\u001b[1;32m    843\u001b[0m     imp_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m--> 844\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_match_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmmc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_match_candidates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcandidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbachelor_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbachelor_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcandidate_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m     )\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m imp_values\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m    854\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_counts[var],\n\u001b[1;32m    855\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mean matching returned malformed array\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_new_data(\n\u001b[1;32m    858\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mds, variable_index\u001b[38;5;241m=\u001b[39mvar, new_data\u001b[38;5;241m=\u001b[39mimp_values\n\u001b[1;32m    859\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/miceforest/mean_matching_functions.py:111\u001b[0m, in \u001b[0;36mdefault_mean_match\u001b[0;34m(mmc, model, candidate_features, bachelor_features, candidate_values, random_state)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# balanced_tree = False fixes a recursion issue for some reason.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# https://github.com/scipy/scipy/issues/14799\u001b[39;00m\n\u001b[1;32m    110\u001b[0m kd_tree \u001b[38;5;241m=\u001b[39m KDTree(candidate_preds, leafsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, balanced_tree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 111\u001b[0m _, knn_indices \u001b[38;5;241m=\u001b[39m \u001b[43mkd_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbachelor_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmmc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We can skip the random selection process if mmc == 1\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/scipy/spatial/_kdtree.py:475\u001b[0m, in \u001b[0;36mKDTree.query\u001b[0;34m(self, x, k, eps, p, distance_upper_bound, workers)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk must be an integer or a sequence of integers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 475\u001b[0m d, i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_upper_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    477\u001b[0m     i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mintp(i)\n",
      "File \u001b[0;32m_ckdtree.pyx:828\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree.cKDTree.query\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_ckdtree.pyx:1604\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree._run_threads\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/threading.py:976\u001b[0m, in \u001b[0;36mThread.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 976\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_started\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/threading.py:634\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    632\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 634\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/threading.py:334\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest import ImputationKernel\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer: int\n",
    "    crse: typing.List\n",
    "    feat: typing.Dict\n",
    "    attr: typing.List\n",
    "    # sch: bool = True\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.term_codes = uniquify([*listify(self.term_codes), self.infer])\n",
    "        self.crse = uniquify(['_total', *listify(self.crse)])\n",
    "        self.mlt_grp = ['crse','levl_code','styp_code','term_code']\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'X':False, 'Y':False, 'Z':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['Z'] |= self.overwrite['X'] | self.overwrite['Y']\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.path = root_path / f\"resources/rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['pred']:\n",
    "            self[k] = self[k] if k in self else list()\n",
    "        for k in ['term']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "    def get_X(self):\n",
    "        nm = 'X'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        print(f'get {nm}')\n",
    "        R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "        repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "        R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "        R['remote'] = R['camp_code'] != 's'\n",
    "        # R['distance'] = R['distance'].fillna(R['distance'].max())\n",
    "        R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "        R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm'})\n",
    "        R['coll_desc'] = R['coll_desc'].replace({\n",
    "            'ag & environmental sciences':'ag & natural resources',\n",
    "            'education & human development':'education',\n",
    "            'health science & human service':'health sciences',\n",
    "            'science & technology':'science & mathematics'})\n",
    "        majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "        S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "        R = R.drop(columns=majr).merge(S, on='majr_code', how='left')\n",
    "\n",
    "        checks = {\n",
    "            'cycle_day': R['cycle_day']>=0,\n",
    "            'apdc_day' : R['apdc_day' ]>=R['cycle_day'],\n",
    "            'appl_day' : R['appl_day' ]>=R['apdc_day' ],\n",
    "            'birth_day':(R['birth_day']>=R['appl_day' ]) & (R['birth_day']>=5000),\n",
    "            'distance': R['distance']>=0,\n",
    "            'hs_pctl': (R['hs_pctl']>=0) & (R['hs_pctl']<=100),\n",
    "            'act_equiv': (R['act_equiv']>=1) & (R['act_equiv']<=36),\n",
    "            'gap_score': (R['gap_score']>=0) & (R['gap_score']<=100),\n",
    "        }\n",
    "        for k, mask in checks.items():\n",
    "            if (~mask).any():\n",
    "                R[~mask].disp(10)\n",
    "                raise Exception(f'check failed - {k}')\n",
    "        self[nm] = R\n",
    "        return self.dump()\n",
    "\n",
    "    def preprocess(self):\n",
    "        nm = 'Z'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        self.get_X()\n",
    "        print(f'get {nm}')\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "        self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "        self.Z.missing().disp(100)\n",
    "\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]) for k in ['cur','end']}\n",
    "        agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "        A = agg(Y['end'])\n",
    "        Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in Y.items()}\n",
    "        B = agg(Y['end'])\n",
    "        M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(\"term_code != @self.infer\").prep()\n",
    "        N = M.assign(term_code=self.infer)\n",
    "        self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "        self.Y = pd.concat([y.squeeze().unstack().dropna(how='all', axis=1).rename(columns=lambda x:x+'_'+k) for k, y in Y.items()], axis=1).fillna(0)\n",
    "        # self.Y = pd.concat([y.squeeze().unstack().rename(columns=lambda x:f'{x}_{k}') for k, y in Y.items()], axis=1).fillna(0)\n",
    "        # self.Y = {k: y.squeeze().unstack().fillna(0) for k, y in Y.items()}#.rename(columns=lambda x:f'{x}_{k}') \n",
    "\n",
    "\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\").assign(credit_hr=lambda x: x['credit_hr'].fillna(0)>0) for term in self.term.values()]) for k in ['end','cur']}\n",
    "        # agg = lambda y: where(y).groupby(['levl_code','styp_code','term_code','crse'])['credit_hr'].sum()\n",
    "        # A = agg(Y['end'])\n",
    "        # Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr'], how='inner') for k, y in Y.items()}\n",
    "        # B = agg(Y['end'])\n",
    "        # M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(\"term_code != @self.infer\").prep()\n",
    "        # N = M.assign(term_code=self.infer)\n",
    "        # self.mlt = pd.concat([M, N], axis=0)\n",
    "        # self.Y = {k: y.squeeze().unstack().fillna(False) for k, y in Y.items()}#.rename(columns=lambda x:f'{x}_{k}') \n",
    "\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\").assign(credit_hr=lambda x: x['credit_hr'].fillna(0)>0) for term in self.term.values()]) for k in ['end','cur']}\n",
    "        # agg = lambda y: where(y).groupby(['levl_code','styp_code','term_code','crse'])['credit_hr'].sum()\n",
    "        # A = agg(Y['end'])\n",
    "        # Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr'], how='inner') for k, y in Y.items()}\n",
    "        # B = agg(Y['end'])\n",
    "        # M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(\"term_code != @self.infer\").prep()\n",
    "        # N = M.assign(term_code=self.infer)\n",
    "        # self.mlt = pd.concat([M, N], axis=0)\n",
    "        # print(type(Y['end']))\n",
    "        # self.Y = {k: y.squeeze().unstack().fillna(False)}#.rename(columns=lambda x:f'{x}_{k}') for k, y in Y.items()}\n",
    "\n",
    "\n",
    "        # M = (A / B).query(\"term_code != @self.infer\")\n",
    "        # N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "        # self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "        # self.Y = {k: y.squeeze().unstack().fillna(False).rename(columns=lambda x:f'{x}_{k}') for k, y in Y.items()}\n",
    "        \n",
    "\n",
    "\n",
    "        # where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        # X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "        # self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "        #     # self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "        #     # self.Z.missing().disp(100)\n",
    "        #     # for c in ['_hs_qrtl', '_act_equiv']:\n",
    "        #     #     self.Z[c+'_missing'] = self.Z[c].isnull()\n",
    "        #     # self.Z = self.Z.prep().binarize().categorize()\n",
    "        # agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "        # grp = ['levl_code','styp_code','term_code','crse']\n",
    "        # end = agg(self.Y[0], grp)\n",
    "        \n",
    "        # self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "        # cur = agg(self.Y[0], grp)\n",
    "\n",
    "        # M = (end / cur).query(\"term_code != @self.infer\")\n",
    "        # N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "        # self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, crse='_total', styp_code='all', train_term=202208, iterations=3, opts=dict()):\n",
    "        print(crse,train_term,styp_code, end=': ')\n",
    "        prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "        for P in self.pred:\n",
    "            if P['meta'] == prediction['meta']:\n",
    "                print('reusing')\n",
    "                return P\n",
    "        print(f'creating')\n",
    "\n",
    "        targ = crse+'_end'\n",
    "        cols = uniquify(['_total_cur', crse+'_cur', targ])\n",
    "        T = self.Z.join(self.Y[cols])\n",
    "        T[targ] = T[targ] > 0\n",
    "        if styp_code != \"all\":\n",
    "            T = T.query(\"styp_code==@styp_code\")\n",
    "\n",
    "        \n",
    "        # d = {'cur':{crse}, 'end':{crse}}\n",
    "        # d['cur'].add('_total')\n",
    "        # T = self.Z.copy()\n",
    "        # for k, v in d.items():\n",
    "        #     T = T.join(self.Y[k][v].rename(columns=lambda x:x+'_'+k), how='left')\n",
    "        # Y = pd.concat([self.Y[k][v] for k, v in d.items()])\n",
    "        # targ = crse+'_end'\n",
    "        # Y[targ] = \n",
    "                       \n",
    "                    #    .rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "\n",
    "        # d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "        # d = {crse+'_cur':1, crse+'_end':0,}\n",
    "        # end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "\n",
    "\n",
    "        # Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "        # T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "        def ampute(df, qry):\n",
    "            df.loc[df.eval(qry), targ] = pd.NA\n",
    "        qry = f\"term_code=={self.infer}\"\n",
    "        ampute(T, qry)\n",
    "        X = T.copy()\n",
    "        qry = f\"term_code!={train_term}\"\n",
    "        ampute(X, qry)\n",
    "        model = ImputationKernel(X, **opts)\n",
    "        model.mice(iterations)\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "            # assert 1==2\n",
    "        #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "        #     # imp.plot_correlations()\n",
    "\n",
    "        # # g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        # g = lambda df, nm=None: df.filter(like='_end').melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        # P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "        # Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "        # grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "        # agg = lambda x: pd.Series({\n",
    "        #     'pred': x['pred'].sum(min_count=1),\n",
    "        #     'true': x['true'].sum(min_count=1),\n",
    "        #     'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "        #     'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        # })\n",
    "        # S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        # for x in ['pred','true']:\n",
    "        #     S[x] = S[x] * S['mlt']\n",
    "        # S.insert(2, 'err', S['pred'] - S['true'])\n",
    "        # S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "        \n",
    "        g = lambda df, nm=None: df.filter(like='_end').rename(columns=lambda x:x[:-4]).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        P = pd.concat([model.complete_data(k).assign(train_term=train_term, sim=k).set_index(['train_term','sim'], append=True) for k in range(model.dataset_count())])\n",
    "        Y = g(P,'pred').join(g(T,'true')).query(qry).prep()\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        S = Y.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            S[x] = S[x] * S['mlt']\n",
    "        S.insert(2, 'err', S['pred'] - S['true'])\n",
    "        S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "        prediction['model'] = model\n",
    "        prediction['detail'] = Y\n",
    "        prediction['summary'] = S.drop(columns='mlt').prep()\n",
    "        prediction['X'] = X\n",
    "        prediction['T'] = T\n",
    "        prediction['P'] = P\n",
    "        self.pred.append(prediction)\n",
    "        self.dump()\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def train(self, styp_codes=('n','r','t'), train_terms=None, iterations=3, opts=dict()):\n",
    "        train_terms = self.term_codes if train_terms is None else train_terms\n",
    "        def pivot(df, val, q=50):\n",
    "            Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "            for _ in range(2):\n",
    "                mr = Y.mean(axis=1)\n",
    "                ma = Y.abs().mean(axis=1)\n",
    "                Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "            return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "        \n",
    "        def analyze(df):\n",
    "            r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "            r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "            return r\n",
    "\n",
    "        P = {(crse, styp_code, train_term): self.predict(crse, styp_code, train_term, iterations, opts) for crse in self.crse for styp_code in listify(styp_codes) for train_term in listify(train_terms)}\n",
    "        R = dict()\n",
    "        for k,v in P.items():\n",
    "            R.setdefault(k[1]=='all', []).append(v)\n",
    "\n",
    "        for b, L in R.items():\n",
    "            v = {k: pd.concat([Y[k] for Y in L]) for k in ['detail', 'summary']}\n",
    "            v['opts'] = opts.copy()\n",
    "            v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "            R[b] = v\n",
    "        return R\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "simpimp = lambda fill: SimpleImputer(strategy='constant', fill_value=fill, missing_values=pd.NA)\n",
    "kwargs = {\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        'resd',\n",
    "        'international',\n",
    "        'gender',\n",
    "        'legacy',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_pctl',\n",
    "    ],\n",
    "    'feat': [\n",
    "        ['_term_code',np.nan],\n",
    "        ['_appl_day',np.nan],\n",
    "        ['_apdc_day',np.nan],\n",
    "        ['_birth_day','median',['term_code','styp_code']],\n",
    "        \n",
    "        # ['_levl_code',np.nan],\n",
    "        ['_styp_code',np.nan],\n",
    "        # ['_admt_code',np.nan],\n",
    "\n",
    "        # ['_camp_code',np.nan],\n",
    "        ['_remote',False],\n",
    "        ['_coll_code',np.nan],\n",
    "        \n",
    "        ['_international',False],\n",
    "        *[[f'_race_{r}',False] for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        ['_gender',np.nan],\n",
    "        ['_legacy',False],\n",
    "        ['_resd',False],\n",
    "        \n",
    "        ['_waiver',False],\n",
    "        # ['_fafsa_app',False],\n",
    "        ['_schlship_app',False],\n",
    "        # ['_finaid_accepted',False],\n",
    "        ['_ssb',False],\n",
    "        ['_math',False],\n",
    "        ['_reading',False],\n",
    "        ['_writing',False],\n",
    "        ['_gap_score',0],\n",
    "        ['_oriented','n'],\n",
    "        \n",
    "        ['_hs_qrtl',np.nan],\n",
    "        ['_act_equiv',np.nan],\n",
    "        ['_distance',np.nan],\n",
    "        \n",
    "    ],\n",
    "    'infer': 202408,\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    # 'cycle_day': 197,\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'crse': [\n",
    "        # 'engl1301',\n",
    "        # 'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'X': True,\n",
    "        # 'Y': True,\n",
    "        # 'Z': True,\n",
    "        'pred': True,\n",
    "    },\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    # 'sch': False,\n",
    "}\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "# self = self.get_X()\n",
    "self = self.preprocess()\n",
    "self.term_codes.remove(self.infer)\n",
    "iterations = 3\n",
    "\n",
    "opts = dict()\n",
    "opts['random_state'] = 42\n",
    "opts['save_all_iterations'] = False\n",
    "opts['datasets'] = 5\n",
    "opts['mean_match_candidates'] = 10\n",
    "opts['mean_match_function'] = mean_match_kdtree_classification\n",
    "\n",
    "# opts['datasets'] = 2\n",
    "# opts['mean_match_candidates'] = 1\n",
    "# opts['mean_match_function'] = default_mean_match\n",
    "\n",
    "# P = self.predict(opts=opts)\n",
    "\n",
    "# R = self.train(iterations=iterations, opts=opts,\n",
    "#     styp_codes='n',\n",
    "#     # train_terms=202208,\n",
    "#     )\n",
    "# for k, v in R[False]['rslt'].items():\n",
    "#     print(k)\n",
    "#     v['err%'].disp(100)\n",
    "\n",
    "tune = []\n",
    "for func in [mean_match_kdtree_classification, default_mean_match]:\n",
    "    opts['mean_match_function'] = func\n",
    "    for cand in range(2,41,3):\n",
    "        opts['mean_match_candidates'] = cand\n",
    "        print(mysort(opts))\n",
    "        R = self.train(\n",
    "            styp_codes='n',\n",
    "            iterations=iterations,\n",
    "            opts=opts)\n",
    "        R[False]['rslt']['_total','n']['err%'].disp(100)\n",
    "        tune.append(R)\n",
    "        write(self.tune, tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['summary'].disp(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, d in R[False]['rslt'].items():\n",
    "    print(g)\n",
    "    d['err%'].disp(100)\n",
    "    # print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in R[False]['rslt'].keys():\n",
    "    for b, v in R.items():\n",
    "        print(k, b)\n",
    "        v['rslt'][k]['err%'].disp(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = self.train(iterations=iterations, opts=opts,\n",
    "    styp_codes='n',\n",
    "    # train_terms=202208,\n",
    "    )\n",
    "\n",
    "def pivot(df, val, q=50):\n",
    "    Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "    for _ in range(2):\n",
    "        mr = Y.mean(axis=1)\n",
    "        ma = Y.abs().mean(axis=1)\n",
    "        Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "    return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "\n",
    "def analyze(df):\n",
    "    r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "    r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "    return r\n",
    "\n",
    "for b, L in R.items():\n",
    "    v = {k: pd.concat([Y[k] for Y in L]) for k in ['detail', 'summary']}\n",
    "    # v['opts'] = opts.copy()\n",
    "    # for g, df in v['summary'].groupby(['crse', 'styp_code']):\n",
    "    #     v[g] = analyze(df)\n",
    "    v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "    # R[b] = v\n",
    "# v[False]\n",
    "# R[False]\n",
    "# R[False][0].keys()\n",
    "# v['summary'].keys()\n",
    "# v['rslt']\n",
    "v.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "yr = 23\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    sfrstcr_term_code as term_code,\n",
    "    sfrstcr_pidm as pidm,\n",
    "    (select sgbstdn_levl_code from sgbstdn where sgbstdn_pidm = sfrstcr_pidm and sgbstdn_term_code_eff <= sfrstcr_term_code order by sgbstdn_term_code_eff desc fetch first 1 rows only) as levl_code,\n",
    "    (select sgbstdn_styp_code from sgbstdn where sgbstdn_pidm = sfrstcr_pidm and sgbstdn_term_code_eff <= sfrstcr_term_code order by sgbstdn_term_code_eff desc fetch first 1 rows only) as styp_code\n",
    "from sfrstcr\n",
    "where\n",
    "    sfrstcr_term_code = 20{yr}08\n",
    "    and  trunc(sfrstcr_add_date) <= trunc(to_date('10-Sep-{yr}')) -- added before cycle_day\n",
    "    and (trunc(sfrstcr_rsts_date) > trunc(to_date('10-Sep-{yr}')) or sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "    and sfrstcr_ptrm_code not in ('28','R3')\n",
    "group by sfrstcr_term_code, sfrstcr_pidm\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    term_code, levl_code, styp_code, count(distinct pidm)\n",
    "from {subqry(qry)}\n",
    "where levl_code='UG' and styp_code in ('N','R','T')\n",
    "group by term_code, levl_code, styp_code\n",
    "order by term_code, levl_code, styp_code\n",
    "\"\"\"\n",
    "db.head(qry, 100, show=True)\n",
    "# )\n",
    "# select A.* from A\n",
    "# union all\n",
    "# select\n",
    "#     A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code,\n",
    "#     '_total' as crse,\n",
    "#     sum(A.credit_hr) as credit_hr\n",
    "# from A\n",
    "# group by A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2143-2273)/2273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "yr = 21\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    A.sfrstcr_term_code as term_code,\n",
    "    A.sfrstcr_pidm as pidm,\n",
    "    (select C.sgbstdn_levl_code from sgbstdn C where C.sgbstdn_pidm = A.sfrstcr_pidm and C.sgbstdn_term_code_eff <= A.sfrstcr_term_code order by C.sgbstdn_term_code_eff desc fetch first 1 rows only) as levl_code,\n",
    "    (select C.sgbstdn_styp_code from sgbstdn C where C.sgbstdn_pidm = A.sfrstcr_pidm and C.sgbstdn_term_code_eff <= A.sfrstcr_term_code order by C.sgbstdn_term_code_eff desc fetch first 1 rows only) as styp_code,\n",
    "    --lower(B.ssbsect_subj_code) || B.ssbsect_crse_numb as crse,\n",
    "    sum(B.ssbsect_credit_hrs) as credit_hr\n",
    "from sfrstcr A, ssbsect B\n",
    "where\n",
    "    A.sfrstcr_term_code = B.ssbsect_term_code\n",
    "    and A.sfrstcr_crn = B.ssbsect_crn\n",
    "    and A.sfrstcr_term_code = 20{yr}08\n",
    "    and A.sfrstcr_ptrm_code not in ('28','R3')\n",
    "    and  trunc(A.sfrstcr_add_date) <= trunc(to_date('10-Sep-{yr}')) -- added before cycle_day\n",
    "    and (trunc(A.sfrstcr_rsts_date) > trunc(to_date('10-Sep-{yr}')) or A.sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "    and B.ssbsect_subj_code <> 'INST'\n",
    "group by A.sfrstcr_term_code, A.sfrstcr_pidm--, B.ssbsect_subj_code, B.ssbsect_crse_numb\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    term_code, levl_code, styp_code, count(distinct pidm)\n",
    "from {subqry(qry)}\n",
    "where credit_hr > 0 and levl_code='UG' and styp_code in ('N','R','T')\n",
    "group by term_code, levl_code, styp_code\n",
    "\"\"\"\n",
    "db.head(qry, 100)\n",
    "# )\n",
    "# select A.* from A\n",
    "# union all\n",
    "# select\n",
    "#     A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code,\n",
    "#     '_total' as crse,\n",
    "#     sum(A.credit_hr) as credit_hr\n",
    "# from A\n",
    "# group by A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "where(self.term[202208].reg['end']).query(\"styp_code=='n'\")['pidm'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['summary'].disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_term = 202208\n",
    "styp_code = 'n'\n",
    "crse = '_total'\n",
    "model = self.pred[0]['rslt']['model']\n",
    "\n",
    "\n",
    "targ = crse+'_end'\n",
    "cols = uniquify(['_total_cur', crse+'_cur', targ])\n",
    "T = self.Z.join(self.Y[cols])\n",
    "T[targ] = T[targ] > 0\n",
    "if styp_code != \"all\":\n",
    "    T = T.query(\"styp_code==@styp_code\")\n",
    "\n",
    "\n",
    "qry = f\"term_code!={train_term}\"\n",
    "g = lambda df, nm=None: df.filter(like='_end').rename(columns=lambda x:x[:-4]).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "agg = lambda x: pd.Series({\n",
    "    'pred': x['pred'].sum(min_count=1),\n",
    "    'true': x['true'].sum(min_count=1),\n",
    "    'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "})\n",
    "S = Y.groupby(['crse','levl_code','styp_code','term_code','train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "S.insert(2, 'err', S['pred'] - S['true'])\n",
    "S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = Y.groupby(['crse','levl_code','styp_code','term_code','train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "S.insert(2, 'err', S['pred'] - S['true'])\n",
    "S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "S.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(self.Y.shape, self.Z.shape)\n",
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y.isnull().sum()\n",
    "# self.crse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.term[202208].reg['cur'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "d = {'cur':{crse}, 'end':{crse}}\n",
    "d['cur'].add('_total')\n",
    "T = self.Z.copy()\n",
    "for k, v in d.items():\n",
    "    T = T.join(self.Y[k][listify(v)].rename(columns=lambda x:x+'_'+k))\n",
    "T.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['cur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = self.X.query('distance.isnull()')\n",
    "\n",
    "Y[['pidm','distance','stat_code','natn_code','zip','international','resd_code']].disp(100)\n",
    "# self.X.query(\"pidm in [1121725,1060603,1063123,1071878]\").disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = self.X.query(\"distance.notnull() & ((natn_code.notnull() & natn_code!='us') | stat_code in ['hi','ak','pr','ae','ap'])\")\n",
    "Y[['distance','stat_code','natn_code']].disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select\n",
    "    B.spraddr_cnty_code as cnty_code,\n",
    "    B.spraddr_seqno as s,\n",
    "    case\n",
    "        when B.spraddr_atyp_code = 'PA' then 6\n",
    "        when B.spraddr_atyp_code = 'PR' then 5\n",
    "        when B.spraddr_atyp_code = 'MA' then 4\n",
    "        when B.spraddr_atyp_code = 'BU' then 3\n",
    "        when B.spraddr_atyp_code = 'BI' then 2\n",
    "        when B.spraddr_atyp_code = 'P1' then 1\n",
    "        when B.spraddr_atyp_code = 'P2' then 0\n",
    "        end as r\n",
    "from spraddr B\n",
    "where B.spraddr_pidm = 1087120\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    B.cnty_code\n",
    "from (\n",
    "    select\n",
    "        B.spraddr_cnty_code as cnty_code,\n",
    "        B.spraddr_seqno as s,\n",
    "        case\n",
    "            when B.spraddr_atyp_code = 'PA' then 6\n",
    "            when B.spraddr_atyp_code = 'PR' then 5\n",
    "            when B.spraddr_atyp_code = 'MA' then 4\n",
    "            when B.spraddr_atyp_code = 'BU' then 3\n",
    "            when B.spraddr_atyp_code = 'BI' then 2\n",
    "            when B.spraddr_atyp_code = 'P1' then 1\n",
    "            when B.spraddr_atyp_code = 'P2' then 0\n",
    "            end as r\n",
    "    from spraddr B\n",
    "    where B.spraddr_pidm = 1087120\n",
    ") B\n",
    "where\n",
    "    B.cnty_code is not null\n",
    "    and B.r is not null\n",
    "order by\n",
    "    B.r desc,\n",
    "    B.s desc\n",
    "\"\"\"\n",
    "db.execute(qry).disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.missing()\n",
    "Y = self.X.query(\"distance.isnull() & (natn_code.isnull() | natn_code=='us') & stat_code not in ['hi','ak','pr','ae','ap']\")\n",
    "Y.sort_values('pidm').disp(1000)\n",
    "uniquify(Y['pidm'].tolist())\n",
    "# [['stat_code','natn_code']].disp(100)\n",
    "# self.X.iloc[[17412,30806]].disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"select distinct spraddr_stat_code from spraddr\"\n",
    "A = db.execute(qry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.value_counts('spbpers','spbpers_gndr_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('spbpers').columns.sort_values()\n",
    "db.head('opeir.admissions_fall2022').columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join(['AL','AR','AZ','CA','CO','CT','DC','DE','FL','GA','IA','ID','IL','IN','KS','KY','LA','MA','MD','ME','MI','MN','MO','MS','MT','NC','ND','NE','NH','NJ','NM','NV','NY','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VA','VT','WA','WI','WV','WY')\n",
    "# len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sort(A.squeeze().str.upper().unique().tolist()))\n",
    "# sort(A.squeeze().str.upper).unique().tolist())\n",
    "print(A.squeeze().str.upper().value_counts().sort_index().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"select A.* from spraddr A where A.spraddr_pidm = 1029274\"db.execute(qry).disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('opeir.admissions_fall2023',1).disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('szrsstd',1).disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute('stvatyp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = self.X.query(\"distance.isnull()\")['pidm'].tolist()\n",
    "qry = f\"select A.* from spraddr A where A.spraddr_pidm in ({join(L)}) and spraddr_stat_code='TX' order by spraddr_pidm\"\n",
    "# qry = f\"select A.* from sarappd A where A.sarappd_pidm in ({join(L)})\"\n",
    "# qry = f\"select A.*, (select sarappd_apdc_code from sarappd where sarappd_pidm = saradap_pidm and sarappd_appl_no = saradap_appl_no order by sarappd_seq_no desc fetch first 1 row only) as sarappd_apdc_code from saradap A where saradap_pidm in ({join(L)})\"\n",
    "A = db.execute(qry, show=True)\n",
    "A.disp(2000)\n",
    "# A['saradap_resd_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "w = pathlib.Path('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/flags/raw/old/201608_admitted_flags_report_031616.xlsx')\n",
    "w.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_ext(func):\n",
    "    def wrapper(X, *args, **kwargs):\n",
    "        try:\n",
    "            Y = func(X, *args, **kwargs)\n",
    "            print(1)\n",
    "        except:\n",
    "            Y = pd.DataFrame(X)\n",
    "            try:\n",
    "                Y = func(Y, *args, **kwargs)\n",
    "                print(2)\n",
    "            except:\n",
    "                Y = Y.apply(func, *args, **kwargs)\n",
    "                print(3)\n",
    "        if isinstance(X, pd.Series):\n",
    "            try:\n",
    "                Y = Y.squeeze()\n",
    "            except:\n",
    "                pass\n",
    "        return Y\n",
    "    wrapper.__name__ = func.__name__\n",
    "    return wrapper\n",
    "\n",
    "@pd_ext\n",
    "def binarize(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    s = set(ser.dropna())\n",
    "    if s:\n",
    "        if s.issubset({'y','Y'}):\n",
    "            ser = ser.notnull().astype('boolean')\n",
    "        elif s.issubset({0,1}):\n",
    "            ser = ser.astype('boolean')\n",
    "    return ser\n",
    "\n",
    "for func in [disp, to_numeric, prep, categorize, binarize, rnd, vc, missing, impute, unmelt]:\n",
    "    for cls in [pd.DataFrame, pd.Series]:\n",
    "        setattr(cls, func.__name__, func)\n",
    "\n",
    "# self.X['schlship_app'].value_counts()\n",
    "# self.X['fafsa_app'].value_counts()\n",
    "# self.X['schlship_app'].dtype\n",
    "# A = self.X.binarize()['schlship_app']\n",
    "# A['schlship_app']\n",
    "binarize(self.X)['schlship_app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['schlship_app'].groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "\n",
    "g = ['levl_code','styp_code','term_code','crse']\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\")[['pidm',*g,'credit_hr']].assign(credit_hr=lambda x: x['credit_hr'].fillna(0)>0) for term in self.term.values()]) for k in ['end','cur']}\n",
    "agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "A = agg(Y['end'], g)\n",
    "Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr'], how='inner') for k, y in Y.items()}\n",
    "B = agg(Y['end'], g)\n",
    "self.mlt = A / B\n",
    "\n",
    "self.Y = {k: y.squeeze().unstack().fillna(False).rename(columns=lambda x:f'{x}_{k}') for k, y in Y.items()}\n",
    "Y['end']\n",
    "# M = (end / cur).query(\"term_code != @self.infer\")\n",
    "# N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "# self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "\n",
    "\n",
    "# end\n",
    "self.Y['end']\n",
    "# Y = [self.Y[0].query(\"crse in @self.crse\").set_index('crse', append=True).unstack().droplevel(0,1).rename(columns=lambda x:f\"_{x}_end\")\n",
    "# # Y.droplevel?\n",
    "# Y.disp(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute(df, col, val=None, grp=None):\n",
    "#     val = val if val is not None else 'median' if pd.api.types.is_numeric_dtype(df[col]) else 'mode'\n",
    "#     if val in ['median']:\n",
    "#         func = lambda x: x.median()\n",
    "#     elif val in ['mean','ave','avg','average']:\n",
    "#         func = lambda x: x.mean()\n",
    "#     elif val in ['mode','most_frequent']:\n",
    "#         func = lambda x: x.mode()[0]\n",
    "#     else:\n",
    "#         func = lambda x: val\n",
    "#     df[col] = (df if grp is None else df.groupby(grp))[col].transform(lambda x: x.fillna(func(x)))\n",
    "#     return df\n",
    "# pd.DataFrame.impute = impute\n",
    "\n",
    "self.Z.reset_index(drop=True)\n",
    "A = self.Z.copy()\n",
    "c = '_birth_day'\n",
    "mask = A[c].isnull()\n",
    "# A.impute('_birth_day', val='median', grp=['term_code','styp_code'])\n",
    "# A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.loc[mask,c].disp(5)\n",
    "# A.groupby(['term_code','styp_code'])['_birth_day'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trf = ColumnTransformer(self.feat, remainder='drop',verbose_feature_names_out = False)\n",
    "# where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "# with warnings.catch_warnings(action='ignore'):\n",
    "#     self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "#     self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "\n",
    "kwargs = {\n",
    "    'feat': [\n",
    "        ['_gender',np.nan],\n",
    "        ['_appl_day',np.nan],\n",
    "        ['_apdc_day',np.nan],\n",
    "        ['_hs_qrtl',np.nan],\n",
    "        ['_act_equiv',np.nan],\n",
    "        ['_remote',False],\n",
    "        ['_resd',False],\n",
    "        ['_legacy',False],\n",
    "        *[[f'_race_{r}',False] for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        ['_waiver',False],\n",
    "        # ['_fafsa_app',False],\n",
    "        ['_schlship_app',False],\n",
    "        # ['_finaid_accepted',False],\n",
    "        ['_ssb',False],\n",
    "        ['_math',False],\n",
    "        ['_reading',False],\n",
    "        ['_writing',False],\n",
    "        ['_gap_score',0],\n",
    "        ['_oriented','n'],\n",
    "        ['_distance','max'],\n",
    "        ['_birth_day','median',['term_code','styp_code']],\n",
    "    ],\n",
    "}\n",
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "g = lambda col:'_'+col\n",
    "# cols = [x[0] for x in kwargs['feat']]\n",
    "# where(self.X).rename(columns=g)[cols].isnull().sum().disp(1000)\n",
    "X = where(self.X).set_index(self.attr, drop=False).rename(columns=g)\n",
    "Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "Z.isnull().sum().disp(1000)\n",
    "Z.dtypes\n",
    "# L = [Z.impute(col, *val)]\n",
    "# L = [[col, *listify(val)] for C, val in kwargs['feat'] for col in listify(C)]\n",
    "# L = [Z.impute(g(col), *listify(val)) for C, val in kwargs['feat'] for col in listify(C)]\n",
    "# L\n",
    "#).rename(columns=lambda x:'_'+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(Z).disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/flags/parq/flg_202308.parq', columns=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('spbpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"select spbpers_sex, count(*) from spbpers group by spbpers_sex\"\n",
    "db.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest import ImputationKernel\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer: int\n",
    "    crse: typing.List\n",
    "    feat: typing.Dict\n",
    "    attr: typing.List\n",
    "    sch: bool = True\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # check feat lists are disjoint\n",
    "        L = [x for f in self.feat for x in f[-1]]\n",
    "        assert len(L) == len(set(L))\n",
    "\n",
    "        self.term_codes = listify(self.term_codes)\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'X':False, 'Y':False, 'Z':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['Z'] |= self.overwrite['X'] | self.overwrite['Y']\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.path = root_path / f\"rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['pred']:\n",
    "            self[k] = self[k] if k in self else list()\n",
    "        for k in ['term']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "    def get_X(self):\n",
    "        nm = 'X'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        print(f'get {nm}')\n",
    "        R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "        repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "        R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "        R['camp_main'] = R['camp_code'] == 's'\n",
    "        R['distance'] = R['distance'].fillna(R['distance'].max())\n",
    "        R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "        R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm'})\n",
    "        R['coll_desc'] = R['coll_desc'].replace({\n",
    "            'ag & environmental sciences':'ag & natural resources',\n",
    "            'education & human development':'education',\n",
    "            'health science & human service':'health sciences',\n",
    "            'science & technology':'science & mathematics'})\n",
    "        majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "        S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "        R = R.drop(columns=majr).merge(S, on='majr_code', how='left')\n",
    "\n",
    "        checks = {\n",
    "            'cycle_day': R['cycle_day']>=0,\n",
    "            'apdc_day' : R['apdc_day' ]>=R['cycle_day'],\n",
    "            'appl_day' : R['appl_day' ]>=R['apdc_day' ],\n",
    "            'birth_day':(R['birth_day']>=R['appl_day' ]) & (R['birth_day']>=5000),\n",
    "            'distance': R['distance']>=0,\n",
    "            'hs_pctl': (R['hs_pctl']>=0) & (R['hs_pctl']<=100),\n",
    "            'act_equiv': (R['act_equiv']>=1) & (R['act_equiv']<=36),\n",
    "            'gap_score': (R['gap_score']>=0) & (R['gap_score']<=100),\n",
    "        }\n",
    "        for k, mask in checks.items():\n",
    "            if (~mask).any():\n",
    "                R[~mask].disp(10)\n",
    "                raise Exception(f'check failed - {k}')\n",
    "        self[nm] = R\n",
    "        return self.dump()\n",
    "\n",
    "    def preprocess(self):\n",
    "        nm = 'Z'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        self.get_X()\n",
    "        print(f'get {nm}')\n",
    "\n",
    "        trf = ColumnTransformer(self.feat, remainder='drop',verbose_feature_names_out = False)\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "            self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "            self.Z.missing().disp(100)\n",
    "            for c in ['_hs_qrtl', '_act_equiv']:\n",
    "                self.Z[c+'_missing'] = self.Z[c].isnull()\n",
    "            self.Z = self.Z.prep().binarize().categorize()\n",
    "        agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "        grp = ['levl_code','styp_code','term_code','crse']\n",
    "        end = agg(self.Y[0], grp)\n",
    "        \n",
    "        self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "        cur = agg(self.Y[0], grp)\n",
    "\n",
    "        M = (end / cur).query(\"term_code != @self.infer\")\n",
    "        N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "        self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, crse='_total', styp_code='all', train_term=202208, iterations=3, opts=dict()):\n",
    "        print(crse,train_term,styp_code, end=': ')\n",
    "        prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "        for P in self.pred:\n",
    "            if P['meta'] == prediction['meta']:\n",
    "                print('reusing')\n",
    "                return P\n",
    "        print(f'creating')\n",
    "        # d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "        d = {crse+'_cur':1, crse+'_end':0,}\n",
    "        end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "        Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "        T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "        if styp_code != \"all\":\n",
    "            T = T.query(\"styp_code==@styp_code\")\n",
    "        T.loc[T.eval(\"term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "        X = T.copy()\n",
    "        # qry = \"term_code!=@train_term\"\n",
    "        qry = \"term_code==@train_term\"\n",
    "        X.loc[X.eval(qry), end.keys()] = pd.NA\n",
    "        model = ImputationKernel(X, **opts)\n",
    "        model.mice(iterations)\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "            # assert 1==2\n",
    "        #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "        #     # imp.plot_correlations()\n",
    "\n",
    "        g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "        Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "        grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            S[x] = S[x] * S['mlt']\n",
    "        S.insert(2, 'err', S['pred'] - S['true'])\n",
    "        S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "        prediction['rslt'] = {'X':X,'T':T,'P':P,'model':model, 'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "        self.pred.append(prediction)\n",
    "        self.dump()\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def train(self, styp_codes=('n','r','t'), train_terms=None, iterations=3, opts=dict()):\n",
    "        train_terms = self.term_codes if train_terms is None else train_terms\n",
    "        def pivot(df, val, q=50):\n",
    "            Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "            for _ in range(2):\n",
    "                mr = Y.mean(axis=1)\n",
    "                ma = Y.abs().mean(axis=1)\n",
    "                Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "            return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "        \n",
    "        def analyze(df):\n",
    "            r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "            r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "            return r\n",
    "\n",
    "        P = {(crse, styp_code, train_term): self.predict(crse, styp_code, train_term, iterations, opts) for crse in self.crse for styp_code in listify(styp_codes) for train_term in listify(train_terms)}\n",
    "        R = dict()\n",
    "        for k,v in P.items():\n",
    "            R.setdefault(k[1]=='all', []).append(v)\n",
    "\n",
    "        for b, L in R.items():\n",
    "            v = {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']}\n",
    "            v['opts'] = opts.copy()\n",
    "            v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "            R[b] = v\n",
    "        return R\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "simpimp = lambda fill: SimpleImputer(strategy='constant', fill_value=fill, missing_values=pd.NA)\n",
    "kwargs = {\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_pctl',\n",
    "    ],\n",
    "    'feat': [\n",
    "        ('scl', make_pipeline(StandardScaler(), PowerTransformer()), [\n",
    "            'distance',\n",
    "            'birth_day',\n",
    "            # 'gap_score',\n",
    "            # 'hs_pctl',\n",
    "            'act_equiv',\n",
    "        ]),\n",
    "        ('pass', 'passthrough', [\n",
    "            'gender',\n",
    "            # 'styp_code',\n",
    "            # 'camp_code',\n",
    "            # 'coll_code',\n",
    "            # 'verified',\n",
    "            # 'term_code',\n",
    "            'appl_day',\n",
    "            'apdc_day',\n",
    "            'hs_qrtl',\n",
    "        ]),\n",
    "        ('false', simpimp(False), [\n",
    "            'camp_main',\n",
    "            'resd',\n",
    "            'legacy',\n",
    "            *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "            'waiver',\n",
    "            # 'fafsa_app',\n",
    "            'schlship_app',\n",
    "            # 'finaid_accepted',\n",
    "            'ssb',\n",
    "            'math',\n",
    "            'reading',\n",
    "            'writing',\n",
    "        ]),\n",
    "        ('0', simpimp(0), [\n",
    "            'gap_score',\n",
    "        ]),\n",
    "        ('n', simpimp('n'), [\n",
    "            'oriented',\n",
    "        ]),\n",
    "    ],\n",
    "    'infer': 202408,\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    # 'cycle_day': 197,\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'crse': [\n",
    "        '_total',\n",
    "        # 'engl1301',\n",
    "        # 'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'X': True,\n",
    "        # 'Y': True,\n",
    "        # 'Z': True,\n",
    "        'pred': True,\n",
    "    },\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    # 'sch': False,\n",
    "}\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "self = self.preprocess()\n",
    "self.term_codes.remove(self.infer)\n",
    "iterations = 3\n",
    "\n",
    "opts = dict()\n",
    "opts['random_state'] = 42\n",
    "opts['save_all_iterations'] = False\n",
    "opts['datasets'] = 5\n",
    "opts['mean_match_candidates'] = 10\n",
    "opts['mean_match_function'] = mean_match_kdtree_classification\n",
    "\n",
    "# # opts['datasets'] = 2\n",
    "# # opts['mean_match_candidates'] = 1\n",
    "# # opts['mean_match_function'] = default_mean_match\n",
    "\n",
    "# P = self.predict(opts=opts)\n",
    "\n",
    "R = self.train(iterations=iterations, opts=opts,\n",
    "    styp_codes='n',\n",
    "    # train_terms=202208,\n",
    "    )\n",
    "# for k in R[False]['rslt'].keys():\n",
    "#     for b, v in R.items():\n",
    "#         print(k, b)\n",
    "#         v['rslt'][k]['err%'].disp(100)\n",
    "\n",
    "# tune = []\n",
    "# for func in [mean_match_kdtree_classification, default_mean_match]:\n",
    "#     opts['mean_match_function'] = func\n",
    "#     for cand in range(2,41,3):\n",
    "#         opts['mean_match_candidates'] = cand\n",
    "#         print(sort(opts))\n",
    "#         R = self.train(\n",
    "#             styp_codes='n',\n",
    "#             iterations=iterations,\n",
    "#             opts=opts)\n",
    "#         R[False]['rslt']['_total','n']['err%'].disp(100)\n",
    "#         tune.append(R)\n",
    "#         write(self.tune, tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "match x:\n",
    "    case 2:\n",
    "        print(2)\n",
    "    case 10:\n",
    "        print(11)\n",
    "    case None:\n",
    "        print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['styp_code'].mode()\n",
    "# self.Z['_birth_day']['median']()\n",
    "df = pd.DataFrame()\n",
    "df['a'] = [1,1,2,2]\n",
    "df['b'] = ['a','a','a','a',]\n",
    "df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, col, val=None, grp=None):\n",
    "    val = val if val is not None else 'median' if pd.api.types.is_numeric_dtype(df[col]) else 'mode'\n",
    "    if val in ['median']:\n",
    "        func = lambda x: x.median()\n",
    "    elif val in ['mean','ave','avg','average']:\n",
    "        func = lambda x: x.mean()\n",
    "    elif val in ['mode','most_frequent']:\n",
    "        func = lambda x: x.mode()[0]\n",
    "    else:\n",
    "        func = lambda x: val\n",
    "    df[col] = (df if grp is None else df.groupby(grp))[col].transform(lambda x: x.fillna(func(x)))\n",
    "    return df\n",
    "pd.DataFrame.impute = impute\n",
    "\n",
    "self.Z.reset_index(drop=True)\n",
    "A = self.Z.copy()\n",
    "c = '_birth_day'\n",
    "mask = A[c].isnull()\n",
    "# A.impute('_birth_day', val='median', grp=['term_code','styp_code'])\n",
    "A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.loc[mask,c].disp(5)\n",
    "# A.groupby(['term_code','styp_code'])['_birth_day'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".102924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = self.pred[0]\n",
    "R = P['rslt']\n",
    "self.Z.dtypes\n",
    "# R['P'].dtypes#.values.astype(float)\n",
    "# model = self.pred[0]['rslt']['model']\n",
    "# model.feature_importance_df()\n",
    "# model.plot_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(self.path / 'predictions.csv', R[False]['summary'])\n",
    "write(self.path / 'predictions.parq', R[False]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.concat([term.raw for term in self.term.values()]).dropna(axis=1, how='all').reset_index(drop=True).prep()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.concat([term.raw for term in self.term.values()]).dropna(axis=1, how='all').reset_index(drop=True).prep()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "# R['hs_qrtl'] = \n",
    "R['A'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False)\n",
    "R['B'] = R['apdc_code'].map(repl)\n",
    "A\n",
    "# R['hs_qrtl'] = R['A'].combine_first(R['B'])\n",
    "# pd.concat([A,B],axis=1)\n",
    "R\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('stvapdc', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "idx = ['pidm','styp_code','apdc_code','apdc_desc']\n",
    "# P = self.X.set_index(idx)[['hs_pctl']]\n",
    "P = where(self.X).filter([*idx, 'hs_pctl'])\n",
    "repl = {\n",
    "    # 'a2':pd.NA,\n",
    "    # 'aa':pd.NA,\n",
    "    # 'ac':pd.NA,\n",
    "    # 'ad':pd.NA,\n",
    "    'ag':pd.NA,\n",
    "    'ai':pd.NA,\n",
    "    'at':pd.NA,\n",
    "    'ae':0,\n",
    "    'n1':1,\n",
    "    'n2':2,\n",
    "    'n3':3,\n",
    "    'n4':4,\n",
    "    'r1':1,\n",
    "    'r2':2,\n",
    "    'r3':3,\n",
    "    'r4':4,\n",
    "}\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "\n",
    "# bins = [100,89.9,74.9,49.9,24.9,0]\n",
    "# bool, default False\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "P['hs_qrtl'] = pd.cut(P['hs_pctl'], right=False, bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0]).combine_first(P['apdc_code'].map(repl))\n",
    "# P.query('hs_qrtl==2')\n",
    "# P.query(\"apdc_code=='n2'\")\n",
    "# P.vc(['apdc_desc','hs_qrtl']).disp(200)\n",
    "# Q = P.query(\"hs_qrtl.isnull()\")\n",
    "# P.groupby(['apdc_code','hs_qrtl']).size()\n",
    "P.groupby(['apdc_code','apdc_desc'])['hs_qrtl'].value_counts(normalize=True, dropna=False).round(2).sort_index().to_frame().disp(200)\n",
    "# Q.vc(['styp_code','apdc_code','apdc_desc']).disp(200)\n",
    "# P['hs_qrtl'].isnull().sum()\n",
    "# P.query(\"hs_qrtl.isnull()\").vc('apdc_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [100,89.9,74.9,49.9,24.9,0]\n",
    "np.arange(4,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P.query(\"apdc_code=='n2' & hs_pctl.notnull()\" ).disp(2000)\n",
    "P.query(\"apdc_code=='n2'\" ).disp(2000)\n",
    "# P.query(\"apdc_code=='n2'\").vc('hs_qrtl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.query(\"apdc_desc=='admitted (nr1)' & hs_qrtl==2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.query('hs_pctl.isnull()').vc('apdc_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    'a2':pd.NA,\n",
    "    'aa':pd.NA,\n",
    "    'ac':pd.NA,\n",
    "    'ad':pd.NA,\n",
    "    'ae':5,\n",
    "    'ag':pd.NA,\n",
    "    'ai':pd.NA,\n",
    "    'at':pd.NA,\n",
    "    'n1':1,\n",
    "    'n2':3,\n",
    "    'n3':4,\n",
    "    'n4':4,\n",
    "    'r1':1,\n",
    "    'r2':2,\n",
    "    'r3':3,\n",
    "    'r4':4,\n",
    "}\n",
    "P['q'] = P['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.vc(['apdc_code','apdc_desc'])\n",
    "# {'n1':1}\n",
    "# set(P.reset_index()['apdc_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.filter(like='_hs_pctl').query('_hs_pctl.isnull()').vc('apdc_desc')\n",
    "# # self.X.groupby('apdc_desc')['hs_pctl'].describe()\n",
    "# P = self.X[['apdc_desc','hs_pctl']]\n",
    "# pd.cut(self.X['hs_pctl'],4)\n",
    "# P = pd.cut(self.X.set_index(['pidm','apdc_desc'])['hs_pctl'], bins=[-1,25,50,75,100], labels=[1,2,3,4])\n",
    "P.vc(['apdc_desc','hs_qrtl']).disp(200)\n",
    "# P.groupby('apdc_desc').describe()\n",
    "# (P==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt'][('_total', 'n')]['proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A['summary'].query(\"pred_term!=202408 & styp_code=='n' & pred_term!=train_term\")#['err%']\n",
    "import seaborn as sns\n",
    "sns.boxplot(M, hue='train_term', y='err%', x='pred_term',\n",
    "    # fill=False,\n",
    "    whis=(0, 100),\n",
    "    dodge = True,\n",
    "    palette='tab10',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['Pmodel'].feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R[False]['rslt']['_total','n']['err%']\n",
    "R[False]['rslt']['_total','n'].keys()#['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P['rslt']['model'].feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_df(self, dataset, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(datset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_feature_importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = self.pred[0]['rslt']['model']\n",
    "# model.plot_feature_importance??\n",
    "imputed_var_names = [model._get_variable_name(int(i)) for i in np.sort(model.imputation_order)]\n",
    "predictor_var_names = [model._get_variable_name(int(i)) for i in np.sort(model.predictor_vars)]\n",
    "# model.\n",
    "c = '_total_end'\n",
    "I = pd.DataFrame(model.get_feature_importance(0), index=imputed_var_names, columns=predictor_var_names).T\n",
    "I *= 100 / I.sum()\n",
    "I[c].sort_values(ascending=False)\n",
    "# I.T['_total_end']\n",
    "# (0).shape\n",
    "#(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt']['_total','n'].keys()\n",
    "\n",
    "# ['rslt']['_total','n'].keys()\n",
    "# model = R[False]['rslt']['_total','n']\n",
    "#['model']\n",
    "# model.plot_feature_importance?\n",
    "# (dataset=0, annot=True,cmap=\"YlGnBu\",vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((len(f[-1]) for f in self.feat))\n",
    "L = [x for f in self.feat for x in f[-1]]\n",
    "len(L), len(set(L))\n",
    "# {x for f in self.feat for x in f[-1]}\n",
    "# {*self.feat[0][-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/flags/parq/flg_202308.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.columns\n",
    "F['styp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.isnull().sum().sort_index().disp(1000)\n",
    "# self.Z.dtypes\n",
    "# .vc('oriented')\n",
    "# hs_pctlact_equiv\n",
    "mask = self.Z['birth_day'].isnull()\n",
    "self.Z[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"select * from spbpers where spbpers_pidm=1115874\"\n",
    "db.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.select_dtypes('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.isnull().sum().sort_values(ascending=False).to_frame('missing').query('missing>0')\n",
    "# self.Z.vc('writing')\n",
    "# self.Z.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "feat = [\n",
    "    ('scl', make_pipeline(StandardScaler(), PowerTransformer()), [\n",
    "        'distance',\n",
    "        'birth_day',\n",
    "    ]),\n",
    "    # ('nom', FunctionTransformer(lambda x: x.astype('category')), [\n",
    "    ('nom', 'passthrough', [\n",
    "        'gender',\n",
    "        'oriented',\n",
    "        'styp_code',\n",
    "        # 'camp_code',\n",
    "        'coll_code',\n",
    "        # 'verified',\n",
    "    ]),\n",
    "    ('pass', 'passthrough', [\n",
    "        'term_code',\n",
    "        'math',\n",
    "        'reading',\n",
    "        'writing',\n",
    "        'hs_pctl',\n",
    "        'appl_day',\n",
    "        'apdc_day',\n",
    "        'act_equiv',\n",
    "    ]),\n",
    "    ('false', SimpleImputer(strategy='constant', fill_value=False), [\n",
    "        'camp_main',\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        # 'fafsa_app',\n",
    "        'schlship_app',\n",
    "        # 'finaid_accepted',\n",
    "        'ssb',\n",
    "    ]),\n",
    "    ('0', SimpleImputer(strategy='constant', fill_value=0), [\n",
    "        'gap_score',\n",
    "    ]),\n",
    "    # ('n', SimpleImputer(strategy='constant', fill_value='n'), [\n",
    "    #     'oriented',\n",
    "    # ]),\n",
    "\n",
    "]\n",
    "\n",
    "# trf = make_pipeline(ColumnTransformer(feat,remainder='drop',verbose_feature_names_out = False), ft)\n",
    "# trf = ColumnTransformer(feat,remainder='drop',verbose_feature_names_out = False)\n",
    "# Z = trf.fit_transform(self.X).binarize()\n",
    "# # Z = Z.apply(f)\n",
    "# # Z.isnull().sum()\n",
    "# Z.dtypes\n",
    "self.X.fillna({c:'' for c in self.X.select_dtypes('string').columns}, inplace=True)\n",
    "self.X.select_dtypes('string').isnull().sum().disp(300)\n",
    "# self.X.select_dtypes('string').fillna('')\n",
    "# self.X.select_dtypes('string').isnull().sum()\n",
    "\n",
    "# .fillna('')\n",
    "# Z\n",
    "# pd.api.types.is_string_dtype(Z['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('opeir.admissions_fall2022',2).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.waiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query(\"waiver.isnull()\").vc(['cycle_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.isnull().sum().disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt']['_total','n']['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in R[False]['rslt'].keys():\n",
    "    for b, v in R.items():\n",
    "        print(k, b)\n",
    "        v['rslt'][k]['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {k:v for k,v in R.items() if k[1]!='all'}.keys()\n",
    "R = {True:[], False:[]}\n",
    "for k,v in P.items():\n",
    "    R[k[1]=='all'].append(v)\n",
    "# q[True][0]['rslt'].keys()\n",
    "# for b,L in R.items():\n",
    "    # print(type(v))\n",
    "    # print(v[0]['rslt'].keys())\n",
    "\n",
    "S = {b: {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']} for b,L in R.items()}\n",
    "S[False]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def predict(self, crse='_total', train_term=202208, iterations=3, opts=dict()):\n",
    "    #     for styp_code in [\"n\",\"r\",\"t\",\"all\"]:\n",
    "    #         print(crse,train_term,styp_code, end=\": \")\n",
    "    #         prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "    #         for P in self.pred:\n",
    "    #             if P['meta'] == prediction['meta']:\n",
    "    #                 print('reusing')\n",
    "    #                 return P\n",
    "    #         print(f'creating')\n",
    "\n",
    "    #         d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "    #         end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "    #         Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "    #         T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "    #         if styp_code != \"all\":\n",
    "    #             T = T.query(\"styp_code==@styp_code\")\n",
    "    #         X = T.copy()\n",
    "    #         X.loc[X.eval(\"term_code!=@train_term or term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "    #         imp = ImputationKernel(X, **opts)\n",
    "    #         imp.mice(iterations)\n",
    "    #         # with warnings.catch_warnings(action='ignore'):\n",
    "    #         #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "    #         #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "    #         #     # imp.plot_correlations()\n",
    "\n",
    "    #         g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "    #         P = pd.concat([imp.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(imp.dataset_count())])\n",
    "    #         Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query('term_code != train_term').prep()\n",
    "    #         grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "    #         agg = lambda x: pd.Series({\n",
    "    #             'pred': x['pred'].sum(min_count=1),\n",
    "    #             'true': x['true'].sum(min_count=1),\n",
    "    #             'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    #             'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "    #         })\n",
    "    #         S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "    #         for x in ['pred','true']:\n",
    "    #             S[x] = S[x] * S['mlt']\n",
    "    #         S.insert(2, 'err', S['pred'] - S['true'])\n",
    "    #         S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "    #         prediction['rslt'] = {'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "    #         self.pred.append(prediction)\n",
    "    #         self.dump()\n",
    "    #     return prediction\n",
    "\n",
    "# class MM():\n",
    "#     def __init__(self, func, candidates):\n",
    "#         assert func in [mean_match_kdtree_classification, default_mean_match]\n",
    "#         self.func = func\n",
    "#         self.candidates = candidates\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return self.func(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return join([x for x in ['kdtree','default'] if x in self.func.__name__]+[self.candidates], \"_\")\n",
    "\n",
    "# class kdtree():\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return mean_match_kdtree_classification(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return 'kdtree__mean_match'\n",
    "\n",
    "# class default():\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return default_mean_match(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return 'default_mean_match'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = it.product(self.crse, ['n','r','t','all'])\n",
    "[[crse, styp_code, train_term] for crse, styp_code in Z for train_term in self.term_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = it.product(self.crse, ['n','r','t','all'])\n",
    "list(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    ('a','b'):7,\n",
    "    ('a','c'):71}\n",
    "d['a','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select\n",
    "        A.sfrstcr_term_code,\n",
    "        A.sfrstcr_pidm,\n",
    "        B.ssbsect_subj_code,\n",
    "        B.ssbsect_crse_numb,\n",
    "        B.ssbsect_credit_hrs,\n",
    "        A.sfrstcr_credit_hr\n",
    "from sfrstcr A, ssbsect B\n",
    "where\n",
    "        A.sfrstcr_term_code = B.ssbsect_term_code\n",
    "        and A.sfrstcr_crn = B.ssbsect_crn\n",
    "        and A.sfrstcr_term_code = 202308\n",
    "        and A.sfrstcr_ptrm_code not in ('28','R3')\n",
    "        and  trunc(to_date('18-Sep-23')) - trunc(A.sfrstcr_add_date) >= 197  -- added before cycle_day\n",
    "        and (trunc(to_date('18-Sep-23')) - trunc(A.sfrstcr_rsts_date) < 197 or A.sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "        and B.ssbsect_subj_code <> 'INST'\n",
    "        and A.sfrstcr_credit_hr <> B.ssbsect_credit_hrs\n",
    "\"\"\"\n",
    "db.head(qry, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"styp_code=='n' & pred_term!={self.infer}\"\n",
    "val = \"err%\"\n",
    "q=50\n",
    "P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "for _ in range(2):\n",
    "    P = (P.assign(mean=lambda x:x.mean(axis=1)) if P.shape[1] > 1 else P).T\n",
    "P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdtree = mean_match_kdtree_classification\n",
    "kdtree.__name__ = 'a'\n",
    "setattr(kdtree,'__str__','a')\n",
    "setattr(kdtree,'__repr__','a')\n",
    "\n",
    "print(kdtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "class MM():\n",
    "    def __init__(self, func, candidates):\n",
    "        self.func = func\n",
    "        self.candidates = candidates\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    def __str__(self):\n",
    "        return join([x for x in ['kdtree','deafult'] if x in self.func.__name__]+[self.candidates], \"_\")\n",
    "\n",
    "mm = MM(mean_match_kdtree_classification, 3)\n",
    "print(mm)\n",
    "# type(mean_match_kdtree_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_match_kdtree_classification.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = default_mean_match\n",
    "x.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # A[styp_code] = {\n",
    "            #     'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "            #     **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "\n",
    "\n",
    "\n",
    "    # R = {styp_code: {\n",
    "    #         'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "    #         **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "    #     } for styp_code in [\"n\"]}\n",
    "\n",
    "        # R['n']['proj'].disp(100)\n",
    "        # R['n']['err%'].disp(100)\n",
    "# B = (\n",
    "#     A['summary']\n",
    "#     .grpby(['crse','styp_code','train_term','pred_term'])\n",
    "#     # .grpby(['crse','styp_code','pred_term'])\n",
    "#     [['pred','err%','mse%','f1_inv%']]\n",
    "#     .agg(summary)\n",
    "#     .stack(0, sort=False)\n",
    "#     .rename_axis(index={None:'kind'})\n",
    "#     .query(f\"(pred_term == {self.infer} and kind == 'pred') or (pred_term != {self.infer} and kind == 'err%')\")\n",
    "#     .reset_index()\n",
    "#     # .sort_values(['crse','styp_code','pred_term','train_term'],ascending=[True,True,False,False])\n",
    "#     .prep()\n",
    "# )\n",
    "# M = A['summary'].query(\"pred_term != @self.infer & styp_code=='n'\").pivot_table(index='train_term', columns='pred_term', values='err%', margins=True)\n",
    "# M.disp(10)\n",
    "# B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R['n']['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {k: pd.concat([p['rslt'][k] for p in P]) for k in ['full','summary']}\n",
    "def pivot(qry, val, q=50):\n",
    "    P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q), margins=True, margins_name='mean')\n",
    "    for _ in range(2):\n",
    "        P = (P.head(1) if P.shape[0] == 2 else P).T\n",
    "    return P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n",
    "\n",
    "R = {styp_code: {\n",
    "    'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "    **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "} for styp_code in [\"n\"]}\n",
    "\n",
    "R['n']['proj'].disp(100)\n",
    "R['n']['err%'].disp(100)\n",
    "# }}\n",
    "# projections = pd.concat([piv(\"pred_term == @self.infer & styp_code=='n'\", 'pred', q) for q in [25,50,75]], axis=1)\n",
    "# errors = piv(\"pred_term != @self.infer & styp_code=='n'\", 'err%', 50)\n",
    "# Q\n",
    "# M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(p):\n",
    "    f = lambda x: x.quantile(p/100)\n",
    "    f.__name__ = f'{p}%'\n",
    "    f.__str__ = f'{p}%'\n",
    "    f.__repr__ = f'{p}%'\n",
    "    return f\n",
    "print(f\"{g(25)}\")\n",
    "display(f)\n",
    "str(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pctl(50)\n",
    "f.__repr__ = 'a'\n",
    "f.__str__ = 'a'\n",
    "f'{f}'\n",
    "# print(f)\n",
    "# f.__qualname__\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pctl(50)\n",
    "hasattr(w, '__name__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'hi'\n",
    "# x.__name__ = x\n",
    "hasattr(x, '__name__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piv(qry, val, q=50):\n",
    "    P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q), margins=True, margins_name='mean')\n",
    "    for _ in range(2):\n",
    "        P = (P.head(1) if P.shape[0] == 2 else P).T\n",
    "    return P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n",
    "A = {k: pd.concat([p['rslt'][k] for p in P]) for k in ['full','summary']}\n",
    "Q = pd.concat([piv(\"pred_term == @self.infer & styp_code=='n'\", 'pred', q) for q in [25,50,75]], axis=1)\n",
    "M = piv(\"pred_term != @self.infer & styp_code=='n'\", 'err%', 50)\n",
    "Q\n",
    "M\n",
    "# q = Q[0]\n",
    "# q\n",
    "# Q[0]\n",
    "# piv(\"styp_code=='n'\", 'err%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.T.assign(a=50).set_index('a', append=True).swaplevel(0,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Q[0]\n",
    "A.rename('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = (\n",
    "    A['summary']\n",
    "    .grpby(['crse','styp_code','train_term','pred_term'])\n",
    "    [['pred','err%','mse%','f1_inv%']]\n",
    "    .agg(summary)\n",
    "    .stack(0, sort=False)\n",
    "    .rename_axis(index={None:'kind'})\n",
    "    .query(f\"(pred_term == {self.infer} and kind == 'pred') or (pred_term != {self.infer} and kind == 'err%')\")\n",
    "    .reset_index()\n",
    "    # .sort_values(['crse','styp_code','pred_term','train_term'],ascending=[True,True,False,False])\n",
    "    .prep()\n",
    ")\n",
    "\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = A['summary'].query(\"pred_term!=202408 & styp_code=='n'\")['err%'].groupby(['train_term','pred_term']).mean().reset_index()#.unstack()\n",
    "# M.pivot_table(index='train_term',columns='pred_term', margins=True)\n",
    "\n",
    "# M\n",
    "A['summary'].reset_index().query(\"pred_term!=202408 & styp_code=='n'\").pivot_table(index='train_term', columns='pred_term', values='err%', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.disp(10)\n",
    "B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = self.Z.vc('term_code')\n",
    "v = t.values\n",
    "pd.DataFrame((v / v.T - 1) * 100, index=t.index, columns=t.index).round().prep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sort_values(['train_term','pred_term'], ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.disp(10)\n",
    "B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A['summary'].query(\"pred_term!=202408 & styp_code=='n' & pred_term!=train_term\")['err%'].groupby(['train_term','pred_term']).mean().unstack()\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary'].disp(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "    # self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False))\n",
    "# agg = lambda y, g: y.groupby(g)[['credit_hr']].sum()\n",
    "# grp = ['styp_code','term_code','crse']\n",
    "# end = agg(where(self.Y[0]), grp)\n",
    "# self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "# cur = agg(self.Y[0], grp)\n",
    "# M = (end / cur).query(\"term_code != @self.infer\")\n",
    "# N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "# self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "# return self.dump()\n",
    "\n",
    "agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "grp = ['levl_code','styp_code','term_code','crse']\n",
    "end = agg(self.Y[0], grp)\n",
    "self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "cur = agg(self.Y[0], grp)\n",
    "M = (end / cur).query(\"term_code != @self.infer\")\n",
    "M\n",
    "# agg(self.Y[0], grp).disp(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
