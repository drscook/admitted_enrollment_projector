{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trf': {'act_equiv': 'passthrough', 'apdc_day': 'passthrough', 'appl_day': 'passthrough', 'birth_day': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('powertransformer', PowerTransformer())]), 'coll_code': 'drop', 'distance': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('powertransformer', PowerTransformer())]), 'gap_score': 'passthrough', 'gender': 'passthrough', 'hs_qrtl': 'passthrough', 'international': 'drop', 'lgcy': 'passthrough', 'math': 'passthrough', 'oriented': 'passthrough', 'race_american_indian': 'passthrough', 'race_asian': 'passthrough', 'race_black': 'passthrough', 'race_hispanic': 'passthrough', 'race_pacific': 'passthrough', 'race_white': 'passthrough', 'reading': 'passthrough', 'remote': 'drop', 'resd': 'passthrough', 'schlship_app': 'passthrough', 'ssb': 'passthrough', 'waiver': 'passthrough', 'writing': 'passthrough'}, 'imp': {'datasets': 5, 'iterations': 4, 'mmc': 1, 'mmf': 'mean_match_default'}}\n",
      "creating _total   202008 n\n",
      "{'datasets': 5, 'mean_match_scheme': <miceforest.MeanMatchScheme.MeanMatchScheme object at 0x7f65226a2cd0>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__act_equiv</th>\n",
       "      <th>__distance</th>\n",
       "      <th>__hs_qrtl</th>\n",
       "      <th>_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>__act_equiv</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.835650</td>\n",
       "      <td>10.852130</td>\n",
       "      <td>13.223831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__apdc_day</th>\n",
       "      <td>4.570723</td>\n",
       "      <td>18.872596</td>\n",
       "      <td>11.553885</td>\n",
       "      <td>13.195991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__appl_day</th>\n",
       "      <td>14.237183</td>\n",
       "      <td>18.625024</td>\n",
       "      <td>7.167920</td>\n",
       "      <td>13.001114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__birth_day</th>\n",
       "      <td>5.435454</td>\n",
       "      <td>16.911065</td>\n",
       "      <td>3.233083</td>\n",
       "      <td>11.943207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__distance</th>\n",
       "      <td>9.326745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.844612</td>\n",
       "      <td>18.429844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__gap_score</th>\n",
       "      <td>8.214947</td>\n",
       "      <td>4.037326</td>\n",
       "      <td>20.551378</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__gender</th>\n",
       "      <td>6.701668</td>\n",
       "      <td>1.752047</td>\n",
       "      <td>4.411028</td>\n",
       "      <td>1.475501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__hs_qrtl</th>\n",
       "      <td>6.053119</td>\n",
       "      <td>3.008951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.814031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__lgcy</th>\n",
       "      <td>0.988264</td>\n",
       "      <td>1.333079</td>\n",
       "      <td>3.859649</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__math</th>\n",
       "      <td>7.072267</td>\n",
       "      <td>0.971244</td>\n",
       "      <td>3.157895</td>\n",
       "      <td>2.004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__oriented</th>\n",
       "      <td>4.261890</td>\n",
       "      <td>1.294991</td>\n",
       "      <td>3.909774</td>\n",
       "      <td>4.370824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__race_american_indian</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__race_asian</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__race_black</th>\n",
       "      <td>1.019148</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>0.075188</td>\n",
       "      <td>0.835189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__race_hispanic</th>\n",
       "      <td>3.736875</td>\n",
       "      <td>2.628071</td>\n",
       "      <td>2.932331</td>\n",
       "      <td>3.981069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__race_pacific</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__race_white</th>\n",
       "      <td>4.014824</td>\n",
       "      <td>1.866311</td>\n",
       "      <td>0.852130</td>\n",
       "      <td>2.978842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__reading</th>\n",
       "      <td>3.026560</td>\n",
       "      <td>0.666540</td>\n",
       "      <td>1.829574</td>\n",
       "      <td>0.445434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__resd</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.837555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__schlship_app</th>\n",
       "      <td>2.655960</td>\n",
       "      <td>1.866311</td>\n",
       "      <td>1.929825</td>\n",
       "      <td>4.259465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__ssb</th>\n",
       "      <td>2.625077</td>\n",
       "      <td>1.447343</td>\n",
       "      <td>1.829574</td>\n",
       "      <td>4.927617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__waiver</th>\n",
       "      <td>6.856084</td>\n",
       "      <td>3.199391</td>\n",
       "      <td>8.370927</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__writing</th>\n",
       "      <td>3.953057</td>\n",
       "      <td>1.314035</td>\n",
       "      <td>2.130326</td>\n",
       "      <td>0.946548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_total_cur</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_total</th>\n",
       "      <td>5.250154</td>\n",
       "      <td>3.351743</td>\n",
       "      <td>3.508772</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from LiveAMP import *\n",
    "import miceforest as mf\n",
    "# from miceforest import ImputationKernel, mean_match_default, mean_match_fast_cat, mean_match_shap\n",
    "from sklearn.base import clone, BaseEstimator\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer, KBinsDiscretizer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge, Ridge\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, iteration=None, normalize=True):\n",
    "    targ = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    feat = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=targ, columns=feat).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "mf.ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "def inspect(self, **kwargs):\n",
    "    self.plot_imputed_distributions(wspace=0.3,hspace=0.3)\n",
    "    self.plot_mean_convergence(wspace=0.3, hspace=0.4)\n",
    "    I = self.feature_importance_df(**kwargs)\n",
    "    I.disp(100)\n",
    "    return I\n",
    "mf.ImputationKernel.inspect = inspect\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer_term: int\n",
    "    crse: typing.List\n",
    "    attr: typing.List\n",
    "    fill: typing.Dict = None\n",
    "    trf_grid: typing.Dict = None\n",
    "    imp_grid: typing.Dict = None\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'raw_df':False, 'reg_df':False, 'X':False, 'Y':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.overwrite['raw_df'] |= self.overwrite['term']\n",
    "        self.overwrite['reg_df'] |= self.overwrite['term']\n",
    "        self.overwrite['X'] |= self.overwrite['raw_df']\n",
    "        self.overwrite['Y'] |= self.overwrite['reg_df'] | self.overwrite['X']\n",
    "        self.overwrite['pred'] |= self.overwrite['Y']\n",
    "        self.path = root_path / f\"resources/rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "\n",
    "        for k in ['fill','term','pred','trf_grid','imp_grid']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        self.term_codes = uniquify([*listify(self.term_codes), self.infer_term])\n",
    "        self.crse = uniquify(['_total', *listify(self.crse)])\n",
    "        self.mlt_grp = ['crse','levl_code','styp_code','term_code']\n",
    "        # def g(X):\n",
    "        #     X = [listify(x) for x in X]\n",
    "        #     return {x.pop(0): x if x else [np.nan] for x in X}\n",
    "        # L = [g(self.attr), g(self.feat)]\n",
    "        # self.imp = L[0] | L[1]\n",
    "        # self.attr, self.feat = [list(x.keys()) for x in L]\n",
    "        self.trf_list = cartesian({k: sorted(setify(v), key=str) for k,v in self.trf_grid.items()})\n",
    "        self.imp_list = cartesian(self.imp_grid)\n",
    "        self.params_list = [{'trf':trf, 'imp':imp} for trf, imp in it.product(self.trf_list,self.imp_list)]\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def preprocess(self):\n",
    "        def get(nm):\n",
    "            if nm in self:\n",
    "                return False\n",
    "            print(f'get {nm}')\n",
    "            return True\n",
    "\n",
    "        if get('raw_df'):\n",
    "            self.raw_df = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "\n",
    "        if get('reg_df'):\n",
    "            with warnings.catch_warnings(action='ignore'):\n",
    "                self.reg_df = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]) for k in ['cur','end']}\n",
    "\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        if get('X'):\n",
    "            R = self.raw_df.copy()\n",
    "            repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "            R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "            R['remote'] = R['camp_code'] != 's'\n",
    "            R['resd'] = R['resd_code'] == 'r'\n",
    "            R['lgcy'] = ~R['lgcy_code'].isin(['n','o'])\n",
    "            R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "            R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm', '00':pd.NA})\n",
    "            R['coll_desc'] = R['coll_desc'].replace({\n",
    "                'ag & environmental sciences':'ag & natural resources',\n",
    "                'education & human development':'education',\n",
    "                'health science & human service':'health sciences',\n",
    "                'science & technology':'science & mathematics'})\n",
    "            majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "            S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "            X = where(R.drop(columns=majr).merge(S, on='majr_code', how='left')).prep().binarize()\n",
    "\n",
    "            checks = [\n",
    "                'cycle_day >= 0',\n",
    "                'apdc_day >= cycle_day',\n",
    "                'appl_day >= apdc_day',\n",
    "                'birth_day >= appl_day',\n",
    "                'birth_day >= 5000',\n",
    "                'distance >= 0',\n",
    "                'hs_pctl >=0',\n",
    "                'hs_pctl <= 100',\n",
    "                'hs_qrtl >= 0',\n",
    "                'hs_qrtl <= 4',\n",
    "                'act_equiv >= 1',\n",
    "                'act_equiv <= 36',\n",
    "                'gap_score >= 0',\n",
    "                'gap_score <= 100',\n",
    "            ]\n",
    "            for check in checks:\n",
    "                mask = X.eval(check)\n",
    "                assert mask.all(), [check,X[~mask].disp(5)]\n",
    "\n",
    "            for k, v in self.fill.items():\n",
    "                X[k] = X.impute(k, *listify(v))\n",
    "\n",
    "            self.X = X.prep().binarize().set_index(self.attr, drop=False).rename(columns=lambda x:'__'+x)\n",
    "            self.X.missing().disp(100)\n",
    "\n",
    "        if get('Y'):\n",
    "            self.Y = {k: self.X[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in self.reg_df.items()}\n",
    "            agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "            A = agg(self.reg_df['end'])\n",
    "            B = agg(self.Y['end'])\n",
    "            M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(f\"term_code != {self.infer_term}\").prep()\n",
    "            N = M.assign(term_code=self.infer_term)\n",
    "            self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "            Y = {k: y.squeeze().unstack().dropna(how='all', axis=1).fillna(0) for k, y in self.Y.items()}\n",
    "            self.Y = Y['cur'].rename(columns=lambda x:x+'_cur').join(Y['end']>0).prep()\n",
    "        return self.dump()\n",
    "\n",
    "   \n",
    "    # def predict(self, params, crse, train_term, styp_code='all'):\n",
    "    #     for step in ['imp','enc','clf']:\n",
    "    #         params.setdefault(step, dict())\n",
    "    #     for p, P in self.pred.items():\n",
    "    #         if p == stringify(params):\n",
    "    #             for c, C in P.items():\n",
    "    #                 if c == crse:\n",
    "    #                     for t, T in C.items():\n",
    "    #                         if t == train_term:\n",
    "    #                             for s, S in T.items():\n",
    "    #                                 if s == styp_code:\n",
    "    #                                     # print('reusing')\n",
    "    #                                     return S\n",
    "\n",
    "    #     X = self.X.copy()\n",
    "    #     if styp_code != 'all':\n",
    "    #         X = X.query(f\"styp_code==@styp_code\")\n",
    "\n",
    "    #     imp_str = stringify({'imp':params['imp']})\n",
    "    #     X_imputed = None\n",
    "    #     for i, I in self.imputed.items():\n",
    "    #         if i == imp_str:\n",
    "    #             for s, S in I.items():\n",
    "    #                 if s == styp_code:\n",
    "    #                     # print('reusing imputed data')\n",
    "    #                     X_imputed = S\n",
    "\n",
    "    #     if X_imputed is None:\n",
    "    #         print('imputing')\n",
    "    #         p = params['imp'].copy()\n",
    "    #         # p = params.pop('imp')\n",
    "    #         iterations = p[1].pop('iterations') if 'iterations' in p[1] else 5\n",
    "    #         print(iterations, p[1])\n",
    "    #         imp = p[0](X, **p[1])\n",
    "    #         imp.mice(iterations)\n",
    "    #         X_imputed = [imp.complete_data(k) for k in range(imp.dataset_count())]\n",
    "    #         self.imputed.setdefault(imp_str, dict()).update({styp_code: X_imputed})\n",
    "    #         self.dump()\n",
    "    #         imp.inspect()\n",
    "\n",
    "    #     print('creating', ljust(crse,8), train_term, styp_code)#, stringify(params))\n",
    "    #     cols = uniquify(['_total_cur',crse+'_cur',crse])\n",
    "    #     S = dict()\n",
    "    #     for k, X in enumerate(X_imputed):\n",
    "    #         Z = X.join(self.Y[cols]).sort_index()\n",
    "    #         Z.missing().disp(100)\n",
    "    #         c = params['clf'].copy()\n",
    "    #         if c[0].__name__ != 'ImputationKernel':\n",
    "    #             enc = ColumnTransformer([('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist', **params['enc'][1]), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)\n",
    "    #             T = enc.fit_transform(Z)\n",
    "    #             T.missing().disp(100)\n",
    "    #             X = {'test': T, 'train': T.query(f\"term_code==@train_term\")}\n",
    "    #             y = {k: x.pop(crse) for k, x in X.items()}\n",
    "    #             model = c[0](**c[1]).fit(X['train'], y['train'])\n",
    "    #             pred = model.predict(X['test'])\n",
    "    #         else:\n",
    "    #             iterations = c[1].pop('iterations') if 'iterations' in c[1] else 5\n",
    "    #             T = Z.copy()\n",
    "    #             T.loc[T.eval(\"term_code!=@train_term\"), crse] = pd.NA\n",
    "    #             model = c[0](T, datasets=1, **c[1])\n",
    "    #             model.mice(1)\n",
    "    #             optimal_parameters, losses = model.tune_parameters(dataset=0, optimization_steps=5)\n",
    "    #             model.mice(iterations, variable_parameters=optimal_parameters)\n",
    "    #             model.inspect()\n",
    "    #             T.loc[:, crse] = pd.NA\n",
    "    #             pred = model.impute_new_data(T).complete_data(0).pop(crse)\n",
    "                \n",
    "    #         details = (\n",
    "    #             Z[crse]\n",
    "    #             .rename('true')\n",
    "    #             .to_frame()\n",
    "    #             .assign(pred=pred, train_term=train_term, crse=crse, sim=k)\n",
    "    #             .set_index(['train_term','crse','sim'], append=True)\n",
    "    #             .binarize()\n",
    "    #         )\n",
    "    #         agg = lambda x: pd.Series({\n",
    "    #             'pred': x['pred'].sum(min_count=1),\n",
    "    #             'true': x['true'].sum(min_count=1),\n",
    "    #             'mse_pct': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    #             'f1_inv_pct': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "    #         })\n",
    "    #         summary = details.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "    #         for x in ['pred','true']:\n",
    "    #             summary[x] = summary[x] * summary['mlt']\n",
    "    #         summary.insert(2, 'err', summary['pred'] - summary['true'])\n",
    "    #         summary.insert(3, 'err_pct', (summary['err'] / summary['true']).clip(-1, 1) * 100)\n",
    "    #         S[k] = {'details':details.copy(), 'summary':summary.copy().drop(columns='mlt').prep(), 'model':model}\n",
    "    #     return S\n",
    "\n",
    "    def analyze(self):\n",
    "        def pivot(df, val):\n",
    "            Y = (\n",
    "                df\n",
    "                .reset_index()\n",
    "                .pivot_table(columns='train_term', index=['crse','styp_code','pred_term'], values=val, aggfunc=[pctl(0),pctl(25),pctl(50),pctl(75),pctl(100)])\n",
    "                .rename_axis(columns=[val,'train_term'])\n",
    "                .stack(0)\n",
    "                .assign(abs_mean = lambda x: x.abs().mean(axis=1))\n",
    "            )\n",
    "            return Y\n",
    "\n",
    "        for k, v in self.pred.items():\n",
    "            print(k)\n",
    "            df = v['summary']\n",
    "            mask = df.eval(f\"pred_term!={self.infer_term}\")\n",
    "            v['rslt'] = {stat: pivot(df[mask], stat) for stat in [\"pred\",\"err\",\"err_pct\",\"mse_pct\",\"f1_inv_pct\"]} | {'pred': pivot(df[~mask], \"pred\")}\n",
    "            v['rslt']['err_pct'].query(\"err_pct==' 50%'\").disp(200)\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def main(self):\n",
    "        self = self.preprocess()\n",
    "        g = lambda Y: Y | {k: pd.concat([y[k] for y in Y.values() if k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "        for params in self.params_list:\n",
    "            P = dict()\n",
    "            print(str(params))\n",
    "            for crse in self.crse:\n",
    "                C = dict()\n",
    "                for train_term in self.term_codes:\n",
    "                    T = dict()\n",
    "                    for styp_code in ['n']:#,'r','t']:\n",
    "                        S = self.predict(params, crse, train_term, styp_code)\n",
    "                        return S\n",
    "                        T[styp_code] = g(S)\n",
    "                    C[train_term] = g(T)\n",
    "                P[crse] = g(C)\n",
    "            self.pred[str(params)] = g(P) | {'params':params}\n",
    "            self.dump()\n",
    "        return self.analyze()\n",
    "    \n",
    "    \n",
    "    def predict(self, params, crse, train_term, styp_code='all'):\n",
    "        for p, P in self.pred.items():\n",
    "            if p == str(params):\n",
    "                for c, C in P.items():\n",
    "                    if c == crse:\n",
    "                        for t, T in C.items():\n",
    "                            if t == train_term:\n",
    "                                for s, S in T.items():\n",
    "                                    if s == styp_code:\n",
    "                                        return S\n",
    "\n",
    "        print('creating', ljust(crse,8), train_term, styp_code)\n",
    "        X = self.X.copy()\n",
    "        if styp_code != 'all':\n",
    "            X = X.query(f\"styp_code==@styp_code\")\n",
    "        trf = ColumnTransformer([(c,t,[\"__\"+c]) for c,t in params['trf'].items()], remainder='drop', verbose_feature_names_out=False)\n",
    "        cols = uniquify(['_total_cur',crse+'_cur',crse])\n",
    "        Z = trf.fit_transform(X).join(self.Y[cols]).prep().categorize().sort_index()\n",
    "        y = Z[crse].copy().rename('true').to_frame()\n",
    "        Z.loc[Z.eval(\"term_code!=@train_term\"), crse] = pd.NA\n",
    "        iterations = params['imp'].pop('iterations') if 'iterations' in params['imp'] else 3\n",
    "        mmc = params['imp'].pop('mmc') if 'mmc' in params['imp'] else 0\n",
    "        if mmc > 0 and 'mmf' in params['imp']:\n",
    "            mms = getattr(mf, params['imp'].pop('mmf')).copy()\n",
    "            mms.set_mean_match_candidates(mmc)\n",
    "            params['imp']['mean_match_scheme'] = mms\n",
    "        imp = mf.ImputationKernel(Z, **params['imp'])\n",
    "        imp.mice(1)\n",
    "        optimal_parameters, losses = imp.tune_parameters(dataset=0, optimization_steps=5)\n",
    "        imp.mice(iterations, variable_parameters=optimal_parameters)\n",
    "        imp.inspect()\n",
    "        Z.loc[:, crse] = pd.NA\n",
    "        P = imp.impute_new_data(Z)\n",
    "        return P\n",
    "        # P = pd.concat([P.complete])\n",
    "        # P = imp.impute_new_data(Z).complete_data(0).pop(crse)\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "passthru = ['passthrough']\n",
    "passdrop = ['passthrough', 'drop']\n",
    "bintrf = lambda n_bins: KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform', subsample=None)\n",
    "pwrtrf = make_pipeline(StandardScaler(), PowerTransformer())\n",
    "kwargs = {\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'infer_term': 202408,\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    'fill': {\n",
    "        'birth_day': ['median',['term_code','styp_code']],\n",
    "        'remote': False,\n",
    "        'international': False,\n",
    "        **{f'race_{r}': False for r in ['american_indian','asian','black','pacific','white','hispanic']},\n",
    "        'lgcy': False,\n",
    "        'resd': False,\n",
    "        'waiver': False,\n",
    "        'fafsa_app': False,\n",
    "        'schlship_app': False,\n",
    "        'finaid_accepted': False,\n",
    "        'ssb': False,\n",
    "        'math': False,\n",
    "        'reading': False,\n",
    "        'writing': False,\n",
    "        'gap_score': 0,\n",
    "        'oriented': 'n',\n",
    "    },\n",
    "    'attr': [\n",
    "        # 'index',\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        *code_desc('resd'),\n",
    "        *code_desc('lgcy'),\n",
    "        'international',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_qrtl',\n",
    "    ],\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    # 'cycle_day': 187,\n",
    "    'crse': [\n",
    "        # 'engl1301',\n",
    "        # 'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'trf_grid': {\n",
    "        'appl_day': passthru,\n",
    "        'apdc_day': passthru,\n",
    "        'birth_day': [*passthru, pwrtrf],#, bintrf(5)],\n",
    "        # 'levl_code': passthru,\n",
    "        # 'styp_code': passthru,\n",
    "        # 'admt_code': passdrop,\n",
    "        # 'camp_code': passdrop,\n",
    "        'remote': passdrop,\n",
    "        'coll_code': passdrop,\n",
    "        'international': passdrop,\n",
    "        **{f'race_{r}': passthru for r in ['american_indian','asian','black','pacific','white','hispanic']},\n",
    "        'gender': passthru,\n",
    "        'lgcy': passthru,\n",
    "        'resd': passthru,\n",
    "        'waiver': passthru,\n",
    "        # 'fafsa_app': passthru,\n",
    "        'schlship_app': passthru,\n",
    "        # 'finaid_accepted': passthru,\n",
    "        'ssb': passthru,\n",
    "        'math': passthru,\n",
    "        'reading': passthru,\n",
    "        'writing': passthru,\n",
    "        'gap_score': passthru,\n",
    "        'oriented': passthru,\n",
    "        'hs_qrtl': passthru,\n",
    "        'act_equiv': passthru,\n",
    "        'distance': [*passthru, pwrtrf],#, bintrf(5)],\n",
    "        },\n",
    "    'imp_grid': {\n",
    "        'datasets': 5,\n",
    "        'mmc': [1, 5],\n",
    "        'mmf': ['mean_match_default', 'mean_match_shap'],\n",
    "        'iterations':4,\n",
    "    },\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'raw_df': True,\n",
    "        # 'reg_df': True,\n",
    "        # 'X': True,\n",
    "        # 'Y': True,\n",
    "        # 'pred': True,\n",
    "    },\n",
    "}\n",
    "\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "self = self.preprocess()\n",
    "Z = self.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157975, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.concat([Z.complete_data(k) for k in range(Z.dataset_count())])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImputationKernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvariable_schema\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mimputation_order\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ascending'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_nonmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmean_match_scheme\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmiceforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanMatchScheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanMatchScheme\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata_subset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minitialization\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msave_all_iterations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msave_models\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcopy_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msave_loggers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Creates a kernel dataset. This dataset can perform MICE on itself,\n",
      "and impute new data from models obtained during MICE.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data : np.ndarray or pandas DataFrame.\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        The data to be imputed.\n",
      "\n",
      "variable_schema : None or list or dict, default=None\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        Specifies the feature - target relationships used to train models.\n",
      "        This parameter also controls which models are built. Models can be built\n",
      "        even if a variable contains no missing values, or is not being imputed\n",
      "        (train_nonmissing must be set to True).\n",
      "\n",
      "            - If None, all columns will be used as features in the training of each model.\n",
      "            - If list, all columns in data are used to impute the variables in the list\n",
      "            - If dict the values will be used to impute the keys. Can be either column\n",
      "                indices or names (if data is a pd.DataFrame).\n",
      "\n",
      "        No models will be trained for variables not specified by variable_schema\n",
      "        (either by None, a list, or in dict keys).\n",
      "\n",
      "imputation_order: str, list[str], list[int], default=\"ascending\"\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        The order the imputations should occur in. If a string from the\n",
      "        items below, all variables specified by variable_schema with\n",
      "        missing data are imputed:\n",
      "            ascending: variables are imputed from least to most missing\n",
      "            descending: most to least missing\n",
      "            roman: from left to right in the dataset\n",
      "            arabic: from right to left in the dataset.\n",
      "        If a list is provided:\n",
      "            - the variables will be imputed in that order.\n",
      "            - only variables with missing values should be included in the list.\n",
      "            - must be a subset of variables specified by variable_schema.\n",
      "        If a variable with missing values is in variable_schema, but not in\n",
      "        imputation_order, then models to impute that variable will be trained,\n",
      "        but the actual values will not be imputed. See examples for details.\n",
      "\n",
      "train_nonmissing: boolean\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        Should models be trained for variables with no missing values? Useful if you\n",
      "        expect you will need to impute new data which will have missing values, but\n",
      "        the training data is fully recognized.\n",
      "\n",
      "        If True, parameters are interpreted like so:\n",
      "            - models are run for all variables specified by variable_schema\n",
      "            - if variable_schema is None, models are run for all variables\n",
      "            - each iteration, models build for fully recognized variables are\n",
      "                always trained after the models trained during mice.\n",
      "            - imputation_order does not have any affect on fully recognized\n",
      "                variable model training.\n",
      "\n",
      "        WARNING: Setting this to True without specifying a variable schema will build\n",
      "        models for all variables in the dataset, whether they have missing values or\n",
      "        not. This may or may not be what you want.\n",
      "\n",
      "data_subset: None or int or float or dict.\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        Subsets the data used in each iteration, which can save a significant amount of time.\n",
      "        This can also help with memory consumption, as the candidate data must be copied to\n",
      "        make a feature dataset for lightgbm.\n",
      "\n",
      "        The number of rows used for each variable is (# rows in raw data) - (# missing variable values)\n",
      "        for each variable. data_subset takes a random sample of this.\n",
      "\n",
      "        If float, must be 0.0 < data_subset <= 1.0. Interpreted as a percentage of available candidates\n",
      "        If int must be data_subset >= 0. Interpreted as the number of candidates.\n",
      "        If 0, no subsetting is done.\n",
      "        If dict, keys must be variable names, and values must follow two above rules.\n",
      "\n",
      "        It is recommended to carefully select this value for each variable if dealing\n",
      "        with very large data that barely fits into memory.\n",
      "\n",
      "mean_match_scheme: Dict, default = None\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        An instance of the miceforest.MeanMatchScheme class.\n",
      "\n",
      "        If None is passed, a sensible default scheme is used. There are multiple helpful\n",
      "        schemes that can be accessed from miceforest.builtin_mean_match_schemes, or\n",
      "        you can build your own.\n",
      "\n",
      "        A description of the defaults:\n",
      "        - mean_match_default (default, if mean_match_scheme is None))\n",
      "            This scheme is has medium speed and accuracy for most data.\n",
      "\n",
      "            Categorical:\n",
      "                If mmc = 0, the class with the highest probability is chosen.\n",
      "                If mmc > 0, get N nearest neighbors from class probabilities.\n",
      "                    Select 1 at random.\n",
      "            Numeric:\n",
      "                If mmc = 0, the predicted value is used\n",
      "                If mmc > 0, obtain the mmc closest candidate\n",
      "                    predictions and collect the associated\n",
      "                    real candidate values. Choose 1 randomly.\n",
      "\n",
      "        - mean_match_shap\n",
      "            This scheme is the most accurate, but takes the longest.\n",
      "            It works the same as mean_match_default, except all nearest\n",
      "            neighbor searches are performed on the shap values of the\n",
      "            predictions, instead of the predictions themselves.\n",
      "\n",
      "        - mean_match_scheme_fast_cat:\n",
      "            This scheme is faster for categorical variables,\n",
      "            but may be less accurate as well..\n",
      "\n",
      "            Categorical:\n",
      "                If mmc = 0, the class with the highest probability is chosen.\n",
      "                If mmc > 0, return class based on random draw weighted by\n",
      "                    class probability for each sample.\n",
      "            Numeric or binary:\n",
      "                If mmc = 0, the predicted value is used\n",
      "                If mmc > 0, obtain the mmc closest candidate\n",
      "                    predictions and collect the associated\n",
      "                    real candidate values. Choose 1 randomly.\n",
      "\n",
      "categorical_feature: str or list, default=\"auto\"\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        The categorical features in the dataset. This handling depends on class of impute_data:\n",
      "\n",
      "            pandas DataFrame:\n",
      "                - \"auto\": categorical information is inferred from any columns with\n",
      "                    datatype category or object.\n",
      "                - list of column names (or indices): Useful if all categorical columns\n",
      "                    have already been cast to numeric encodings of some type, otherwise you\n",
      "                    should just use \"auto\". Will throw an error if a list is provided AND\n",
      "                    categorical dtypes exist in data. If a list is provided, values in the\n",
      "                    columns must be consecutive integers starting at 0, as required by lightgbm.\n",
      "\n",
      "            numpy ndarray:\n",
      "                - \"auto\": no categorical information is stored.\n",
      "                - list of column indices: Specified columns are treated as categorical. Column\n",
      "                    values must be consecutive integers starting at 0, as required by lightgbm.\n",
      "\n",
      "initialization: str\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        \"random\" - missing values will be filled in randomly from existing values.\n",
      "        \"empty\" - lightgbm will start MICE without initial imputation\n",
      "\n",
      "save_all_iterations: boolean, optional(default=True)\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        Save all the imputation values from all iterations, or just\n",
      "        the latest. Saving all iterations allows for additional\n",
      "        plotting, but may take more memory\n",
      "\n",
      "save_models: int\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        Which models should be saved:\n",
      "            = 0: no models are saved. Cannot get feature importance or\n",
      "                impute new data.\n",
      "            = 1: only the last model iteration is saved. Can only get\n",
      "                feature importance of last iteration. New data is\n",
      "                imputed using the last model for all specified iterations.\n",
      "                This is only an issue if data is heavily Missing At Random.\n",
      "            = 2: all model iterations are saved. Can get feature importance\n",
      "                for any iteration. When imputing new data, each iteration is\n",
      "                imputed using the model obtained at that iteration in mice.\n",
      "                This allows for imputations that most closely resemble those\n",
      "                that would have been obtained in mice.\n",
      "\n",
      "copy_data: boolean (default = False)\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        Should the dataset be referenced directly? If False, this will cause\n",
      "        the dataset to be altered in place. If a copy is created, it is saved\n",
      "        in self.working_data. There are different ways in which the dataset\n",
      "        can be altered:\n",
      "\n",
      "        1) complete_data() will fill in missing values\n",
      "        2) To save space, mice() references and manipulates self.working_data directly.\n",
      "            If self.working_data is a reference to the original dataset, the original\n",
      "            dataset will undergo these manipulations during the mice process.\n",
      "            At the end of the mice process, missing values will be set back to np.NaN\n",
      "            where they were originally missing.\n",
      "\n",
      "save_loggers: boolean (default = False)\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        A logger is created each time mice() or impute_new_data() is called.\n",
      "        If True, the loggers are stored in a list ImputationKernel.loggers.\n",
      "        If you wish to start saving logs, call ImputationKernel.start_logging().\n",
      "        If you wish to stop saving logs, call ImputationKernel.stop_logging().\n",
      "\n",
      "random_state: None,int, or numpy.random.RandomState\n",
      "\n",
      "    .. code-block:: text\n",
      "\n",
      "        The random_state ensures script reproducibility. It only ensures reproducible\n",
      "        results if the same script is called multiple times. It does not guarantee\n",
      "        reproducible results at the record level, if a record is imputed multiple\n",
      "        different times. If reproducible record-results are desired, a seed must be\n",
      "        passed for each record in the random_seed_array parameter.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/my3.11/lib/python3.11/site-packages/miceforest/ImputationKernel.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "mf.ImputationKernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__act_equiv                Float64\n",
       "__apdc_day                   Int64\n",
       "__appl_day                   Int64\n",
       "__birth_day                Float64\n",
       "__distance                 Float64\n",
       "__gap_score                  Int64\n",
       "__gender                  category\n",
       "__hs_qrtl                    Int64\n",
       "__lgcy                     boolean\n",
       "__math                     boolean\n",
       "__oriented                category\n",
       "__race_american_indian     boolean\n",
       "__race_asian               boolean\n",
       "__race_black               boolean\n",
       "__race_hispanic            boolean\n",
       "__race_pacific             boolean\n",
       "__race_white               boolean\n",
       "__reading                  boolean\n",
       "__resd                     boolean\n",
       "__schlship_app             boolean\n",
       "__ssb                      boolean\n",
       "__waiver                   boolean\n",
       "__writing                  boolean\n",
       "_total_cur                   Int64\n",
       "_total                     boolean\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'trf': {'act_equiv': 'passthrough', 'apdc_day': 'passthrough', 'appl_day': 'passthrough', 'birth_day': KBinsDiscretizer(encode='ordinal', strategy='uniform'), 'coll_code': 'drop', 'distance': KBinsDiscretizer(encode='ordinal', strategy='uniform'), 'gap_score': 'passthrough', 'gender': 'passthrough', 'hs_qrtl': 'passthrough', 'international': 'drop', 'lgcy': 'passthrough', 'math': 'passthrough', 'oriented': 'passthrough', 'race_american_indian': 'passthrough', 'race_asian': 'passthrough', 'race_black': 'passthrough', 'race_hispanic': 'passthrough', 'race_pacific': 'passthrough', 'race_white': 'passthrough', 'reading': 'passthrough', 'remote': 'drop', 'resd': 'passthrough', 'schlship_app': 'passthrough', 'ssb': 'passthrough', 'waiver': 'passthrough', 'writing': 'passthrough'}, 'imp': {'datasets': 5, 'iterations': 4, 'mmc': 0, 'mmf': 'mean_match_default'}}\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 'passthrough'\n",
    "pd = ['passthrough', 'drop']\n",
    "bin = lambda n_bins: KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "pwt = make_pipeline(StandardScaler(), PowerTransformer())\n",
    "trf_grid = {\n",
    "    'appl_day': p,\n",
    "    'apdc_day': p,\n",
    "    'birth_day': [p, bin(5), pwt],\n",
    "    # 'levl_code': p,\n",
    "    # 'styp_code': p,\n",
    "    # 'admt_code': pd,\n",
    "    # 'camp_code': pd,\n",
    "    'remote': pd,\n",
    "    'coll_code': pd,\n",
    "    'international': pd,\n",
    "    **{f'race_{r}': p for r in ['american_indian','asian','black','pacific','white','hispanic']},\n",
    "    'gender': p,\n",
    "    'lgcy': p,\n",
    "    'resd': p,\n",
    "    'waiver': p,\n",
    "    # 'fafsa_app': p,\n",
    "    'schlship_app': p,\n",
    "    # 'finaid_accepted': p,\n",
    "    'ssb': p,\n",
    "    'math': p,\n",
    "    'reading': p,\n",
    "    'writing': p,\n",
    "    'gap_score': p,\n",
    "    'oriented': p,\n",
    "    'hs_qrtl': p,\n",
    "    'act_equiv': p,\n",
    "    'distance': [p, bin(5), pwt],\n",
    "    }\n",
    "trf_list = cartesian({k: sorted(setify(v), key=str) for k,v in trf_grid.items()})\n",
    "imp_grid = {\n",
    "    'datasets': 5,\n",
    "    'mmc': [0, 5],\n",
    "    'mmf': ['mean_match_default', 'mean_match_shap'],\n",
    "    'iterations':4,\n",
    "}\n",
    "imp_list = cartesian(imp_grid)\n",
    "\n",
    "params_list = [{'trf':trf, 'imp':imp} for trf, imp in it.product(trf_list,imp_list)]\n",
    "\n",
    "\n",
    "def predict(self, params, crse, train_term, styp_code='all'):\n",
    "        for p, P in self.pred.items():\n",
    "            if p == str(params):\n",
    "                for c, C in P.items():\n",
    "                    if c == crse:\n",
    "                        for t, T in C.items():\n",
    "                            if t == train_term:\n",
    "                                for s, S in T.items():\n",
    "                                    if s == styp_code:\n",
    "                                        return S\n",
    "\n",
    "    print('creating', ljust(crse,8), train_term, styp_code)\n",
    "    cols = uniquify(['_total_cur',crse+'_cur',crse])\n",
    "    S = dict()\n",
    "\n",
    "    X = self.X.copy()\n",
    "    if styp_code != 'all':\n",
    "        X = X.query(f\"styp_code==@styp_code\")\n",
    "    trf = ColumnTransformer([(c,t,[\"__\"+c]) for c,t in params['trf'].items()], remainder='drop', verbose_feature_names_out=False)\n",
    "    Z = trf.fit_transform(X).categorize().join(self.Y[cols]).sort_index()\n",
    "\n",
    "\n",
    "    model = c[0](T, datasets=1, **c[1])\n",
    "    model.mice(1)\n",
    "    optimal_parameters, losses = model.tune_parameters(dataset=0, optimization_steps=5)\n",
    "    model.mice(iterations, variable_parameters=optimal_parameters)\n",
    "    model.inspect()\n",
    "    T.loc[:, crse] = pd.NA\n",
    "    pred = model.impute_new_data(T).complete_data(0).pop(crse)\n",
    "\n",
    "\n",
    "    y['true'] = Z[crse].copy()\n",
    "    Z.loc[Z.eval(\"term_code!=@train_term\"), crse] = pd.NA\n",
    "    iterations = params['imp'].pop('iterations') if 'iterations' in params['imp'] else 3\n",
    "    params['imp']['mean_match_scheme'] = getattr(mf, params['imp'].pop('mmf')).copy()\n",
    "    params['imp']['mean_match_scheme'].set_mean_match_candidates(params['imp'].pop('mmc'))\n",
    "    imp = mf.ImputationKernel(Z, **params['imp'])\n",
    "    imp.mice(1)\n",
    "    optimal_parameters, losses = imp.tune_parameters(dataset=0, optimization_steps=5)\n",
    "    imp.mice(iterations, variable_parameters=optimal_parameters)\n",
    "    imp.inspect()\n",
    "    Z.loc[:, crse] = pd.NA\n",
    "    P = imp.impute_new_data(Z)\n",
    "    P = pd.concat([P.complete])\n",
    "    P = imp.impute_new_data(Z).complete_data(0).pop(crse)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# imp = cartesian(imp)\n",
    "# imp\n",
    "# def g(d):\n",
    "#     d['mean_match_scheme'] = getattr(mf, d.pop('mmf')).copy()\n",
    "#     d['mean_match_scheme'].set_mean_match_candidates(d.pop('mmc'))\n",
    "#     return d\n",
    "\n",
    "# imp = [g(d) for d in cartesian(imp)]\n",
    "# # imp\n",
    "# # # imp = \n",
    "# # str(imp[0])\n",
    "\n",
    "# str(imp[0]['mean_match_scheme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<miceforest.MeanMatchScheme.MeanMatchScheme at 0x7f220a524d10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from miceforest import mean_match_default\n",
    "import miceforest as mf\n",
    "getattr(mf, 'mean_match_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# params_grid = {\n",
    "#     'enc': {\n",
    "#         OneHotEncoder: {\n",
    "#             'min_frequency': [0.1],\n",
    "#         },\n",
    "#     },\n",
    "#     'imp': {\n",
    "#         ImputationKernel: {\n",
    "#             'datasets': 5,\n",
    "#             # 'save_all_iterations': False,\n",
    "#             # 'mean_match_candidates': [29],\n",
    "#             # 'mean_match_function': mean_match_kdtree_classification,\n",
    "#             'mean_match_scheme': [mmc(25)],\n",
    "#             'iterations':4,\n",
    "#         },\n",
    "#     },\n",
    "#     'clf': {\n",
    "#         # RandomForestClassifier: {\n",
    "#         #     'max_depth': 3,\n",
    "#         # },\n",
    "#         HistGradientBoostingClassifier: {\n",
    "#             'max_depth': 3,\n",
    "#         },\n",
    "#         # ImputationKernel: {\n",
    "#         #     'save_all_iterations': False,\n",
    "#         #     # 'mean_match_candidates': [29],\n",
    "#         #     # 'mean_match_function': mean_match_kdtree_classification,\n",
    "#         #     'iterations':3,\n",
    "#         # }\n",
    "#     },\n",
    "# }\n",
    "# params_list = cartesian({step: [[alg, values] for alg, grid in D.items() for values in cartesian(grid)] for step, D in params_grid.items()})\n",
    "# def stringify(P):\n",
    "#     def f(x):\n",
    "#         try:\n",
    "#             return x.__name__\n",
    "#         except:\n",
    "#             return x\n",
    "#     return str({f(step): [f(D[0]), {f(k): f(v) for k, v in D[1].items()}] for step, D in P.items()})\n",
    "\n",
    "# self.main(params_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler().\n",
    "HistGradientBoostingClassifier(random_state=45).__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trf = sorted([\n",
    "trf = mysort({\n",
    "    'appl_day': 'passthrough',\n",
    "    'apdc_day': 'drop',\n",
    "    # 'birth_day': 'passthrough',\n",
    "    'birth_day': make_pipeline(StandardScaler(), PowerTransformer()),\n",
    "    # 'levl_code': 'passthrough',\n",
    "    # 'styp_code': 'passthrough',\n",
    "    # 'admt_code': 'passthrough',\n",
    "    # 'camp_code': 'passthrough',\n",
    "    'remote': 'passthrough',\n",
    "    'coll_code': 'passthrough',\n",
    "    'international': 'passthrough',\n",
    "    **{f'race_{r}': 'passthrough' for r in ['american_indian','asian','black','pacific','white','hispanic']},\n",
    "    'gender': 'passthrough',\n",
    "    'lgcy': 'passthrough',\n",
    "    'resd': 'passthrough',\n",
    "    'waiver': 'passthrough',\n",
    "    # 'fafsa_app': 'passthrough',\n",
    "    'schlship_app': 'passthrough',\n",
    "    # 'finaid_accepted': 'passthrough',\n",
    "    'ssb': 'passthrough',\n",
    "    'math': 'passthrough',\n",
    "    'reading': 'passthrough',\n",
    "    'writing': 'passthrough',\n",
    "    'gap_score': 'passthrough',\n",
    "    'oriented': 'passthrough',\n",
    "    'hs_qrtl': 'passthrough',\n",
    "    'act_equiv': 'passthrough',\n",
    "    'lgcy': 'passthrough',\n",
    "    # 'distance': StandardScaler()\n",
    "    # 'distance': 'passthrough'\n",
    "    'distance': make_pipeline(StandardScaler(), PowerTransformer()),\n",
    "    })\n",
    "ct = ColumnTransformer([(c,t,[\"__\"+c]) for c,t in trf.items()], remainder='drop', verbose_feature_names_out=False)\n",
    "#         # ('lgcy', 'passthrough', '__lgcy'),\n",
    "#         # ('distance', StandardScaler(), '__distance'),\n",
    "#     # ]\n",
    "str(trf)\n",
    "\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# ct = ColumnTransformer([\n",
    "#         ('lgcy', 'passthrough', '__lgcy'),\n",
    "#         ('distance', StandardScaler(), '__distance'),\n",
    "#     ], remainder='drop', verbose_feature_names_out=False)\n",
    "# str(ct)\n",
    "# def stringify(self):\n",
    "#     # def f(x):\n",
    "#     #     try:\n",
    "#     #         return str(x).split('(')[0]\n",
    "#     #     except:\n",
    "#     #         return str(x)\n",
    "#     # return ', '.join([f\"({a}, {b}, {c})\" for a,b,c in sorted(self.transformers)])\n",
    "#     return join(f\"({join(t)})\" for t in sorted(self.transformers))\n",
    "# stringify(ct)\n",
    "ct.fit_transform(self.X).columns\n",
    "# # str(ct.transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mean_match_default#.copy()\n",
    "x = mean_match_shap\n",
    "x.__repr__()\n",
    "mean_match_default??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest import ImputationKernel, mean_match_default, mean_match_fast_cat, mean_match_shap\n",
    "# from sklearn.base import clone, BaseEstimator\n",
    "# from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "# from sklearn.linear_model import BayesianRidge, Ridge\n",
    "# from sklearn.kernel_approximation import Nystroem\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "# from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, iteration=None, normalize=True):\n",
    "    targ = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    feat = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=targ, columns=feat).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "def inspect(self, **kwargs):\n",
    "    self.plot_imputed_distributions(wspace=0.3,hspace=0.3)\n",
    "    self.plot_mean_convergence(wspace=0.3, hspace=0.4)\n",
    "    I = self.feature_importance_df(**kwargs)\n",
    "    I.disp(100)\n",
    "    return I\n",
    "ImputationKernel.inspect = inspect\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer_term: int\n",
    "    crse: typing.List\n",
    "    attr: typing.List\n",
    "    # feat: typing.Dict\n",
    "    fill: typing.Dict = None\n",
    "    # trf: typing.Dict = None\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'X':False, 'Y':False, 'Z':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['Z'] |= self.overwrite['X'] | self.overwrite['Y']\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.path = root_path / f\"resources/rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "\n",
    "        for k in ['term','pred','imputed']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        self.term_codes = uniquify([*listify(self.term_codes), self.infer_term])\n",
    "        self.crse = uniquify(['_total', *listify(self.crse)])\n",
    "        self.mlt_grp = ['crse','levl_code','styp_code','term_code']\n",
    "        \n",
    "\n",
    "        # def g(X):\n",
    "        #     X = [listify(x) for x in X]\n",
    "        #     return {x.pop(0): x if x else [np.nan] for x in X}\n",
    "        # L = [g(self.attr), g(self.feat)]\n",
    "        # self.imp = L[0] | L[1]\n",
    "        # self.attr, self.feat = [list(x.keys()) for x in L]\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "    def preprocess(self):\n",
    "        def get(nm):\n",
    "            if nm in self:\n",
    "                return False\n",
    "            print(f'get {nm}')\n",
    "            return True\n",
    "\n",
    "        if get('raw_df'):\n",
    "            self.raw_df = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "        \n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        \n",
    "        if get('X'):\n",
    "            R = self.raw_df.copy()\n",
    "            repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "            R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "            R['remote'] = R['camp_code'] != 's'\n",
    "            R['resd'] = R['resd_code'] == 'r'\n",
    "            R['lgcy'] = ~R['lgcy_code'].isin(['n','o'])\n",
    "            R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "            R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm', '00':pd.NA})\n",
    "            R['coll_desc'] = R['coll_desc'].replace({\n",
    "                'ag & environmental sciences':'ag & natural resources',\n",
    "                'education & human development':'education',\n",
    "                'health science & human service':'health sciences',\n",
    "                'science & technology':'science & mathematics'})\n",
    "            majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "            S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "            X = where(R.drop(columns=majr).merge(S, on='majr_code', how='left')).prep().binarize()\n",
    "\n",
    "            checks = [\n",
    "                'cycle_day >= 0',\n",
    "                'apdc_day >= cycle_day',\n",
    "                'appl_day >= apdc_day',\n",
    "                'birth_day >= appl_day',\n",
    "                'birth_day >= 5000',\n",
    "                'distance >= 0',\n",
    "                'hs_pctl >=0',\n",
    "                'hs_pctl <= 100',\n",
    "                'hs_qrtl >= 0',\n",
    "                'hs_qrtl <= 4',\n",
    "                'act_equiv >= 1',\n",
    "                'act_equiv <= 36',\n",
    "                'gap_score >= 0',\n",
    "                'gap_score <= 100',\n",
    "            ]\n",
    "            for check in checks:\n",
    "                mask = X.eval(check)\n",
    "                assert mask.all(), [check,X[~mask].disp(5)]\n",
    "\n",
    "            for k, v in self.feat.items():\n",
    "                if 'fill' in v:\n",
    "                    X[k] = X.impute(k, *v['fill'])\n",
    "\n",
    "            # ren = lambda x:'__'+x\n",
    "            self.X = X.prep().binarize().set_index(self.attr, drop=False).rename(columns=lambda x:'__'+x)\n",
    "            # self.feat = {ren(k): v for k, v in self.feat.items()}\n",
    "            # for k, v in self.feat.items():\n",
    "            #     if 'fill' in v:\n",
    "            #         X[k] = X.impute(k, *v['fill'])\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            # self.feat = {ren(k): v for k, v in self.feat.items()}\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            # for k, v in self.trf.items():\n",
    "            #     X[k] = instantiate(v).fit_transform(X[[k]]).squeeze()\n",
    "            \n",
    "            # for k, v in self.imp.items():\n",
    "            #     X[k] = X.impute(k, *v)\n",
    "\n",
    "            # self.X = (X\n",
    "            #     .prep()\n",
    "            #     .binarize()\n",
    "            #     # .reset_index()\n",
    "            #     # .rename(columns={'index':'idx'})\n",
    "            #     # .set_index(['idx',*self.attr], drop=False)\n",
    "            #     .set_index(self.attr, drop=False)\n",
    "            #     .rename(columns=feat_renamer)\n",
    "            #     [self.feat.keys()]\n",
    "                \n",
    "            # )\n",
    "\n",
    "            # .categorize()\n",
    "\n",
    "            self.X.missing().disp(100)\n",
    "\n",
    "        if get('reg_df'):\n",
    "            with warnings.catch_warnings(action='ignore'):\n",
    "                self.reg_df = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]) for k in ['cur','end']}\n",
    "        \n",
    "        if get('Y'):\n",
    "            print(self.X.shape)\n",
    "            self.Y = {k: self.X[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in self.reg_df.items()}\n",
    "            print(self.Y['end'].shape)\n",
    "            print(self.Y['cur'].shape)\n",
    "            agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "            A = agg(self.reg_df['end'])\n",
    "            B = agg(self.Y['end'])\n",
    "            M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(f\"term_code != {self.infer_term}\").prep()\n",
    "            N = M.assign(term_code=self.infer_term)\n",
    "            self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "            Y = {k: y.squeeze().unstack().dropna(how='all', axis=1).fillna(0) for k, y in self.Y.items()}\n",
    "            self.Y = Y['cur'].rename(columns=lambda x:x+'_cur').join(Y['end']>0).prep()\n",
    "            print(self.Y.shape)\n",
    "            self.Y.missing().disp(100)\n",
    "\n",
    "        # if get('Z'):\n",
    "        #     self.Z = self.X.join(self.Y['cur'].rename(columns=lambda x:x+'_cur')).join(self.Y['end']>0).prep()\n",
    "        return self.dump()\n",
    "\n",
    "   \n",
    "    def predict(self, params, crse, train_term, styp_code='all'):\n",
    "        for step in ['imp','enc','clf']:\n",
    "            params.setdefault(step, dict())\n",
    "        for p, P in self.pred.items():\n",
    "            if p == stringify(params):\n",
    "                for c, C in P.items():\n",
    "                    if c == crse:\n",
    "                        for t, T in C.items():\n",
    "                            if t == train_term:\n",
    "                                for s, S in T.items():\n",
    "                                    if s == styp_code:\n",
    "                                        # print('reusing')\n",
    "                                        return S\n",
    "\n",
    "        X = self.X.copy()\n",
    "        if styp_code != 'all':\n",
    "            X = X.query(f\"styp_code==@styp_code\")\n",
    "\n",
    "        imp_str = stringify({'imp':params['imp']})\n",
    "        X_imputed = None\n",
    "        for i, I in self.imputed.items():\n",
    "            if i == imp_str:\n",
    "                for s, S in I.items():\n",
    "                    if s == styp_code:\n",
    "                        # print('reusing imputed data')\n",
    "                        X_imputed = S\n",
    "\n",
    "        if X_imputed is None:\n",
    "            print('imputing')\n",
    "            p = params['imp'].copy()\n",
    "            # p = params.pop('imp')\n",
    "            iterations = p[1].pop('iterations') if 'iterations' in p[1] else 5\n",
    "            print(iterations, p[1])\n",
    "            imp = p[0](X, **p[1])\n",
    "            imp.mice(iterations)\n",
    "            X_imputed = [imp.complete_data(k) for k in range(imp.dataset_count())]\n",
    "            self.imputed.setdefault(imp_str, dict()).update({styp_code: X_imputed})\n",
    "            self.dump()\n",
    "            imp.inspect()\n",
    "\n",
    "        print('creating', ljust(crse,8), train_term, styp_code)#, stringify(params))\n",
    "        cols = uniquify(['_total_cur',crse+'_cur',crse])\n",
    "        S = dict()\n",
    "        for k, X in enumerate(X_imputed):\n",
    "            Z = X.join(self.Y[cols]).sort_index()\n",
    "            Z.missing().disp(100)\n",
    "            c = params['clf'].copy()\n",
    "            if c[0].__name__ != 'ImputationKernel':\n",
    "                enc = ColumnTransformer([('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist', **params['enc'][1]), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)\n",
    "                T = enc.fit_transform(Z)\n",
    "                T.missing().disp(100)\n",
    "                X = {'test': T, 'train': T.query(f\"term_code==@train_term\")}\n",
    "                y = {k: x.pop(crse) for k, x in X.items()}\n",
    "                model = c[0](**c[1]).fit(X['train'], y['train'])\n",
    "                pred = model.predict(X['test'])\n",
    "            else:\n",
    "                iterations = c[1].pop('iterations') if 'iterations' in c[1] else 5\n",
    "                T = Z.copy()\n",
    "                T.loc[T.eval(\"term_code!=@train_term\"), crse] = pd.NA\n",
    "                model = c[0](T, datasets=1, **c[1])\n",
    "                model.mice(1)\n",
    "                optimal_parameters, losses = model.tune_parameters(dataset=0, optimization_steps=5)\n",
    "                model.mice(iterations, variable_parameters=optimal_parameters)\n",
    "                model.inspect()\n",
    "                T.loc[:, crse] = pd.NA\n",
    "                pred = model.impute_new_data(T).complete_data(0).pop(crse)\n",
    "                \n",
    "            details = (\n",
    "                Z[crse]\n",
    "                .rename('true')\n",
    "                .to_frame()\n",
    "                .assign(pred=pred, train_term=train_term, crse=crse, sim=k)\n",
    "                .set_index(['train_term','crse','sim'], append=True)\n",
    "                .binarize()\n",
    "            )\n",
    "            agg = lambda x: pd.Series({\n",
    "                'pred': x['pred'].sum(min_count=1),\n",
    "                'true': x['true'].sum(min_count=1),\n",
    "                'mse_pct': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "                'f1_inv_pct': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "            })\n",
    "            summary = details.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "            for x in ['pred','true']:\n",
    "                summary[x] = summary[x] * summary['mlt']\n",
    "            summary.insert(2, 'err', summary['pred'] - summary['true'])\n",
    "            summary.insert(3, 'err_pct', (summary['err'] / summary['true']).clip(-1, 1) * 100)\n",
    "            S[k] = {'details':details.copy(), 'summary':summary.copy().drop(columns='mlt').prep(), 'model':model}\n",
    "        return S\n",
    "\n",
    "    def analyze(self):\n",
    "        def pivot(df, val):\n",
    "            Y = (\n",
    "                df\n",
    "                .reset_index()\n",
    "                .pivot_table(columns='train_term', index=['crse','styp_code','pred_term'], values=val, aggfunc=[pctl(0),pctl(25),pctl(50),pctl(75),pctl(100)])\n",
    "                .rename_axis(columns=[val,'train_term'])\n",
    "                .stack(0)\n",
    "                .assign(abs_mean = lambda x: x.abs().mean(axis=1))\n",
    "            )\n",
    "            return Y\n",
    "\n",
    "        for k, v in self.pred.items():\n",
    "            print(k)\n",
    "            df = v['summary']\n",
    "            mask = df.eval(f\"pred_term!={self.infer_term}\")\n",
    "            v['rslt'] = {stat: pivot(df[mask], stat) for stat in [\"pred\",\"err\",\"err_pct\",\"mse_pct\",\"f1_inv_pct\"]} | {'pred': pivot(df[~mask], \"pred\")}\n",
    "            v['rslt']['err_pct'].query(\"err_pct==' 50%'\").disp(200)\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def main(self, params_list):\n",
    "        g = lambda Y: Y | {k: pd.concat([y[k] for y in Y.values() if k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "        for params in params_list:\n",
    "            M = dict()\n",
    "            print(stringify(params))\n",
    "            for crse in self.crse:\n",
    "                C = dict()\n",
    "                for train_term in self.term_codes:\n",
    "                    T = dict()\n",
    "                    for styp_code in ['n']:#,'r','t']:\n",
    "                        S = self.predict(params, crse, train_term, styp_code)\n",
    "                        T[styp_code] = g(S)\n",
    "                    C[train_term] = g(T)\n",
    "                M[crse] = g(C)\n",
    "            self.pred[stringify(params)] = g(M) | {'params':params}\n",
    "            self.dump()\n",
    "        return self.analyze()\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "kwargs = {\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'infer_term': 202408,\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    'attr': [\n",
    "        # 'index',\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        *code_desc('resd'),\n",
    "        *code_desc('lgcy'),\n",
    "        'international',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_qrtl',\n",
    "    ],\n",
    "    'feat': [\n",
    "        # {'term_code: {}}',\n",
    "        {'appl_day': {}},\n",
    "        {'apdc_day': {}},\n",
    "        {'birth_day': {'fill': ['median',['term_code','styp_code']]}},\n",
    "        # {'levl_code': {}},\n",
    "        # {'styp_code': {}},\n",
    "        # {'admt_code': {}},\n",
    "        # {'camp_code': {}},\n",
    "        {'remote', {'fill': False}},\n",
    "        {'coll_code': {}},\n",
    "        {'international': {'fill': False}},\n",
    "        *[{f'race_{r}': {'fill': False}} for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        {'gender': {}},\n",
    "        {'lgcy': {'fill': False}},\n",
    "        {'resd': {'fill': False}},\n",
    "        {'waiver': {'fill': False}},\n",
    "        # {'fafsa_app': {'fill': False}},\n",
    "        {'schlship_app': {'fill': False}},\n",
    "        # {'finaid_accepted': {'fill': False}},\n",
    "        {'ssb': {'fill': False}},\n",
    "        {'math': {'fill': False}},\n",
    "        {'reading': {'fill': False}},\n",
    "        {'writing': {'fill': False}},\n",
    "        {'gap_score': {'fill': 0}},\n",
    "        {'oriented': {'fill': 'n'}},\n",
    "        {'distance': {}},\n",
    "        {'hs_qrtl': {}},\n",
    "        {'act_equiv': {}},\n",
    "    ],\n",
    "    'trf': {\n",
    "        'birth_day': make_pipeline(StandardScaler(), PowerTransformer()),\n",
    "        'distance': make_pipeline(StandardScaler(), PowerTransformer()),\n",
    "    },\n",
    "    # 'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    'cycle_day': 187,\n",
    "    'crse': [\n",
    "        # 'engl1301',\n",
    "        # 'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        'raw_df': True,\n",
    "        'reg_df': True,\n",
    "        'X': True,\n",
    "        'Y': True,\n",
    "        'Z': True,\n",
    "        # 'imputed':True,\n",
    "        'pred': True,\n",
    "    },\n",
    "}\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "self = self.preprocess()\n",
    "self.term_codes.remove(self.infer_term)\n",
    "\n",
    "def mmc(k):\n",
    "    m = mean_match_default.copy()\n",
    "    m.set_mean_match_candidates(k)\n",
    "    return m\n",
    "MMC = [mmc(k) for k in range(0,10,2)]\n",
    "\n",
    "params_grid = {\n",
    "    'enc': {\n",
    "        OneHotEncoder: {\n",
    "            'min_frequency': [0.1],\n",
    "        },\n",
    "    },\n",
    "    'imp': {\n",
    "        ImputationKernel: {\n",
    "            'datasets': 5,\n",
    "            # 'save_all_iterations': False,\n",
    "            # 'mean_match_candidates': [29],\n",
    "            # 'mean_match_function': mean_match_kdtree_classification,\n",
    "            'mean_match_scheme': [mmc(25)],\n",
    "            'iterations':4,\n",
    "        },\n",
    "    },\n",
    "    'clf': {\n",
    "        # RandomForestClassifier: {\n",
    "        #     'max_depth': 3,\n",
    "        # },\n",
    "        HistGradientBoostingClassifier: {\n",
    "            'max_depth': 3,\n",
    "        },\n",
    "        # ImputationKernel: {\n",
    "        #     'save_all_iterations': False,\n",
    "        #     # 'mean_match_candidates': [29],\n",
    "        #     # 'mean_match_function': mean_match_kdtree_classification,\n",
    "        #     'iterations':3,\n",
    "        # }\n",
    "    },\n",
    "}\n",
    "params_list = cartesian({step: [[alg, values] for alg, grid in D.items() for values in cartesian(grid)] for step, D in params_grid.items()})\n",
    "def stringify(P):\n",
    "    def f(x):\n",
    "        try:\n",
    "            return x.__name__\n",
    "        except:\n",
    "            return x\n",
    "    return str({f(step): [f(D[0]), {f(k): f(v) for k, v in D[1].items()}] for step, D in P.items()})\n",
    "\n",
    "# self.main(params_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.join(self.Y).missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = imp\n",
    "targ = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.imputation_order)]\n",
    "feat = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "I = pd.DataFrame(self.get_feature_importance(dataset=0), index=targ, columns=feat).T\n",
    "I = I / I.sum() * 100# if normalize else I\n",
    "I.sort_values('__act_equiv', ascending=False)\n",
    "# (dataset=0, annot=True,cmap=\"YlGnBu\",vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmc(k):\n",
    "    m = mean_match_default.copy()\n",
    "    m.set_mean_match_candidates(k)\n",
    "    return m\n",
    "MMC = [mmc(k) for k in range(10)]\n",
    "# mmc = []\n",
    "# for k in range(10):\n",
    "#     m = mean_match_default.copy()\n",
    "#     m.set_mean_match_candidates(k)\n",
    "#     mmc.append(m)\n",
    "# mmc[2].mean_match_candidates\n",
    "    \n",
    "    \n",
    "\n",
    "# scheme_mmc_0.set_mean_match_candidates(0)\n",
    "# scheme_mmc_5.set_mean_match_candidates(5)\n",
    "# scheme_mmc_5.mean_match_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.X['__coll_code'].replace('00',pd.NA)\n",
    "self.X.vc('__coll_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data and introduce missing values\n",
    "iris = pd.concat(load_iris(as_frame=True,return_X_y=True),axis=1)\n",
    "iris.rename({\"target\": \"species\"}, inplace=True, axis=1)\n",
    "iris['species'] = iris['species'].astype('category')\n",
    "iris_amp = mf.ampute_data(iris,perc=0.25,random_state=1991)\n",
    "\n",
    "# Create kernel. \n",
    "kernel = mf.ImputationKernel(\n",
    "  iris_amp,\n",
    "  datasets=4,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1\n",
    ")\n",
    "\n",
    "# Run the MICE algorithm for 2 iterations on each of the datasets\n",
    "kernel.mice(2)\n",
    "\n",
    "# Printing the kernel will show you some high level information.\n",
    "print(kernel)\n",
    "\n",
    "# Using the first ImputationKernel in kernel to tune parameters\n",
    "# with the default settings.\n",
    "optimal_parameters, losses = kernel.tune_parameters(\n",
    "  dataset=0,\n",
    "  optimization_step=5,\n",
    "  hi=6\n",
    ")\n",
    "\n",
    "# Run mice with our newly tuned parameters.\n",
    "kernel.mice(1, variable_parameters=optimal_parameters)\n",
    "\n",
    "# The optimal parameters are kept in ImputationKernel.optimal_parameters:\n",
    "print(optimal_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.tune_parameters??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a complicated setup:\n",
    "optimal_parameters, losses = kernel.tune_parameters(\n",
    "  dataset=0,\n",
    "  variables = ['sepal width (cm)','species','petal width (cm)'],\n",
    "  variable_parameters = {\n",
    "    'sepal width (cm)': {'bagging_fraction': 0.5},\n",
    "    'species': {'bagging_freq': (5,10)}\n",
    "  },\n",
    "  optimization_steps=5,\n",
    "  extra_trees = [True, False]\n",
    ")\n",
    "\n",
    "kernel.mice(1, variable_parameters=optimal_parameters)\n",
    "print(optimal_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data and introduce missing values\n",
    "iris = pd.concat(load_iris(as_frame=True,return_X_y=True),axis=1)\n",
    "iris.rename({\"target\": \"species\"}, inplace=True, axis=1)\n",
    "iris['species'] = iris['species'].astype('category')\n",
    "iris_amp = mf.ampute_data(iris,perc=0.25,random_state=1991)\n",
    "\n",
    "# Create kernel. \n",
    "kds = mf.ImputationKernel(\n",
    "  iris_amp,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1991\n",
    ")\n",
    "\n",
    "# Run the MICE algorithm for 2 iterations\n",
    "kds.mice(2)\n",
    "\n",
    "# Return the completed dataset.\n",
    "iris_complete = kds.complete_data(0)\n",
    "\n",
    "# Create kernel. \n",
    "kernel = mf.ImputationKernel(\n",
    "  iris_amp,\n",
    "  datasets=4,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1\n",
    ")\n",
    "\n",
    "# Run the MICE algorithm for 2 iterations on each of the datasets\n",
    "kernel.mice(2)\n",
    "\n",
    "# Printing the kernel will show you some high level information.\n",
    "print(kernel)\n",
    "\n",
    "completed_dataset = kernel.complete_data(dataset=2)\n",
    "print(completed_dataset.isnull().sum(0))\n",
    "\n",
    "# Run the MICE algorithm for 1 more iteration on the kernel with new parameters\n",
    "kernel.mice(iterations=1,n_estimators=50)\n",
    "\n",
    "# Run the MICE algorithm for 2 more iterations on the kernel \n",
    "kernel.mice(\n",
    "  iterations=1,\n",
    "  variable_parameters={'species': {'n_estimators': 25}},\n",
    "  n_estimators=50\n",
    ")\n",
    "\n",
    "# Let's get the actual models for these variables:\n",
    "species_model = kernel.get_model(dataset=0,variable=\"species\")\n",
    "sepalwidth_model = kernel.get_model(dataset=0,variable=\"sepal width (cm)\")\n",
    "\n",
    "print(\n",
    "f\"\"\"Species used {str(species_model.params[\"num_iterations\"])} iterations\n",
    "Sepal Width used {str(sepalwidth_model.params[\"num_iterations\"])} iterations\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create kernel. \n",
    "cust_kernel = mf.ImputationKernel(\n",
    "  iris_amp,\n",
    "  datasets=1,\n",
    "  random_state=1\n",
    ")\n",
    "\n",
    "cust_kernel.mice(\n",
    "  iterations=1, \n",
    "  variable_parameters={'sepal width (cm)': {'objective': 'poisson'}},\n",
    "  boosting = 'gbdt',\n",
    "  min_sum_hessian_in_leaf=0.01\n",
    ")\n",
    "\n",
    "# Our 'new data' is just the first 15 rows of iris_amp\n",
    "from datetime import datetime\n",
    "\n",
    "# Define our new data as the first 15 rows\n",
    "new_data = iris_amp.iloc[range(15)]\n",
    "\n",
    "# Imputing new data can often be made faster by \n",
    "# first compiling candidate predictions\n",
    "kernel.compile_candidate_preds()\n",
    "\n",
    "start_t = datetime.now()\n",
    "new_data_imputed = kernel.impute_new_data(new_data=new_data)\n",
    "print(f\"New Data imputed in {(datetime.now() - start_t).total_seconds()} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install git+https://github.com/AnotherSamWilson/miceforest.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['__birth_day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in self.X.select_dtypes('number').items():\n",
    "    v.plot(kind='kde', title=k)\n",
    "    plt.show()\n",
    "    # print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = PowerTransformer()\n",
    "self.X['__birth_day'] = trf.fit_transform(self.X[['__birth_day']]).squeeze()\n",
    "self.X['__birth_day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[0].keys()\n",
    "g = lambda Y: Y | {k: pd.concat([y[k] for y in Y.values() if k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "g(S)\n",
    "list(S.values())[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_df(self, dataset=0, normalize=True, iteration=None):\n",
    "    predictor_var_names = [self._get_variable_name(i) for i in sorted(self.predictor_vars)]\n",
    "    imputed_var_names   = [self._get_variable_name(i) for i in sorted(self.imputation_order)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "for k, v in self.pred.items():\n",
    "    pass\n",
    "m = v['_total'][202008]['n'][0]['model']\n",
    "m.get_feature_importance(0)\n",
    "feature_importance_df(m, 0).squeeze().sort_values()\n",
    "#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install\n",
    "pip install git+https://github.com/AnotherSamWilson/miceforest.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "cols = uniquify(['_total_cur',crse+'_cur',crse])\n",
    "X_imputed = list(self.imputed.values())[0]['n'][:1]\n",
    "for k, X in enumerate(X_imputed):\n",
    "    Z = X.join(self.Y[cols])\n",
    "    Z.iloc[0,-1] = pd.NA\n",
    "    imp = ImputationKernel(Z, train_nonmissing=True)\n",
    "Z.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImputationKernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list[0]['imp'][0].__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.pred.values())[0]['rslt']['err_pct'].query(\"err_pct==' 50%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "styp_code = 'n'\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "for k, v in self.imputed.items():\n",
    "    X_imputed = v[styp_code]\n",
    "    S = dict()\n",
    "    for k, X in enumerate(X_imputed):\n",
    "        if params['imp'][0].__name__:\n",
    "            \n",
    "\n",
    "        Z = clone(enc).fit_transform(X).join(self.Y[cols])\n",
    "        X = {'test': Z, 'train': Z.query(f\"term_code==@train_term\")}\n",
    "        y = {k: x.pop(crse) for k, x in X.items()}\n",
    "        model = clone(clf).fit(X['train'], y['train'])\n",
    "        details = (\n",
    "            y['test']\n",
    "            .rename('true')\n",
    "            .to_frame()\n",
    "            .assign(pred=model.predict(X['test']), train_term=train_term, crse=crse, sim=k)\n",
    "            .set_index(['train_term','crse','sim'], append=True)\n",
    "            .binarize()\n",
    "        )\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse_pct': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv_pct': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        summary = details.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            summary[x] = summary[x] * summary['mlt']\n",
    "        summary.insert(2, 'err', summary['pred'] - summary['true'])\n",
    "        summary.insert(3, 'err_pct', (summary['err'] / summary['true']).clip(-1, 1) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict()\n",
    "a.setdefault('b',dict()).update({'c':4})\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImputationKernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'imp':params_list[0]['imp']}\n",
    "p\n",
    "stringify = lambda P: str({f(step): [f(D[0]), {f(k): f(v) for k, v in D[1].items()}] for step, D in P.items()})\n",
    "stringify(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in self.pred.items():\n",
    "    print(k)\n",
    "    v['rslt']['err%'].query(\"err% == 0\").disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.pred.values())[0]['rslt']['err%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = params_list[0]\n",
    "# q = P['enc'].values()\n",
    "# dict(q)\n",
    "# dir(q)\n",
    "# q.mapping()\n",
    "list(P['enc'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = cartesian({step: [[alg, values] for alg, grid in D.items() for values in cartesian(grid)] for step, D in params_grid.items()})\n",
    "def f(x):\n",
    "    try:\n",
    "        return x.__name__\n",
    "    except:\n",
    "        return x\n",
    "stringify = lambda P: {f(step): [f(k): f(v)  for k, v in D.items()} for step, D in P.items()}\n",
    "# stringify(param_list[0])\n",
    "P = params_list[0]\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = cartesian({step: [{alg: values} for alg, grid in D.items() for values in cartesian(grid)] for step, D in params_grid.items()})\n",
    "def f(x):\n",
    "    try:\n",
    "        return x.__name__\n",
    "    except:\n",
    "        return x\n",
    "param_list[0]\n",
    "stringify = lambda P: {f(step): {f(alg): {f(k): f(v) for k, v in H.items()} for alg, H in D.items()} for step, D in P.items()}\n",
    "stringify(param_list[0])\n",
    "    \n",
    "# param_list\n",
    "# S = [{f(step): {f(k): f(v)  for k, v in D.items()}  for step, D in P.items()} for P in param_list]\n",
    "# S\n",
    "# str(S[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = cartesian({step: [{'alg':alg}|values for alg, grid in D.items() for values in cartesian(grid)] for step, D in params_grid.items()})\n",
    "def f(x):\n",
    "    try:\n",
    "        return x.__name__\n",
    "    except:\n",
    "        return x\n",
    "stringify = lambda P: {f(step): {f(k): f(v)  for k, v in D.items()} for step, D in P.items()}\n",
    "stringify(param_list[0])\n",
    "    \n",
    "# param_list\n",
    "# S = [{f(step): {f(k): f(v)  for k, v in D.items()}  for step, D in P.items()} for P in param_list]\n",
    "# S\n",
    "# str(S[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Collection, Mapping\n",
    "\n",
    "# def recursive_map(data, func):\n",
    "#     apply = lambda x: recursive_map(x, func)\n",
    "#     if isinstance(data, Mapping):\n",
    "#         return type(data)({k: apply(v) for k, v in data.items()})\n",
    "#     elif isinstance(data, Collection):\n",
    "#         return type(data)(apply(v) for v in data)\n",
    "#     else:\n",
    "#         return func(data)\n",
    "    \n",
    "# def func(x):\n",
    "#     try:\n",
    "#         return x.__name__\n",
    "#     except:\n",
    "#         return x\n",
    "    \n",
    "# func(mean_match_kdtree_classification)\n",
    "mean_match_kdtree_classification.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple(sorted(params_list))\n",
    "# str(params_list[0])\n",
    "# params_list[0]\n",
    "def f(x):\n",
    "    try:\n",
    "        return x.__name__\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "# [{f(k):v} for k,v in a.items() for a in params_list]\n",
    "\n",
    "# {f(a): {f(b):} for a, A in }\n",
    "# cartesian({step: [[alg, values] for alg, grid in D.items() for values in cartesian(grid)] for step, D in params_grid.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0x7f91603f5300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 'clf'\n",
    "G = cartesian({step: [{'alg':alg} | values for alg, grid in D.items() for values in cartesian(grid)] for step, D in param_grid.items()})\n",
    "G = cartesian({step: [[alg, values] for alg, grid in D.items() for values in cartesian(grid)] for step, D in param_grid.items()})\n",
    "len(G)\n",
    "G[0]\n",
    "# param_grid['clf']\n",
    "\n",
    "\n",
    "# [{step: {'alg':alg} | values} for step, D in param_grid.items() for alg, grid in D.items() for values in cartesian(grid)][2]\n",
    "# [(step, alg) for step, D in param_grid.items() for alg, grid in cartD.items() ]\n",
    "# [{'alg':k} | m for k,v in param_grid['clf'].items() for m in cartesian(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(param_grid['clf'].values())\n",
    "# param_grid[0]['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(X):\n",
    "    if X is None or X is np.nan:\n",
    "        return []\n",
    "    elif isinstance(X, (str,int,float,bool)) or callable(X):\n",
    "        return [X]\n",
    "    else:\n",
    "        return list(X)\n",
    "listify(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mean_match_kdtree_classification\n",
    "print(type(x))\n",
    "# list(x)\n",
    "isinstance(x, type(sum))\n",
    "type(sum)\n",
    "x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian(dct):\n",
    "    \"\"\"Creates the Cartesian product of a dictionary with list-like values\"\"\"\n",
    "    # try:\n",
    "    D = {key: listify(val) for key, val in dct.items()}\n",
    "    return [dict(zip(D.keys(), x)) for x in it.product(*D.values())]\n",
    "    # except:\n",
    "    #     return dict()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'enc': cartesian({\n",
    "        'min_frequency': [0.1],\n",
    "    }),\n",
    "    'imp': cartesian({\n",
    "        'datasets': [5],\n",
    "        'save_all_iterations': [False],\n",
    "        'mean_match_candidates': 10,\n",
    "        'mean_match_function': mean_match_kdtree_classification,\n",
    "    }),\n",
    "    'clf':{\n",
    "        RandomForestClassifier: {\n",
    "            'max_depth': 3,\n",
    "            'random_state': [1,2],\n",
    "        },\n",
    "        HistGradientBoostingClassifier: {\n",
    "            'max_depth': 3,\n",
    "            'random_state': [1,2],\n",
    "        },\n",
    "    }\n",
    "}\n",
    "param_grid['imp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone, BaseEstimator\n",
    "# p = {'alg':RandomForestClassifier, 'max_depth':3}\n",
    "# p.pop('alg')(**p)\n",
    "p = {\n",
    "    RandomForestClassifier: {\n",
    "        'max_depth': 3,\n",
    "        'random_state': [1,2],\n",
    "    },\n",
    "    HistGradientBoostingClassifier(): {\n",
    "        'max_depth': 3,\n",
    "        'random_state': [1,2],\n",
    "    }\n",
    "}\n",
    "a = [{'alg':k} | m for k,v in p.items() for m in cartesian(v)]\n",
    "b = [{'alg':k} | m for k,v in p.items() for m in cartesian(v)]\n",
    "c = a[0]\n",
    "inst = lambda x: x if isinstance(x, BaseEstimator) else x()\n",
    "inst(c.pop('alg')).set_params(**c)\n",
    "# type(RandomForestClassifier)\n",
    "# RandomForestClassifier.__mro__\n",
    "# isinstance(RandomForestClassifier(), BaseEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = ColumnTransformer([('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)\n",
    "enc.set_params(cat__min_frequency=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miceforest import ImputationKernel\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "imp = ImputationKernel(self.X)\n",
    "# kds.mice(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.dataset_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "cols = uniquify(['_total_cur',crse+'_cur',crse])\n",
    "self.Y[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = kds.complete_data(0)\n",
    "X.missing()\n",
    "X.dtypes\n",
    "enc = ColumnTransformer([('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)\n",
    "X = enc.fit_transform(X).join(self.Y[cols])\n",
    "X = {'test': X, 'train': X.query(f\"term_code==@train_term\")}\n",
    "y = {k: x.pop(crse) for k, x in X.items()}\n",
    "\n",
    "# train_term = 202208\n",
    "# X = {'test':X.copy(), 'train':X.query('term_code==@train_term')}\n",
    "# y = {'test':self.Y.copy(), 'train':self.Y.query('term_code==@train_term')}\n",
    "# clf = HistGradientBoostingClassifier()\n",
    "# clf.fit(X['train'], y['train'])\n",
    "# clf.predict(X['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z = enc.fit_transform(X).join(self.Y['cur'].rename(columns=lambda x:x+'_cur')).join(self.Y['end']>0).prep()\n",
    "Y = self.Y['cur'].rename(columns=lambda x:x+'_cur').join(self.Y['end']>0).prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list(self.pred.values())[0]['_total']['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z['__act_equiv'].reset_index(drop=True).disp(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge, Ridge\n",
    "est = Pipeline(verbose=False, steps=[\n",
    "    ('prc', ColumnTransformer([('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    # ('imp', IterativeImputer(skip_complete=True, estimator=RandomForestRegressor())),\n",
    "    ('imp', IterativeImputer(skip_complete=True, estimator=BayesianRidge())),\n",
    "    \n",
    "    # ('clf', HistGradientBoostingClassifier()),\n",
    "    # ('clf', RandomForestClassifier()),\n",
    "    # ('clf', GradientBoostingClassifier()),\n",
    "])\n",
    "\n",
    "self.X.missing().disp(100)\n",
    "Q = est.fit_transform(self.X)\n",
    "Q.missing().disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:0 for k,v in est.get_params().items() if 'random_state' in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(self.pred.values())[0]['_total']\n",
    "df = a['summary']\n",
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'x'.ljust(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list(self.pred.values())[0]['_total']['summary']\n",
    "def pivot(df, val, q=50):\n",
    "    Y = df.reset_index().pivot_table(columns='train_term', index=['crse','styp_code','pred_term'], values=val, aggfunc=[pctl(0),pctl(25),pctl(50),pctl(75),pctl(100),'max'])   # for _ in range(2):\n",
    "    #     # mr = Y.mean(axis=1)\n",
    "    #     ma = Y.abs().mean(axis=1)\n",
    "    #     Y = (Y.assign(abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "        # Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "    return Y.stack(0)#.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep()\n",
    "\n",
    "\n",
    "w = {stat: pivot(df.query(f\"pred_term!={self.infer_term}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "w['err%'].sort_index()\n",
    "\n",
    "# pivot(df.query(f\"pred_term=={self.infer_term}\"), \"pred\", q=25)\n",
    "\n",
    "# list(self.pred.keys())[0]\n",
    "# val = 'err%'\n",
    "# q = 50\n",
    "# df.query(f\"pred_term!={self.infer_term}\").reset_index().pivot_table(columns='train_term', index=['crse','pred_term','styp_code'], values=val, aggfunc=pctl(q))\n",
    "# df.query(f\"pred_term=={self.infer_term}\").reset_index().pivot_table(columns='train_term', index=['crse','pred_term','styp_code'], values=val, aggfunc=pctl(q))\n",
    "# pivot(df.query(f\"pred_term!={self.infer_term}\"), 'err%')\n",
    "# {stat: pivot(df.query(f\"pred_term!={self.infer_term}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "# pivot(df.query(f\"pred_term=={self.infer_term}\"), \"pred\")\n",
    "# pd.concat([pivot(df.query(f\"pred_term=={self.infer_term}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "# for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list(self.pred.values())[0]['_total']['summary']\n",
    "df.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(self):\n",
    "    def pivot(df, val):\n",
    "        Y = (\n",
    "            df\n",
    "            .reset_index()\n",
    "            .pivot_table(columns='train_term', index=['crse','styp_code','pred_term'], values=val, aggfunc=[pctl(0),pctl(25),pctl(50),pctl(75),pctl(100)])\n",
    "            .rename_axis(columns=[val,'train_term'])\n",
    "            .stack(0)\n",
    "            .assign(abs_mean = lambda x: x.abs().mean(axis=1))\n",
    "        )\n",
    "        return Y\n",
    "\n",
    "    for k, v in self.pred.items():\n",
    "        df = v['summary']\n",
    "        mask = df.eval(f\"pred_term!={self.infer_term}\")\n",
    "        v['rslt'] = {stat: pivot(df[mask], stat) for stat in [\"pred\",\"err\",\"err%\",\"mse%\",\"f1_inv%\"]} | {'pred': pivot(df[~mask], \"pred\")}\n",
    "        # rslt['pred'] = pivot(df[~mask], \"pred\")\n",
    "# rslt = {stat: pivot(df.query(f\"pred_term!={self.infer_term}\"), stat) for stat in [\"pred\",\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "\n",
    "# rslt['pred'] = pivot(df.query(f\"pred_term=={self.infer_term}\"), \"pred\")\n",
    "rslt['pred']\n",
    "rslt['err%']\n",
    "# pivot(df.query(f\"pred_term=={self.infer_term}\"), \"pred\", q=25)\n",
    "\n",
    "# list(self.pred.keys())[0]\n",
    "# val = 'err%'\n",
    "# q = 50\n",
    "# df.query(f\"pred_term!={self.infer_term}\").reset_index().pivot_table(columns='train_term', index=['crse','pred_term','styp_code'], values=val, aggfunc=pctl(q))\n",
    "# df.query(f\"pred_term=={self.infer_term}\").reset_index().pivot_table(columns='train_term', index=['crse','pred_term','styp_code'], values=val, aggfunc=pctl(q))\n",
    "# pivot(df.query(f\"pred_term!={self.infer_term}\"), 'err%')\n",
    "# {stat: pivot(df.query(f\"pred_term!={self.infer_term}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "# pivot(df.query(f\"pred_term=={self.infer_term}\"), \"pred\")\n",
    "# pd.concat([pivot(df.query(f\"pred_term=={self.infer_term}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "# for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k,str(v)) for k,v in est.named_steps.items()]\n",
    "# est.get_params()\n",
    "# est['imp'].__repr__()\n",
    "# est['imp']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return 3\n",
    "g.__name__ = 'hi'\n",
    "g.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Pipeline(verbose=False, steps=[\n",
    "    # ('prc', ColumnTransformer([('cat', OneHotEncoder(), lambda X: X.apply(pd.api.types.is_string_dtype))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    ('prc', ColumnTransformer([('cat', OneHotEncoder(), lambda X: X.select_dtypes(['string','category']).columns)], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    \n",
    "    # ('imp', IterativeImputer()),\n",
    "    # ('clf', HistGradientBoostingClassifier()),\n",
    "])\n",
    "\n",
    "p = cartesian(param_grid)[0]\n",
    "est.set_params(**p).fit_transform(self.Z).disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.select_dtypes(['string','category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.nan\n",
    "# x=None\n",
    "x in [np.nan], x == np.nan, x is np.nan\n",
    "np.fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cartesian(param_grid)[0]\n",
    "est.set_params(**p)\n",
    "P = est.get_params()\n",
    "P2 = clone(est).get_params()\n",
    "w = {k: (v,P2[k]) for k,v in P.items() if v!=P2[k]}\n",
    "w.keys()\n",
    "for k,v in w.items():\n",
    "    print(k)\n",
    "    print(type(v[0]))\n",
    "    print(type(v[1]))\n",
    "    print(\"-----------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda X: X.apply(pd.api.types.is_string_dtype)\n",
    "g(self.Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Pipeline(verbose=False, steps=[\n",
    "    ('prc', ColumnTransformer([('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), lambda X: X.apply(pd.api.types.is_string_dtype))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    # ('prc', ColumnTransformer([('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    # ('imp', IterativeImputer()),\n",
    "    # ('clf', HistGradientBoostingClassifier()),\n",
    "])\n",
    "\n",
    "e2 = clone(est)\n",
    "P = est.get_params()\n",
    "P2 = clone(est).get_params()\n",
    "w = {k: (v,P2[k]) for k,v in P.items() if v!=P2[k]}\n",
    "w.keys()\n",
    "w['prc__cat']\n",
    "# print(est['prc'].get_params())\n",
    "# print(clone(est)['prc'].get_params())\n",
    "# est.fit_transform(self.Z).disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x: pd.api.types.is_string_dtype(x)\n",
    "g(self.Z['__styp_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = self.X.select_dtypes(['string','category']).columns.tolist()\n",
    "est = Pipeline(verbose=False, steps=[\n",
    "    ('prc', ColumnTransformer([('cat', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), cat)], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    ('imp', IterativeImputer()),\n",
    "    ('clf', HistGradientBoostingClassifier()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.named_steps['enc'].__str__()\n",
    "est.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['end'].disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = est\n",
    "model._params = tuple([('n_sims',3)] + sorted((k,v) for k,v in model.get_params(deep=True).items() if isinstance(v, (int,float,str,bool)) and v not in [None,np.nan]))\n",
    "S = self.predict(est.set_params(enc__enc__min_frequency=0.1), '_total', 202208, 'n')\n",
    "S[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = list(self.pred.values())[0]#['_total'][202008]['n']\n",
    "A.keys()\n",
    "A['summary']\n",
    "# A['summary']\n",
    "# [202208]#['n']#.keys()#['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = cartesian(param_grid)[0]\n",
    "model = clone(est).set_params(**params)\n",
    "P = tuple([('n_sims',3)] + sorted((k,v) for k,v in model.get_params(deep=True).items() if isinstance(v, (int,float,str,bool)) and v not in [None,np.nan]))\n",
    "Q = list(self.pred.keys())[0]\n",
    "len(P), len(Q)\n",
    "for p,q in zip(P,Q):\n",
    "    print(p==q,p,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.pred.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Pipeline(verbose=False, steps=[\n",
    "    ('enc', ColumnTransformer([('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(self.X, self.Y['end']['_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.disp()\n",
    "m.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.pred.values())[0].keys()\n",
    "# self.pred.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(1,2),(2,3), (1,2,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ColumnTransformer([('enc', OneHotEncoder)], remainder='passthrough', verbose_feature_names_out=False)\n",
    "b = clone(a)\n",
    "# a.get_params() == \n",
    "b.get_params\n",
    "# dir(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted((k,v) for k,v in est.get_params(deep=True).items() if isinstance(v, (int,float,str,bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Pipeline(verbose=False, steps=[\n",
    "    ('enc', ColumnTransformer([('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    ('imp', IterativeImputer(random_state=self.random_state)),\n",
    "    ('clf', HistGradientBoostingClassifier(random_state=self.random_state)),\n",
    "])\n",
    "est._pa\n",
    "# est2 = clone(est)\n",
    "# eq = False\n",
    "# P = est.get_params()\n",
    "# Q = est2.get_params()\n",
    "# N = [None,np.nan,pd.NA]\n",
    "\n",
    "get_params = lambda est: {k:v for k,v in est.get_params(deep=True) if isinstance(v, (int,float,str,bool))}\n",
    "\n",
    "# if P.keys() == Q.keys():\n",
    "#     eq = all(v==Q[k] or pd.isnull([v,Q[k]]).all() for k,v in P.items() if isinstance(v, (int,float,str,bool,type,type(None))))\n",
    "# eq\n",
    "# d\n",
    "    # for k, v in P.items():\n",
    "    #     if isinstance(v, (int,float,str,bool,type,type(None))):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.NA\n",
    "isinstance(v, (int,float,str,bool,type,type(None),pd.NA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pd.NA)\n",
    "np.isnan([1])\n",
    "pd.isnull(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull([1,None]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Pipeline(verbose=False, steps=[\n",
    "    ('enc', ColumnTransformer([('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    ('imp', IterativeImputer(random_state=self.random_state)),\n",
    "    ('clf', HistGradientBoostingClassifier(random_state=self.random_state)),\n",
    "])\n",
    "est.get_params(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import dump, load\n",
    "import joblib \n",
    "from sklearn.base import clone\n",
    "est = Pipeline(verbose=False, steps=[\n",
    "    ('enc', ColumnTransformer([('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    ('imp', IterativeImputer(random_state=self.random_state)),\n",
    "    ('clf', HistGradientBoostingClassifier(random_state=self.random_state)),\n",
    "])\n",
    "est = Pipeline(verbose=False, steps=[\n",
    "    ('enc', ColumnTransformer([('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "    ('imp', IterativeImputer(random_state=self.random_state)),\n",
    "    ('clf', HistGradientBoostingClassifier(random_state=self.random_state)),\n",
    "])\n",
    "\n",
    "# s = pickle.dump(est)\n",
    "# est2 = pickle.load(est)\n",
    "f = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/admitted_matriculation_predictor/src/temp.joblib'\n",
    "s = joblib.dump(est, f)\n",
    "est2 = joblib.load(f)\n",
    "est == est2\n",
    "\n",
    "\n",
    "# est2 = clone(est)\n",
    "# est == est2\n",
    "# # est2\n",
    "N = est.named_steps\n",
    "E = N['enc']\n",
    "P = est.get_params(deep=True)\n",
    "for k, v in P.items():\n",
    "    if not isinstance(v, (int,float,str,bool,type,type(None))):\n",
    "        print(k, type(v))\n",
    "    # print(k, type(v), isinstance(v, (int,float,str,bool,type,type(None))))\n",
    "# N2 = est2.named_steps\n",
    "# N.keys() == N2.keys()\n",
    "# for k in N.keys():\n",
    "#     # print(k)\n",
    "#     P = N[k].get_params()\n",
    "#     P2 = N2[k].get_params()\n",
    "#     print(P.keys() == P2.keys())\n",
    "#     for l in P.keys():\n",
    "#         if P[l] != P2[l]:\n",
    "#             print(k, l)\n",
    "#             print(P[l])\n",
    "#             print(P2[l])\n",
    "\n",
    "# #         print()\n",
    "# #     print()\n",
    "# # print(N['enc'].get_params())\n",
    "# # print(N2['enc'].get_params())\n",
    "# # est.get_params()\n",
    "# # est.named_steps == est2.named_steps\n",
    "# # est."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "ColumnTransformer(transformers=[('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)\n",
    "make_column_transformer((OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category'])), remainder='passthrough', verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # ('enc', ColumnTransformer([('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "                # ('imp', IterativeImputer(random_state=self.random_state)),\n",
    "                # ('clf', HistGradientBoostingClassifier(random_state=self.random_state)),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "G = {\n",
    "    'enc': {\n",
    "        ColumnTransformer: {\n",
    "            'tranformers':\n",
    "        OneHotEncoder: {\n",
    "            'sparse_output': False,\n",
    "            'handle_unknown': 'infrequent_if_exist',\n",
    "            'min_frequency': [0.1,0.2],\n",
    "        },\n",
    "        LabelEncoder: {\n",
    "            'sparse_output': False,\n",
    "            'handle_unknown': 'infrequent_if_exist',\n",
    "            'min_frequency': [0.1,0.2],\n",
    "        },\n",
    "    },\n",
    "    'imp': {\n",
    "        IterativeImputer: {\n",
    "            'initial_strategy': ['median','mean'],\n",
    "        },\n",
    "    }\n",
    "    # __enc__min_frequency':[0.1],\n",
    "    # # 'imp__initial_strategy': ['median'],\n",
    "    # 'clf__learning_rate': [0.1,0.2],\n",
    "    # 'n_sims': 4,\n",
    "}\n",
    "# cartesian({step: {meth: cartesian({name: listify(vals) for name, vals in M.items()}) for meth, M in S.items()} for step, S in G.items()})[0]\n",
    "# {step: {meth: cartesian({name: listify(vals) for name, vals in M.items()}) for meth, M in S.items()} for step, S in G.items()}['enc']\n",
    "# cartesian({step: {meth: {name: listify(vals) for name, vals in M.items()} for meth, M in S.items()} for step, S in G.items()})\n",
    "\n",
    "# [{meth: values for values in cartesian(M)} for meth, M in G['enc'].items()]\n",
    "step = 'enc'\n",
    "# H = {step: [(method,values) for method, M in S.items() for values in cartesian(M) ] for step, S in G.items()}\n",
    "H = {step: [[method,values] for method, M in S.items() for values in cartesian(M)] for step, S in G.items()}\n",
    "q = cartesian(H)[0]\n",
    "\n",
    "# meth = OneHotEncoder\n",
    "# {meth: cartesian(G['enc'][meth])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # ('enc', ColumnTransformer([('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "                # ('imp', IterativeImputer(random_state=self.random_state)),\n",
    "                # ('clf', HistGradientBoostingClassifier(random_state=self.random_state)),\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "G = {\n",
    "    'enc': {\n",
    "        OneHotEncoder: {\n",
    "            'sparse_output': False,\n",
    "            'handle_unknown': 'infrequent_if_exist',\n",
    "            'min_frequency': [0.1,0.2],\n",
    "        },\n",
    "        LabelEncoder: {\n",
    "            'sparse_output': False,\n",
    "            'handle_unknown': 'infrequent_if_exist',\n",
    "            'min_frequency': [0.1,0.2],\n",
    "        },\n",
    "    },\n",
    "    'imp': {\n",
    "        IterativeImputer: {\n",
    "            'initial_strategy': ['median','mean'],\n",
    "        },\n",
    "    }\n",
    "    # __enc__min_frequency':[0.1],\n",
    "    # # 'imp__initial_strategy': ['median'],\n",
    "    # 'clf__learning_rate': [0.1,0.2],\n",
    "    # 'n_sims': 4,\n",
    "}\n",
    "# cartesian({step: {meth: cartesian({name: listify(vals) for name, vals in M.items()}) for meth, M in S.items()} for step, S in G.items()})[0]\n",
    "# {step: {meth: cartesian({name: listify(vals) for name, vals in M.items()}) for meth, M in S.items()} for step, S in G.items()}['enc']\n",
    "# cartesian({step: {meth: {name: listify(vals) for name, vals in M.items()} for meth, M in S.items()} for step, S in G.items()})\n",
    "\n",
    "# [{meth: values for values in cartesian(M)} for meth, M in G['enc'].items()]\n",
    "step = 'enc'\n",
    "# H = {step: [(method,values) for method, M in S.items() for values in cartesian(M) ] for step, S in G.items()}\n",
    "H = {step: [[method,values] for method, M in S.items() for values in cartesian(M)] for step, S in G.items()}\n",
    "q = cartesian(H)[0]\n",
    "\n",
    "# meth = OneHotEncoder\n",
    "# {meth: cartesian(G['enc'][meth])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred['_total'][0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = {'train': T} | {k: pd.concat([t[k] for t in T.values()]) for k in list(T.values()).pop().keys()}\n",
    "# {k: 0 for k in list(T.values()).pop().keys()}\n",
    "# T\n",
    "\n",
    "\n",
    "# rslt = {'param':param, 'train': {train_term: self.predict(crse, param.copy(), train_term) for train_term in self.term_codes}}\n",
    "# self.pred.setdefault(crse,list()).append(rslt)\n",
    "rslt['summary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'a':3}\n",
    "# # d[d.keys().pop()]\n",
    "# d.keys().__iter__()[0]\n",
    "v = list(d.values())[0]\n",
    "v\n",
    "# dir(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "w = self.pred[crse][0]\n",
    "q = w['train']\n",
    "q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "W = self.pred[crse][0]\n",
    "# for train_term, sims in W['train'].items():\n",
    "#     for sim in sims:\n",
    "#         for rslt, df in sim.items():\n",
    "#             print(rslt)\n",
    "# W |= {rslt: pd.concat([df for df in sim[rslt]])}\n",
    "\n",
    "rslt = 'details'\n",
    "L = [sim[rslt] for sims in W['train'].values() for sim in sims]\n",
    "\n",
    "crse = '_total'\n",
    "W = self.pred[crse][0]\n",
    "W |= {rslt: pd.concat([sim[rslt] for sims in W['train'].values() for sim in sims]) for rslt in ['details','summary']}\n",
    "W.keys()\n",
    "    \n",
    "    \n",
    "    # df in sim[rslt]\n",
    "\n",
    "\n",
    "        # print(sim.keys())\n",
    "    # print(len(rslt))\n",
    "    # print(rslt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations = 3\n",
    "\n",
    "# opts = dict()\n",
    "# opts['random_state'] = 42\n",
    "# opts['save_all_iterations'] = False\n",
    "# opts['datasets'] = 5\n",
    "# opts['mean_match_candidates'] = 29\n",
    "# opts['mean_match_function'] = mean_match_kdtree_classification\n",
    "\n",
    "# opts['datasets'] = 2\n",
    "# opts['mean_match_candidates'] = 1\n",
    "# opts['mean_match_function'] = default_mean_match\n",
    "\n",
    "# P = self.predict(opts=opts)\n",
    "\n",
    "# R = self.train(iterations=iterations, opts=opts,\n",
    "#     styp_codes='n',\n",
    "#     # train_terms=202208,\n",
    "#     )\n",
    "# for k, v in R[False]['rslt'].items():\n",
    "#     print(k)\n",
    "#     v['err%'].disp(100)\n",
    "\n",
    "# tune = []\n",
    "# # for func in [mean_match_kdtree_classification, default_mean_match]:\n",
    "#     # opts['mean_match_function'] = func\n",
    "# for cand in range(2,41,3):\n",
    "#     opts['mean_match_candidates'] = cand\n",
    "#     print(mysort(opts))\n",
    "#     R = self.train(\n",
    "#         styp_codes='n',\n",
    "#         iterations=iterations,\n",
    "#         opts=opts)\n",
    "#     R[False]['rslt']['_total','n']['err%'].disp(100)\n",
    "#     tune.append(R)\n",
    "#     write(self.tune, tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "seed = 0\n",
    "n_sims = 2\n",
    "param_grid = cartesian({\n",
    "    'enc__enc__min_frequency':[0.05,0.1],\n",
    "    'imp__initial_strategy': ['median'],\n",
    "    'clf__learning_rate': [0.1],\n",
    "})\n",
    "\n",
    "rslt = dict()\n",
    "# for crse, param, train_term in it.product(self.crse, param_grid, self.term_codes):\n",
    "for crse in self.crse:\n",
    "    for param in param_grid:\n",
    "        for train_term in self.term_codes:\n",
    "    print(crse, train_term, param)\n",
    "    rslt.setdefault(crse, list()).append({'param':param, 'train':dict()})\n",
    "    cols = uniquify([*self.feat,'_total_cur',crse+'_cur',crse])\n",
    "    X = self.Z[cols]\n",
    "    X = {'test': X, 'train': X.query(f\"term_code==@train_term\")}\n",
    "    y = {k: x.pop(crse) for k, x in X.items()}\n",
    "    for sim in range(n_sims):\n",
    "        est = Pipeline(verbose=False, steps=[\n",
    "            ('enc', ColumnTransformer([('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category']))], remainder='passthrough', verbose_feature_names_out=False)),\n",
    "            ('imp', IterativeImputer(random_state=seed)),\n",
    "            ('clf', HistGradientBoostingClassifier(random_state=seed)),\n",
    "        ]).set_params(**param).fit(X['train'], y['train'])\n",
    "        details = (\n",
    "            y['test']\n",
    "            .rename('true')\n",
    "            .to_frame()\n",
    "            .assign(pred=est.predict(X['test']), train_term=train_term, crse=crse, sim=sim)\n",
    "            .set_index(['train_term','crse','sim'], append=True)\n",
    "            .binarize()\n",
    "        )\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        summary = details.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            summary[x] = summary[x] * summary['mlt']\n",
    "        summary.insert(2, 'err', summary['pred'] - summary['true'])\n",
    "        summary.insert(3, 'err%', (summary['err'] / summary['true']).clip(-1, 1) * 100)\n",
    "        rslt[crse][-1]['train'].setdefault(train_term, list()).append({'details':details, 'summary':summary})\n",
    "        # assert 1==2\n",
    "\n",
    "    # rslt[crse][-1]['train'].setdefault(train_term, list()).append({'details':, 'summary':  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary.disp(1)\n",
    "r = rslt['_total'][0]\n",
    "r['param']\n",
    "r['train'][202008][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian(dct):\n",
    "    \"\"\"Creates the Cartesian product of a dictionary with list-like values\"\"\"\n",
    "    D = {key: listify(val) for key, val in dct.items()}\n",
    "    return [dict(zip(D.keys(), x)) for x in it.product(*D.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "seed = 0\n",
    "train_term = 202208\n",
    "crse = '_total'\n",
    "cols = list({'_total',crse})\n",
    "\n",
    "for sim in range(1):\n",
    "    X = (\n",
    "        self.X\n",
    "        .join(self.Y['cur'][cols].rename(columns=lambda x:x+'_cur'))\n",
    "        .join(self.Y['end'][crse]>0)\n",
    "        .assign(train_term=train_term, crse=crse, sim=sim)\n",
    "        .prep()\n",
    "        .set_index(['train_term','crse','sim'], append=True)\n",
    "    )\n",
    "    X = {'test': X.copy(), 'train': X.query(f\"term_code==@train_term\")}\n",
    "    y = {k: x.pop(crse) for k, x in X.items()}\n",
    "\n",
    "    enc = ColumnTransformer(remainder='passthrough', verbose_feature_names_out=False, transformers=[\n",
    "        ('enc', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['string','category'])),\n",
    "    ])\n",
    "\n",
    "    est = Pipeline(verbose=False, steps=[\n",
    "        ('enc', enc),\n",
    "        ('imp', IterativeImputer(random_state=seed)),\n",
    "        ('clf', HistGradientBoostingClassifier(random_state=seed)),\n",
    "    ])\n",
    "    param_grid = {\n",
    "        'enc__enc__min_frequency':[0.05],\n",
    "        'imp__initial_strategy': ['median'],\n",
    "        'clf__learning_rate': [0.2],\n",
    "    }\n",
    "    grid = GridSearchCV(estimator=est, param_grid=param_grid)\n",
    "    grid.fit(X['train'], y['train'])\n",
    "    model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = y['test'].rename('true').to_frame().assign(pred=model.predict(X['test'])).binarize()\n",
    "P.disp(1)\n",
    "agg = lambda x: pd.Series({\n",
    "    'pred': x['pred'].sum(min_count=1),\n",
    "    'true': x['true'].sum(min_count=1),\n",
    "    'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "})\n",
    "S = P.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "# # # S.insert(2, 'err', S['pred'] - S['true'])\n",
    "# # # S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(check_params_exist(pipe, 'imputer'))\n",
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = pipe['enc']\n",
    "vars(e)\n",
    "# e.onehotencoder\n",
    "e.named_transformers_['onehotencoder']\n",
    "e.transformers_[0]\n",
    "# e.onehotencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit_transform(X['train']).disp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pick imp & clf hyperparams\n",
    "imp m datasets\n",
    "draw n shuffled datasets\n",
    "train on one year\n",
    "predict on others\n",
    "apply multiplier\n",
    "compute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query('idx==0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "train_term = 202208\n",
    "\n",
    "iterations = 3\n",
    "opts = dict()\n",
    "opts['random_state'] = 42\n",
    "opts['save_all_iterations'] = False\n",
    "opts['datasets'] = 2\n",
    "opts['mean_match_candidates'] = 29\n",
    "cols = list({'_total',crse})\n",
    "\n",
    "imp = ImputationKernel(self.X, **opts)\n",
    "imp.mice(iterations)\n",
    "self.Z = (\n",
    "    pd.concat([imp.complete_data(k).assign(sim=k) for k in range(imp.dataset_count())])\n",
    "    .pipe(pd.get_dummies)\n",
    "    .join(self.Y['cur'][cols].rename(columns=lambda x:x+'_cur'))\n",
    "    .join(self.Y['end'][crse]>0)\n",
    "    .prep()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.query('\"index\"==17404')\n",
    "\n",
    "# .query('pidm==2710').disp(1000)#.query('index==0')#.shape#.sort_index().disp(10)\n",
    "# self.Z.groupby('pidm').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z = (\n",
    "    pd.concat([\n",
    "        imp.complete_data(k)\n",
    "        .assign(sim=k)\n",
    "        \n",
    "    for k in range(imp.dataset_count())])\n",
    "    .pipe(pd.get_dummies)\n",
    "    .join(self.Y['cur'][cols].rename(columns=lambda x:x+'_cur'))\n",
    "    .join(self.Y['end'][crse]>0)\n",
    "    .prep()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.groupby(self.attr).ngroup().sort_index().disp(10)\n",
    "# self.Z.groupby('index')\n",
    "self.X = self.X.reset_index().reset_index().set_index(['index',*self.attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "train_term = 202208\n",
    "# Z = self.Z.reset_index().sample(frac=1).drop_duplicates(self.attr).assign(train_term=train_term, crse=crse).set_index([*self.attr,'train_term','crse','sim'])\n",
    "Z = (\n",
    "    self.Z\n",
    "    .sample(frac=1)\n",
    "    .reset_index()\n",
    "    .drop_duplicates(self.attr)\n",
    "    .assign(train_term=train_term, crse=crse)\n",
    "    .set_index([*self.attr,'train_term','crse','sim'])\n",
    ")\n",
    "X = {'test':Z, 'train':Z.query(f'term_code=={train_term}')}\n",
    "y = {k: v.pop(crse) for k, v in X.items()}\n",
    "clf = HistGradientBoostingClassifier()\n",
    "clf.fit(X['train'], y['train'])\n",
    "P = y['test'].rename('true').to_frame().assign(pred=clf.predict(X['test'])).binarize()\n",
    "\n",
    "agg = lambda x: pd.Series({\n",
    "    'pred': x['pred'].sum(min_count=1),\n",
    "    'true': x['true'].sum(min_count=1),\n",
    "    'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "})\n",
    "S = P.groupby([*self.mlt_grp,'train_term']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "# S.insert(2, 'err', S['pred'] - S['true'])\n",
    "# S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "S\n",
    "\n",
    "# P.groupby([*self.mlt_grp,'train_term','crse','sim']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "A = agg(self.reg_df['end'])\n",
    "self.Y = {k: self.X[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in self.reg_df.items()}\n",
    "B = agg(self.Y['end'])\n",
    "M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(f\"term_code != {self.infer_term}\").prep()\n",
    "N = M.assign(term_code=self.infer_term)\n",
    "self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "# self.Y = Y\n",
    "self.Y = {k: y.squeeze().unstack().dropna(how='all', axis=1).fillna(0) for k, y in self.Y.items()}\n",
    "self.Y['end'].disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Y = {k: y.squeeze().unstack().dropna(how='all', axis=1).fillna(0) for k, y in Y.items()}\n",
    "self.Y['end'].groupby(self.mlt_grp).agg(lambda x:(x>0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlt_grp = ['levl_code', 'styp_code', 'term_code','crse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]) for k in ['cur','end']}\n",
    "agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "A = agg(Y['end'])\n",
    "# A.disp(10)\n",
    "Y = {k: self.X[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in Y.items()}\n",
    "B = agg(Y['end'])\n",
    "M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(f\"term_code != {self.infer_term}\").prep()\n",
    "N = M.assign(term_code=self.infer_term)\n",
    "self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "self.Y = {k: y.squeeze().unstack().dropna(how='all', axis=1).fillna(0) for k, y in Y.items()}\n",
    "\n",
    "fat = lambda y: y.squeeze().unstack('crse').dropna(how='all', axis=1).fillna(0)\n",
    "# fat(self.mlt)\n",
    "self.mlt.squeeze()#unstack('crse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]) for k in ['cur','end']}\n",
    "agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "A = agg(Y['end'])\n",
    "# A.disp(10)\n",
    "Y = {k: self.X[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in Y.items()}\n",
    "B = agg(Y['end'])\n",
    "M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(f\"term_code != {self.infer_term}\").prep()\n",
    "N = M.assign(term_code=self.infer_term)\n",
    "self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "self.mlt\n",
    "\n",
    "# self.Y = Y\n",
    "# fat = lambda y: y.squeeze().unstack('crse').dropna(how='all', axis=1).fillna(0)\n",
    "# self.Y = {k: fat(y) for k, y in Y.items()}\n",
    "# self.mlt\n",
    "# fat(self.mlt)\n",
    "# self.Y = {k: y.squeeze().unstack('crse').dropna(how='all', axis=1).fillna(0) for k, y in Y.items()}\n",
    "# self.Y['end'].disp(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = self.mlt_grp\n",
    "w.pop(0)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    Y = {k:\n",
    "         pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()])\n",
    "         .set_index(['pidm',*w,'crse'])['credit_hr'].unstack()\n",
    "          \n",
    "          \n",
    "           for k in ['cur','end']}\n",
    "agg = lambda y: where(y).groupby(w).agg(lambda x: (x>0).sum()).prep()\n",
    "A = agg(Y['end'])\n",
    "# A.disp(100)\n",
    "Y = {k: self.X[[]].join(y.droplevel(['levl_code','styp_code'])) for k, y in Y.items()}\n",
    "# B = agg(Y['end'])\n",
    "# M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(f\"term_code != {self.infer_term}\").prep()\n",
    "\n",
    "# N = M.assign(term_code=self.infer_term)\n",
    "# self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "# self.Y = {k: y.squeeze().unstack().dropna(how='all', axis=1).fillna(0) for k, y in Y.items()}\n",
    "Y['end'].droplevel('levl_code')\n",
    "\n",
    "# Z = (\n",
    "#     self.X\n",
    "#     .pipe(pd.get_dummies)\n",
    "#     .join(self.Y['cur'][cols].rename(columns=lambda x:x+'_cur'))\n",
    "#     .join(self.Y['end'][crse]>0)\n",
    "#     .prep()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['cur'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(self.Z.query('sim==0')[crse]>0).groupby(['styp_code','term_code']).sum()\n",
    "1777*1.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.query('sim==0')[crse].groupby(['styp_code','term_code']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(self.Y['end']>0).groupby(w).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = self.mlt_grp\n",
    "w.pop(0)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z['_total'].groupby(w).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "Q = (self.Y['end'][[crse]]>0).assign(crse=crse).groupby(self.mlt_grp).sum().join(self.mlt)\n",
    "Q[crse] *= Q['mlt']\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "train_term = 202208\n",
    "# Z = self.Z.reset_index().sample(frac=1).drop_duplicates(self.attr).assign(train_term=train_term, crse=crse).set_index([*self.attr,'train_term','crse','sim'])\n",
    "Z = (\n",
    "    self.Z\n",
    "    .sample(frac=1)\n",
    "    .reset_index()\n",
    "    .drop_duplicates(self.attr)\n",
    "    .assign(train_term=train_term, crse=crse)\n",
    "    .set_index([*self.attr,'train_term','crse','sim'])\n",
    ")\n",
    "X = {'train': Z.query(f'term_code=={train_term}'), 'test': Z}\n",
    "y = {k: v.pop(crse) for k, v in X.items()}\n",
    "clf = HistGradientBoostingClassifier()\n",
    "clf.fit(X['train'], y['train'])\n",
    "P = y['test'].rename('true').to_frame().assign(pred=clf.predict(X['test'])).binarize()\n",
    "\n",
    "agg = lambda x: pd.Series({\n",
    "    'pred': x['pred'].sum(min_count=1),\n",
    "    'true': x['true'].sum(min_count=1),\n",
    "    'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "})\n",
    "S = P.groupby([*self.mlt_grp,'train_term']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "# S.insert(2, 'err', S['pred'] - S['true'])\n",
    "# S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "S\n",
    "\n",
    "# P.groupby([*self.mlt_grp,'train_term','crse','sim']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.term[202208].reg['cur'].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "attr = [\n",
    "        'term_code',\n",
    "        'pidm',\n",
    "        'hs_qrtl',\n",
    "    ]\n",
    "feat= [\n",
    "        'term_code',\n",
    "        ['birth_day','median',['term_code','styp_code']],\n",
    "        ['international',False],\n",
    "]\n",
    "\n",
    "def f(A):\n",
    "    A = [listify(x) for x in A]\n",
    "    return {x.pop(0): x if x else [np.nan] for x in A}\n",
    "L = [f(attr), f(feat)]\n",
    "cols = L[0] | L[1]\n",
    "attr, feat = [list(x.keys()) for x in L]\n",
    "\n",
    "# attr = f(attr)\n",
    "# feat = f(feat)\n",
    "# cols = attr | feat\n",
    "# attr = list(attr.keys())\n",
    "# feat = list(feat.keys())\n",
    "\n",
    "# attr\n",
    "# c0\n",
    "\n",
    "# for A in [attr, feat]:\n",
    "#     A = [listify(x) for x in A]\n",
    "#     cols |= {x.pop(0): x if x else [np.nan] for x in A}\n",
    "#     A = list(A.keys())\n",
    "\n",
    "# attr = [listify(x) for x in attr]\n",
    "# feat = [listify(x) for x in feat]\n",
    "# feat = {x.pop(0): x if x else [np.nan] for x in feat}\n",
    "# attr = {x.pop(0): x if x else [np.nan] for x in attr}\n",
    "# cols = attr | feat\n",
    "# attr = list(attr.keys())\n",
    "# feat = list(feat.keys())\n",
    "# # cols = {x.pop(0): x if x else [np.nan] for x in attr+feat}\n",
    "# # print(cols)\n",
    "# where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "# X = where(self.X)\n",
    "# for k, v in cols.items():\n",
    "#     X[k] = X.impute(k, *v)\n",
    "# X.missing()\n",
    "# X = X.prep().binarize().categorize().set_index(attr, drop=False)[feat].rename(columns=lambda col:'_'+col)\n",
    "# X\n",
    "cols\n",
    "attr\n",
    "# feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = {x: [np.nan] for x in self.attr}\n",
    "feat = {x[0][1:]:listify(x[1]) for x in self.feat}\n",
    "cols = attr | feat\n",
    "# cols = {k:listify(v) for k,v in cols.items()}\n",
    "cols\n",
    "# where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "# X = where(self.X)\n",
    "# X.missing().disp(1000)\n",
    "# cols\n",
    "# for k, v in cols.items():\n",
    "#     X[k] = X.impute(k, *listify(v))\n",
    "# X = X.prep().binarize().categorize()\n",
    "# X.missing().disp(1000)\n",
    "# Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "\n",
    "# col = uniquify(self.attr + feat)\n",
    "\n",
    "\n",
    "\n",
    "# .set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "# # X = where(self.X).reset_index().set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "# self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['cur'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = y['test'].rename('true').to_frame().assign(train_term=train_term, crse=crse, pred=clf.predict(X['test'])).binarize()\n",
    "P.groupby([*self.mlt_grp,'train_term','crse']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['train'].disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.shape, Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([imp.complete_data(k).assign(sim=k) for k in range(imp.dataset_count())]).transform(pd.get_dummies).disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['cur'].disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = (\n",
    "    pd.concat([imp.complete_data(k).assign(sim=k) for k in range(imp.dataset_count())])\n",
    "    .pipe(pd.get_dummies)\n",
    "    .join(self.Y['cur'][cols].rename(columns=lambda x:x+'_cur'))\n",
    "    .join(self.Y['end'][crse])\n",
    "    .reset_index()\n",
    "    .sample(frac=1)\n",
    "    .drop_duplicates(self.attr)\n",
    "    .set_index([*self.attr,'sim'])\n",
    ")\n",
    "Z\n",
    "# pd.get_dummies(Z)\n",
    "\n",
    "# X = Z.reset_index().sample(frac=1).drop_duplicates(self.attr).set_index([*self.attr,'sim'])\n",
    "# train_term = 202208\n",
    "# qry = {'infer': f'term_code=={self.infer_term}', 'train': f'term_code=={train_term}'}\n",
    "# qry['test'] = f\"~({join(qry.values(),'|')})\"\n",
    "# X = {k: X.query(v) for k, v in qry.items()}\n",
    "# X = {'train': Z.query(f'term_code=={train_term}'), 'test': Z.query(f'term_code!={train_term}')}\n",
    "\n",
    "\n",
    "\n",
    "# X['test'].vc('term_code')\n",
    "# X = {\"infer\":X.query(f\"term_code=={self.infer_term}\"), \"train\"}\n",
    "\n",
    "# Z#.index#['index']\n",
    "# Z.loc['pidm']\n",
    "# Z.index.names\n",
    "# Z.groupby('index').size()\n",
    "# Z = Z.sample(frac=1)\n",
    "# Z\n",
    "# Z.reset_index?\n",
    "\n",
    "# ('index', drop=False)#.drop_duplicates('index')#.vc('sim')\n",
    "# sample(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "qry = {\"infer\": f\"term_code=={self.infer_term}\", \"train\": f\"term_code==train_term\"}\n",
    "qry['test'] = \"~(\"+join(qry.values() ,' | ')+\")\"\n",
    "X = dict()\n",
    "y = dict()\n",
    "for k, v in qry.items():\n",
    "    X[k] = Z.query(v)\n",
    "    y[k] = X[k].pop(crse)\n",
    "# clf = RandomForestClassifier(categorical_features=self.Z.select_dtypes('category').columns.tolist())\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "clf = HistGradientBoostingClassifier()#categorical_features=X['train'].select_dtypes('category').columns.tolist())\n",
    "# clf.categorical_features\n",
    "# X['train'].dtypes\n",
    "clf.fit(X['train'], y['train'])\n",
    "y['pred'] = clf.predict(X['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['pred'] = clf.predict(X['test']).astype('boolean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = y['test'].rename('true').to_frame().assign(pred=y['pred']).binarize().assign(crse=crse)\n",
    "details.groupby([*self.mlt_grp,'train_term','sim']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(Z).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.query('coll_code==00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z.columns)\n",
    "W = pd.get_dummies(self.Z)\n",
    "print(W.columns)\n",
    "W[W['_coll_code_00']].disp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat([imp.complete_data(k).join(self.Y['end'][crse]>0).assign(train_term=train_term, sim=k).set_index(['train_term','sim'], append=True) for k in range(imp.dataset_count())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.select_dtypes('category').columns.tolist()\n",
    "# pd.api.types.is_string_dtype(x) for x in self.Z)\n",
    "# A = self.Z.dtypes.to_frame()\n",
    "# A.query(\"0=='index\")\n",
    "# A[A=='category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "qry = {\"infer\": f\"term_code=={self.infer_term}\", \"train\": f\"term_code==train_term\"}\n",
    "qry['test'] = \"~(\"+join(qry.values() ,' | ')+\")\"\n",
    "X = dict()\n",
    "y = dict()\n",
    "Z = pd.get_dummies(Z)\n",
    "for k, v in qry.items():\n",
    "    X[k] = pd.get_dummies(Z).query(v)\n",
    "    y[k] = X[k].pop(crse)\n",
    "# clf = RandomForestClassifier(categorical_features=self.Z.select_dtypes('category').columns.tolist())\n",
    "clf = HistGradientBoostingClassifier()#categorical_features=X['train'].select_dtypes('category').columns.tolist())\n",
    "# clf.categorical_features\n",
    "# X['train'].dtypes\n",
    "clf.fit(X['train'], y['train'])\n",
    "# y['pred'] = clf.predict(X['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['infer'].vc('term_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I[0].join(self.Y['end'][crse]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = P['model']\n",
    "predictor_var_names = [self._get_variable_name(i) for i in np.sort(self.predictor_vars)]\n",
    "imputed_var_names   = [self._get_variable_name(i) for i in self.imputation_order]\n",
    "I = pd.DataFrame(self.get_feature_importance(0), index=imputed_var_names, columns=predictor_var_names).T\n",
    "I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = P['model']\n",
    "# [model._get_variable_name(i) for i in model.imputation_order]\n",
    "# model.imputation_order\n",
    "# [model._get_variable_name(int(i)) for i in np.sort(model.imputation_order)]\n",
    "model.vars_with_any_missing\n",
    "self.Z.columns[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "model = self.pred[k]['model']\n",
    "# [model._get_variable_name(int(i)) for i in np.sort(model.imputation_order)]\n",
    "# model.imputed_variable_count\n",
    "# model.column_names\n",
    "# print(self.pred[k]['meta'])\n",
    "model.feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.shape\n",
    "self.term[202208].adm['zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImputationKernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.binarize()['international'].dtype\n",
    "self.X['international'].dropna().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "X = where(self.X.binarize()).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "# X['_international'].disp(1)\n",
    "X.impute('_international', False)\n",
    "# X.dtypes.disp(1000)\n",
    "# self.X.dtypes.disp(100)\n",
    "# pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    s = set(ser.dropna())\n",
    "    if s:\n",
    "        try:\n",
    "            ser = ser.str.lower()\n",
    "            if s.issubset({'y','n'}):\n",
    "                ser = (ser=='y').astype('boolean').fillna(False)\n",
    "            if s.issubset({'true','false'}):\n",
    "                ser = (ser=='true').astype('boolean').fillna(False)\n",
    "        except:\n",
    "            if s.issubset({0,1}):\n",
    "                ser = ser.astype('boolean').fillna(False)\n",
    "    return ser\n",
    "A = R['international'].str.lower()\n",
    "(A=='true').astype('boolean').fillna(False)\n",
    "# binarize(A).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.term[202408].adm['international'].dtypes\n",
    "# self.reg\n",
    "R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "R['international'].value_counts()#.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.term[202208].adm['international'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R['international'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.columns\n",
    "self.X['international'].value_counts()\n",
    "# self.X['natn_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"select distinct B.gorvisa_natn_code_issue, B.gorvisa_vtyp_code from gorvisa B\"\"\"\n",
    "db.execute(qry).disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "t = TERM(term_code=202008, overwrite={'adm':True}, show={'adm':True})\n",
    "A = t.get_adm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('gorvisa')\n",
    "# db.value_counts('gorvisa','gorvisa_natn_code_issue','gorvisa_pidm')\n",
    "# qry = \"select * from (select gorvisa_pidm, count(gorvisa_natn_code_issue) as ct from gorvisa group by gorvisa_pidm) where ct>1\"\n",
    "# qry = \"select gorvisa_pidm, count(distinct gorvisa_natn_code_issue) as ct from gorvisa group by gorvisa_pidm order by ct desc\"\n",
    "# db.head(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select A.* from (\n",
    "    select \n",
    "        A.*,\n",
    "        case\n",
    "            when max(case when A.cycle_day >= 0 then A.cycle_date end) over (partition by A.pidm, A.appl_no) = A.cycle_date then 1\n",
    "            end as r1,\n",
    "        case\n",
    "            when sum(case when A.cycle_day <  0 then 1 end) over (partition by A.pidm, A.appl_no) >= 0/2 then 1\n",
    "            when sysdate - trunc(to_date('11-Sep-20')) < 5 then 1\n",
    "            end as r2\n",
    "    from (\n",
    "        select \n",
    "            trunc(to_date('11-Sep-20')) - trunc(A.current_date) as cycle_day,\n",
    "            trunc(A.current_date) as cycle_date,\n",
    "            min(trunc(A.current_date)) over (partition by A.pidm, A.appl_no) as appl_date,\n",
    "            min(case when A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null) then trunc(A.current_date) end) over (partition by A.pidm, A.appl_no) as apdc_date,\n",
    "            A.pidm,\n",
    "            A.id,\n",
    "            A.term_code as term_code_entry,\n",
    "            A.levl_code,\n",
    "            A.styp_code,\n",
    "            A.admt_code,\n",
    "            A.appl_no,\n",
    "            A.apst_code,\n",
    "            A.apdc_code,\n",
    "            A.camp_code,\n",
    "            A.saradap_resd_code as resd_code,\n",
    "            A.coll_code_1 as coll_code,\n",
    "            A.majr_code_1 as majr_code,\n",
    "            A.dept_code,\n",
    "            A.hs_percentile as hs_pctl\n",
    "        from opeir.admissions_fall2020 A\n",
    "    ) A where cycle_day between 0 and 0 + 14 and A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null)\n",
    ") A where A.r1 = 1 and A.r2 = 1\n",
    "\"\"\"\n",
    "db.head(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select A.* from (\n",
    "--select A.r2, count(*) from (\n",
    "    select \n",
    "        A.*,\n",
    "        case\n",
    "            when max(case when A.cycle_day >= 0 then A.cycle_date end) over (partition by A.pidm, A.appl_no) = A.cycle_date then 1\n",
    "            end as r1,\n",
    "        case\n",
    "            when sum(case when A.cycle_day <  0 then 1 else 0 end) over (partition by A.pidm, A.appl_no) >= 0/2 then 1\n",
    "            when sysdate - trunc(to_date('11-Sep-23')) < 5 then 1\n",
    "            end as r2\n",
    "    from (\n",
    "        select \n",
    "            trunc(to_date('11-Sep-23')) - trunc(A.current_date) as cycle_day,\n",
    "            trunc(A.current_date) as cycle_date,\n",
    "            min(trunc(A.current_date)) over (partition by A.pidm, A.appl_no) as appl_date,\n",
    "            min(case when A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null) then trunc(A.current_date) end) over (partition by A.pidm, A.appl_no) as apdc_date,\n",
    "            A.pidm,\n",
    "            A.id,\n",
    "            A.term_code as term_code_entry,\n",
    "            A.levl_code,\n",
    "            A.styp_code,\n",
    "            A.admt_code,\n",
    "            A.appl_no,\n",
    "            A.apst_code,\n",
    "            A.apdc_code,\n",
    "            A.camp_code,\n",
    "            A.saradap_resd_code as resd_code,\n",
    "            A.coll_code_1 as coll_code,\n",
    "            A.majr_code_1 as majr_code,\n",
    "            A.dept_code,\n",
    "            A.hs_percentile as hs_pctl\n",
    "        from opeir.admissions_fall2023 A\n",
    "    ) A where cycle_day between 0 and 0 + 14 and A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null)\n",
    ") A where A.r1 = 1 and A.r2 = 1\n",
    "\"\"\"\n",
    "A = db.head(qry)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.query('r1.notnull()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = self.pred[-1]['model']\n",
    "model.mean_match_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['summary'].disp(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, d in R[False]['rslt'].items():\n",
    "    print(g)\n",
    "    d['err%'].disp(100)\n",
    "    # print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in R[False]['rslt'].keys():\n",
    "    for b, v in R.items():\n",
    "        print(k, b)\n",
    "        v['rslt'][k]['err%'].disp(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = self.train(iterations=iterations, opts=opts,\n",
    "    styp_codes='n',\n",
    "    # train_terms=202208,\n",
    "    )\n",
    "\n",
    "def pivot(df, val, q=50):\n",
    "    Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "    for _ in range(2):\n",
    "        mr = Y.mean(axis=1)\n",
    "        ma = Y.abs().mean(axis=1)\n",
    "        Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "    return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "\n",
    "def analyze(df):\n",
    "    r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "    r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "    return r\n",
    "\n",
    "for b, L in R.items():\n",
    "    v = {k: pd.concat([Y[k] for Y in L]) for k in ['detail', 'summary']}\n",
    "    # v['opts'] = opts.copy()\n",
    "    # for g, df in v['summary'].groupby(['crse', 'styp_code']):\n",
    "    #     v[g] = analyze(df)\n",
    "    v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "    # R[b] = v\n",
    "# v[False]\n",
    "# R[False]\n",
    "# R[False][0].keys()\n",
    "# v['summary'].keys()\n",
    "# v['rslt']\n",
    "v.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "yr = 23\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    sfrstcr_term_code as term_code,\n",
    "    sfrstcr_pidm as pidm,\n",
    "    (select sgbstdn_levl_code from sgbstdn where sgbstdn_pidm = sfrstcr_pidm and sgbstdn_term_code_eff <= sfrstcr_term_code order by sgbstdn_term_code_eff desc fetch first 1 rows only) as levl_code,\n",
    "    (select sgbstdn_styp_code from sgbstdn where sgbstdn_pidm = sfrstcr_pidm and sgbstdn_term_code_eff <= sfrstcr_term_code order by sgbstdn_term_code_eff desc fetch first 1 rows only) as styp_code\n",
    "from sfrstcr\n",
    "where\n",
    "    sfrstcr_term_code = 20{yr}08\n",
    "    and  trunc(sfrstcr_add_date) <= trunc(to_date('10-Sep-{yr}')) -- added before cycle_day\n",
    "    and (trunc(sfrstcr_rsts_date) > trunc(to_date('10-Sep-{yr}')) or sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "    and sfrstcr_ptrm_code not in ('28','R3')\n",
    "group by sfrstcr_term_code, sfrstcr_pidm\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    term_code, levl_code, styp_code, count(distinct pidm)\n",
    "from {subqry(qry)}\n",
    "where levl_code='UG' and styp_code in ('N','R','T')\n",
    "group by term_code, levl_code, styp_code\n",
    "order by term_code, levl_code, styp_code\n",
    "\"\"\"\n",
    "db.head(qry, 100, show=True)\n",
    "# )\n",
    "# select A.* from A\n",
    "# union all\n",
    "# select\n",
    "#     A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code,\n",
    "#     '_total' as crse,\n",
    "#     sum(A.credit_hr) as credit_hr\n",
    "# from A\n",
    "# group by A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2143-2273)/2273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "yr = 21\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    A.sfrstcr_term_code as term_code,\n",
    "    A.sfrstcr_pidm as pidm,\n",
    "    (select C.sgbstdn_levl_code from sgbstdn C where C.sgbstdn_pidm = A.sfrstcr_pidm and C.sgbstdn_term_code_eff <= A.sfrstcr_term_code order by C.sgbstdn_term_code_eff desc fetch first 1 rows only) as levl_code,\n",
    "    (select C.sgbstdn_styp_code from sgbstdn C where C.sgbstdn_pidm = A.sfrstcr_pidm and C.sgbstdn_term_code_eff <= A.sfrstcr_term_code order by C.sgbstdn_term_code_eff desc fetch first 1 rows only) as styp_code,\n",
    "    --lower(B.ssbsect_subj_code) || B.ssbsect_crse_numb as crse,\n",
    "    sum(B.ssbsect_credit_hrs) as credit_hr\n",
    "from sfrstcr A, ssbsect B\n",
    "where\n",
    "    A.sfrstcr_term_code = B.ssbsect_term_code\n",
    "    and A.sfrstcr_crn = B.ssbsect_crn\n",
    "    and A.sfrstcr_term_code = 20{yr}08\n",
    "    and A.sfrstcr_ptrm_code not in ('28','R3')\n",
    "    and  trunc(A.sfrstcr_add_date) <= trunc(to_date('10-Sep-{yr}')) -- added before cycle_day\n",
    "    and (trunc(A.sfrstcr_rsts_date) > trunc(to_date('10-Sep-{yr}')) or A.sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "    and B.ssbsect_subj_code <> 'INST'\n",
    "group by A.sfrstcr_term_code, A.sfrstcr_pidm--, B.ssbsect_subj_code, B.ssbsect_crse_numb\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    term_code, levl_code, styp_code, count(distinct pidm)\n",
    "from {subqry(qry)}\n",
    "where credit_hr > 0 and levl_code='UG' and styp_code in ('N','R','T')\n",
    "group by term_code, levl_code, styp_code\n",
    "\"\"\"\n",
    "db.head(qry, 100)\n",
    "# )\n",
    "# select A.* from A\n",
    "# union all\n",
    "# select\n",
    "#     A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code,\n",
    "#     '_total' as crse,\n",
    "#     sum(A.credit_hr) as credit_hr\n",
    "# from A\n",
    "# group by A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "where(self.term[202208].reg['end']).query(\"styp_code=='n'\")['pidm'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['summary'].disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_term = 202208\n",
    "styp_code = 'n'\n",
    "crse = '_total'\n",
    "model = self.pred[0]['rslt']['model']\n",
    "\n",
    "\n",
    "targ = crse+'_end'\n",
    "cols = uniquify(['_total_cur', crse+'_cur', targ])\n",
    "T = self.Z.join(self.Y[cols])\n",
    "T[targ] = T[targ] > 0\n",
    "if styp_code != \"all\":\n",
    "    T = T.query(\"styp_code==@styp_code\")\n",
    "\n",
    "\n",
    "qry = f\"term_code!={train_term}\"\n",
    "g = lambda df, nm=None: df.filter(like='_end').rename(columns=lambda x:x[:-4]).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "agg = lambda x: pd.Series({\n",
    "    'pred': x['pred'].sum(min_count=1),\n",
    "    'true': x['true'].sum(min_count=1),\n",
    "    'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "})\n",
    "S = Y.groupby(['crse','levl_code','styp_code','term_code','train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "S.insert(2, 'err', S['pred'] - S['true'])\n",
    "S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = Y.groupby(['crse','levl_code','styp_code','term_code','train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "S.insert(2, 'err', S['pred'] - S['true'])\n",
    "S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "S.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(self.Y.shape, self.Z.shape)\n",
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y.isnull().sum()\n",
    "# self.crse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.term[202208].reg['cur'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "d = {'cur':{crse}, 'end':{crse}}\n",
    "d['cur'].add('_total')\n",
    "T = self.Z.copy()\n",
    "for k, v in d.items():\n",
    "    T = T.join(self.Y[k][listify(v)].rename(columns=lambda x:x+'_'+k))\n",
    "T.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['cur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = self.X.query('distance.isnull()')\n",
    "\n",
    "Y[['pidm','distance','stat_code','natn_code','zip','international','resd_code']].disp(100)\n",
    "# self.X.query(\"pidm in [1121725,1060603,1063123,1071878]\").disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = self.X.query(\"distance.notnull() & ((natn_code.notnull() & natn_code!='us') | stat_code in ['hi','ak','pr','ae','ap'])\")\n",
    "Y[['distance','stat_code','natn_code']].disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select\n",
    "    B.spraddr_cnty_code as cnty_code,\n",
    "    B.spraddr_seqno as s,\n",
    "    case\n",
    "        when B.spraddr_atyp_code = 'PA' then 6\n",
    "        when B.spraddr_atyp_code = 'PR' then 5\n",
    "        when B.spraddr_atyp_code = 'MA' then 4\n",
    "        when B.spraddr_atyp_code = 'BU' then 3\n",
    "        when B.spraddr_atyp_code = 'BI' then 2\n",
    "        when B.spraddr_atyp_code = 'P1' then 1\n",
    "        when B.spraddr_atyp_code = 'P2' then 0\n",
    "        end as r\n",
    "from spraddr B\n",
    "where B.spraddr_pidm = 1087120\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    B.cnty_code\n",
    "from (\n",
    "    select\n",
    "        B.spraddr_cnty_code as cnty_code,\n",
    "        B.spraddr_seqno as s,\n",
    "        case\n",
    "            when B.spraddr_atyp_code = 'PA' then 6\n",
    "            when B.spraddr_atyp_code = 'PR' then 5\n",
    "            when B.spraddr_atyp_code = 'MA' then 4\n",
    "            when B.spraddr_atyp_code = 'BU' then 3\n",
    "            when B.spraddr_atyp_code = 'BI' then 2\n",
    "            when B.spraddr_atyp_code = 'P1' then 1\n",
    "            when B.spraddr_atyp_code = 'P2' then 0\n",
    "            end as r\n",
    "    from spraddr B\n",
    "    where B.spraddr_pidm = 1087120\n",
    ") B\n",
    "where\n",
    "    B.cnty_code is not null\n",
    "    and B.r is not null\n",
    "order by\n",
    "    B.r desc,\n",
    "    B.s desc\n",
    "\"\"\"\n",
    "db.execute(qry).disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.missing()\n",
    "Y = self.X.query(\"distance.isnull() & (natn_code.isnull() | natn_code=='us') & stat_code not in ['hi','ak','pr','ae','ap']\")\n",
    "Y.sort_values('pidm').disp(1000)\n",
    "uniquify(Y['pidm'].tolist())\n",
    "# [['stat_code','natn_code']].disp(100)\n",
    "# self.X.iloc[[17412,30806]].disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"select distinct spraddr_stat_code from spraddr\"\n",
    "A = db.execute(qry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.value_counts('spbpers','spbpers_gndr_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('spbpers').columns.sort_values()\n",
    "db.head('opeir.admissions_fall2022').columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join(['AL','AR','AZ','CA','CO','CT','DC','DE','FL','GA','IA','ID','IL','IN','KS','KY','LA','MA','MD','ME','MI','MN','MO','MS','MT','NC','ND','NE','NH','NJ','NM','NV','NY','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VA','VT','WA','WI','WV','WY')\n",
    "# len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sort(A.squeeze().str.upper().unique().tolist()))\n",
    "# sort(A.squeeze().str.upper).unique().tolist())\n",
    "print(A.squeeze().str.upper().value_counts().sort_index().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"select A.* from spraddr A where A.spraddr_pidm = 1029274\"db.execute(qry).disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('opeir.admissions_fall2023',1).disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('szrsstd',1).disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute('stvatyp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = self.X.query(\"distance.isnull()\")['pidm'].tolist()\n",
    "qry = f\"select A.* from spraddr A where A.spraddr_pidm in ({join(L)}) and spraddr_stat_code='TX' order by spraddr_pidm\"\n",
    "# qry = f\"select A.* from sarappd A where A.sarappd_pidm in ({join(L)})\"\n",
    "# qry = f\"select A.*, (select sarappd_apdc_code from sarappd where sarappd_pidm = saradap_pidm and sarappd_appl_no = saradap_appl_no order by sarappd_seq_no desc fetch first 1 row only) as sarappd_apdc_code from saradap A where saradap_pidm in ({join(L)})\"\n",
    "A = db.execute(qry, show=True)\n",
    "A.disp(2000)\n",
    "# A['saradap_resd_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "w = pathlib.Path('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/flags/raw/old/201608_admitted_flags_report_031616.xlsx')\n",
    "w.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_ext(func):\n",
    "    def wrapper(X, *args, **kwargs):\n",
    "        try:\n",
    "            Y = func(X, *args, **kwargs)\n",
    "            print(1)\n",
    "        except:\n",
    "            Y = pd.DataFrame(X)\n",
    "            try:\n",
    "                Y = func(Y, *args, **kwargs)\n",
    "                print(2)\n",
    "            except:\n",
    "                Y = Y.apply(func, *args, **kwargs)\n",
    "                print(3)\n",
    "        if isinstance(X, pd.Series):\n",
    "            try:\n",
    "                Y = Y.squeeze()\n",
    "            except:\n",
    "                pass\n",
    "        return Y\n",
    "    wrapper.__name__ = func.__name__\n",
    "    return wrapper\n",
    "\n",
    "@pd_ext\n",
    "def binarize(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    s = set(ser.dropna())\n",
    "    if s:\n",
    "        if s.issubset({'y','Y'}):\n",
    "            ser = ser.notnull().astype('boolean')\n",
    "        elif s.issubset({0,1}):\n",
    "            ser = ser.astype('boolean')\n",
    "    return ser\n",
    "\n",
    "for func in [disp, to_numeric, prep, categorize, binarize, rnd, vc, missing, impute, unmelt]:\n",
    "    for cls in [pd.DataFrame, pd.Series]:\n",
    "        setattr(cls, func.__name__, func)\n",
    "\n",
    "# self.X['schlship_app'].value_counts()\n",
    "# self.X['fafsa_app'].value_counts()\n",
    "# self.X['schlship_app'].dtype\n",
    "# A = self.X.binarize()['schlship_app']\n",
    "# A['schlship_app']\n",
    "binarize(self.X)['schlship_app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['schlship_app'].groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "\n",
    "g = ['levl_code','styp_code','term_code','crse']\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\")[['pidm',*g,'credit_hr']].assign(credit_hr=lambda x: x['credit_hr'].fillna(0)>0) for term in self.term.values()]) for k in ['end','cur']}\n",
    "agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "A = agg(Y['end'], g)\n",
    "Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr'], how='inner') for k, y in Y.items()}\n",
    "B = agg(Y['end'], g)\n",
    "self.mlt = A / B\n",
    "\n",
    "self.Y = {k: y.squeeze().unstack().fillna(False).rename(columns=lambda x:f'{x}_{k}') for k, y in Y.items()}\n",
    "Y['end']\n",
    "# M = (end / cur).query(\"term_code != @self.infer\")\n",
    "# N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "# self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "\n",
    "\n",
    "# end\n",
    "self.Y['end']\n",
    "# Y = [self.Y[0].query(\"crse in @self.crse\").set_index('crse', append=True).unstack().droplevel(0,1).rename(columns=lambda x:f\"_{x}_end\")\n",
    "# # Y.droplevel?\n",
    "# Y.disp(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute(df, col, val=None, grp=None):\n",
    "#     val = val if val is not None else 'median' if pd.api.types.is_numeric_dtype(df[col]) else 'mode'\n",
    "#     if val in ['median']:\n",
    "#         func = lambda x: x.median()\n",
    "#     elif val in ['mean','ave','avg','average']:\n",
    "#         func = lambda x: x.mean()\n",
    "#     elif val in ['mode','most_frequent']:\n",
    "#         func = lambda x: x.mode()[0]\n",
    "#     else:\n",
    "#         func = lambda x: val\n",
    "#     df[col] = (df if grp is None else df.groupby(grp))[col].transform(lambda x: x.fillna(func(x)))\n",
    "#     return df\n",
    "# pd.DataFrame.impute = impute\n",
    "\n",
    "self.Z.reset_index(drop=True)\n",
    "A = self.Z.copy()\n",
    "c = '_birth_day'\n",
    "mask = A[c].isnull()\n",
    "# A.impute('_birth_day', val='median', grp=['term_code','styp_code'])\n",
    "# A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.loc[mask,c].disp(5)\n",
    "# A.groupby(['term_code','styp_code'])['_birth_day'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trf = ColumnTransformer(self.feat, remainder='drop',verbose_feature_names_out = False)\n",
    "# where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "# with warnings.catch_warnings(action='ignore'):\n",
    "#     self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "#     self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "\n",
    "kwargs = {\n",
    "    'feat': [\n",
    "        ['_gender',np.nan],\n",
    "        ['_appl_day',np.nan],\n",
    "        ['_apdc_day',np.nan],\n",
    "        ['_hs_qrtl',np.nan],\n",
    "        ['_act_equiv',np.nan],\n",
    "        ['_remote',False],\n",
    "        ['_resd',False],\n",
    "        ['_legacy',False],\n",
    "        *[[f'_race_{r}',False] for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        ['_waiver',False],\n",
    "        # ['_fafsa_app',False],\n",
    "        ['_schlship_app',False],\n",
    "        # ['_finaid_accepted',False],\n",
    "        ['_ssb',False],\n",
    "        ['_math',False],\n",
    "        ['_reading',False],\n",
    "        ['_writing',False],\n",
    "        ['_gap_score',0],\n",
    "        ['_oriented','n'],\n",
    "        ['_distance','max'],\n",
    "        ['_birth_day','median',['term_code','styp_code']],\n",
    "    ],\n",
    "}\n",
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "g = lambda col:'_'+col\n",
    "# cols = [x[0] for x in kwargs['feat']]\n",
    "# where(self.X).rename(columns=g)[cols].isnull().sum().disp(1000)\n",
    "X = where(self.X).set_index(self.attr, drop=False).rename(columns=g)\n",
    "Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "Z.isnull().sum().disp(1000)\n",
    "Z.dtypes\n",
    "# L = [Z.impute(col, *val)]\n",
    "# L = [[col, *listify(val)] for C, val in kwargs['feat'] for col in listify(C)]\n",
    "# L = [Z.impute(g(col), *listify(val)) for C, val in kwargs['feat'] for col in listify(C)]\n",
    "# L\n",
    "#).rename(columns=lambda x:'_'+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(Z).disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/flags/parq/flg_202308.parq', columns=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('spbpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"select spbpers_sex, count(*) from spbpers group by spbpers_sex\"\n",
    "db.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest import ImputationKernel\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer: int\n",
    "    crse: typing.List\n",
    "    feat: typing.Dict\n",
    "    attr: typing.List\n",
    "    sch: bool = True\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # check feat lists are disjoint\n",
    "        L = [x for f in self.feat for x in f[-1]]\n",
    "        assert len(L) == len(set(L))\n",
    "\n",
    "        self.term_codes = listify(self.term_codes)\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'X':False, 'Y':False, 'Z':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['Z'] |= self.overwrite['X'] | self.overwrite['Y']\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.path = root_path / f\"rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['pred']:\n",
    "            self[k] = self[k] if k in self else list()\n",
    "        for k in ['term']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "    def get_X(self):\n",
    "        nm = 'X'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        print(f'get {nm}')\n",
    "        R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "        repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "        R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "        R['camp_main'] = R['camp_code'] == 's'\n",
    "        R['distance'] = R['distance'].fillna(R['distance'].max())\n",
    "        R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "        R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm'})\n",
    "        R['coll_desc'] = R['coll_desc'].replace({\n",
    "            'ag & environmental sciences':'ag & natural resources',\n",
    "            'education & human development':'education',\n",
    "            'health science & human service':'health sciences',\n",
    "            'science & technology':'science & mathematics'})\n",
    "        majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "        S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "        R = R.drop(columns=majr).merge(S, on='majr_code', how='left')\n",
    "\n",
    "        checks = {\n",
    "            'cycle_day': R['cycle_day']>=0,\n",
    "            'apdc_day' : R['apdc_day' ]>=R['cycle_day'],\n",
    "            'appl_day' : R['appl_day' ]>=R['apdc_day' ],\n",
    "            'birth_day':(R['birth_day']>=R['appl_day' ]) & (R['birth_day']>=5000),\n",
    "            'distance': R['distance']>=0,\n",
    "            'hs_pctl': (R['hs_pctl']>=0) & (R['hs_pctl']<=100),\n",
    "            'act_equiv': (R['act_equiv']>=1) & (R['act_equiv']<=36),\n",
    "            'gap_score': (R['gap_score']>=0) & (R['gap_score']<=100),\n",
    "        }\n",
    "        for k, mask in checks.items():\n",
    "            if (~mask).any():\n",
    "                R[~mask].disp(10)\n",
    "                raise Exception(f'check failed - {k}')\n",
    "        self[nm] = R\n",
    "        return self.dump()\n",
    "\n",
    "    def preprocess(self):\n",
    "        nm = 'Z'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        self.get_X()\n",
    "        print(f'get {nm}')\n",
    "\n",
    "        trf = ColumnTransformer(self.feat, remainder='drop',verbose_feature_names_out = False)\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "            self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "            self.Z.missing().disp(100)\n",
    "            for c in ['_hs_qrtl', '_act_equiv']:\n",
    "                self.Z[c+'_missing'] = self.Z[c].isnull()\n",
    "            self.Z = self.Z.prep().binarize().categorize()\n",
    "        agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "        grp = ['levl_code','styp_code','term_code','crse']\n",
    "        end = agg(self.Y[0], grp)\n",
    "        \n",
    "        self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "        cur = agg(self.Y[0], grp)\n",
    "\n",
    "        M = (end / cur).query(\"term_code != @self.infer\")\n",
    "        N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "        self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, crse='_total', styp_code='all', train_term=202208, iterations=3, opts=dict()):\n",
    "        print(crse,train_term,styp_code, end=': ')\n",
    "        prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "        for P in self.pred:\n",
    "            if P['meta'] == prediction['meta']:\n",
    "                print('reusing')\n",
    "                return P\n",
    "        print(f'creating')\n",
    "        # d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "        d = {crse+'_cur':1, crse+'_end':0,}\n",
    "        end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "        Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "        T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "        if styp_code != \"all\":\n",
    "            T = T.query(\"styp_code==@styp_code\")\n",
    "        T.loc[T.eval(\"term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "        X = T.copy()\n",
    "        # qry = \"term_code!=@train_term\"\n",
    "        qry = \"term_code==@train_term\"\n",
    "        X.loc[X.eval(qry), end.keys()] = pd.NA\n",
    "        model = ImputationKernel(X, **opts)\n",
    "        model.mice(iterations)\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "            # assert 1==2\n",
    "        #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "        #     # imp.plot_correlations()\n",
    "\n",
    "        g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "        Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "        grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            S[x] = S[x] * S['mlt']\n",
    "        S.insert(2, 'err', S['pred'] - S['true'])\n",
    "        S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "        prediction['rslt'] = {'X':X,'T':T,'P':P,'model':model, 'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "        self.pred.append(prediction)\n",
    "        self.dump()\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def train(self, styp_codes=('n','r','t'), train_terms=None, iterations=3, opts=dict()):\n",
    "        train_terms = self.term_codes if train_terms is None else train_terms\n",
    "        def pivot(df, val, q=50):\n",
    "            Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "            for _ in range(2):\n",
    "                mr = Y.mean(axis=1)\n",
    "                ma = Y.abs().mean(axis=1)\n",
    "                Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "            return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "        \n",
    "        def analyze(df):\n",
    "            r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "            r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "            return r\n",
    "\n",
    "        P = {(crse, styp_code, train_term): self.predict(crse, styp_code, train_term, iterations, opts) for crse in self.crse for styp_code in listify(styp_codes) for train_term in listify(train_terms)}\n",
    "        R = dict()\n",
    "        for k,v in P.items():\n",
    "            R.setdefault(k[1]=='all', []).append(v)\n",
    "\n",
    "        for b, L in R.items():\n",
    "            v = {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']}\n",
    "            v['opts'] = opts.copy()\n",
    "            v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "            R[b] = v\n",
    "        return R\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "simpimp = lambda fill: SimpleImputer(strategy='constant', fill_value=fill, missing_values=pd.NA)\n",
    "kwargs = {\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_pctl',\n",
    "    ],\n",
    "    'feat': [\n",
    "        ('scl', make_pipeline(StandardScaler(), PowerTransformer()), [\n",
    "            'distance',\n",
    "            'birth_day',\n",
    "            # 'gap_score',\n",
    "            # 'hs_pctl',\n",
    "            'act_equiv',\n",
    "        ]),\n",
    "        ('pass', 'passthrough', [\n",
    "            'gender',\n",
    "            # 'styp_code',\n",
    "            # 'camp_code',\n",
    "            # 'coll_code',\n",
    "            # 'verified',\n",
    "            # 'term_code',\n",
    "            'appl_day',\n",
    "            'apdc_day',\n",
    "            'hs_qrtl',\n",
    "        ]),\n",
    "        ('false', simpimp(False), [\n",
    "            'camp_main',\n",
    "            'resd',\n",
    "            'legacy',\n",
    "            *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "            'waiver',\n",
    "            # 'fafsa_app',\n",
    "            'schlship_app',\n",
    "            # 'finaid_accepted',\n",
    "            'ssb',\n",
    "            'math',\n",
    "            'reading',\n",
    "            'writing',\n",
    "        ]),\n",
    "        ('0', simpimp(0), [\n",
    "            'gap_score',\n",
    "        ]),\n",
    "        ('n', simpimp('n'), [\n",
    "            'oriented',\n",
    "        ]),\n",
    "    ],\n",
    "    'infer': 202408,\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    # 'cycle_day': 197,\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'crse': [\n",
    "        '_total',\n",
    "        # 'engl1301',\n",
    "        # 'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'X': True,\n",
    "        # 'Y': True,\n",
    "        # 'Z': True,\n",
    "        'pred': True,\n",
    "    },\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    # 'sch': False,\n",
    "}\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "self = self.preprocess()\n",
    "self.term_codes.remove(self.infer)\n",
    "iterations = 3\n",
    "\n",
    "opts = dict()\n",
    "opts['random_state'] = 42\n",
    "opts['save_all_iterations'] = False\n",
    "opts['datasets'] = 5\n",
    "opts['mean_match_candidates'] = 10\n",
    "opts['mean_match_function'] = mean_match_kdtree_classification\n",
    "\n",
    "# # opts['datasets'] = 2\n",
    "# # opts['mean_match_candidates'] = 1\n",
    "# # opts['mean_match_function'] = default_mean_match\n",
    "\n",
    "# P = self.predict(opts=opts)\n",
    "\n",
    "R = self.train(iterations=iterations, opts=opts,\n",
    "    styp_codes='n',\n",
    "    # train_terms=202208,\n",
    "    )\n",
    "# for k in R[False]['rslt'].keys():\n",
    "#     for b, v in R.items():\n",
    "#         print(k, b)\n",
    "#         v['rslt'][k]['err%'].disp(100)\n",
    "\n",
    "# tune = []\n",
    "# for func in [mean_match_kdtree_classification, default_mean_match]:\n",
    "#     opts['mean_match_function'] = func\n",
    "#     for cand in range(2,41,3):\n",
    "#         opts['mean_match_candidates'] = cand\n",
    "#         print(sort(opts))\n",
    "#         R = self.train(\n",
    "#             styp_codes='n',\n",
    "#             iterations=iterations,\n",
    "#             opts=opts)\n",
    "#         R[False]['rslt']['_total','n']['err%'].disp(100)\n",
    "#         tune.append(R)\n",
    "#         write(self.tune, tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "match x:\n",
    "    case 2:\n",
    "        print(2)\n",
    "    case 10:\n",
    "        print(11)\n",
    "    case None:\n",
    "        print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['styp_code'].mode()\n",
    "# self.Z['_birth_day']['median']()\n",
    "df = pd.DataFrame()\n",
    "df['a'] = [1,1,2,2]\n",
    "df['b'] = ['a','a','a','a',]\n",
    "df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, col, val=None, grp=None):\n",
    "    val = val if val is not None else 'median' if pd.api.types.is_numeric_dtype(df[col]) else 'mode'\n",
    "    if val in ['median']:\n",
    "        func = lambda x: x.median()\n",
    "    elif val in ['mean','ave','avg','average']:\n",
    "        func = lambda x: x.mean()\n",
    "    elif val in ['mode','most_frequent']:\n",
    "        func = lambda x: x.mode()[0]\n",
    "    else:\n",
    "        func = lambda x: val\n",
    "    df[col] = (df if grp is None else df.groupby(grp))[col].transform(lambda x: x.fillna(func(x)))\n",
    "    return df\n",
    "pd.DataFrame.impute = impute\n",
    "\n",
    "self.Z.reset_index(drop=True)\n",
    "A = self.Z.copy()\n",
    "c = '_birth_day'\n",
    "mask = A[c].isnull()\n",
    "# A.impute('_birth_day', val='median', grp=['term_code','styp_code'])\n",
    "A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.loc[mask,c].disp(5)\n",
    "# A.groupby(['term_code','styp_code'])['_birth_day'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".102924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = self.pred[0]\n",
    "R = P['rslt']\n",
    "self.Z.dtypes\n",
    "# R['P'].dtypes#.values.astype(float)\n",
    "# model = self.pred[0]['rslt']['model']\n",
    "# model.feature_importance_df()\n",
    "# model.plot_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(self.path / 'predictions.csv', R[False]['summary'])\n",
    "write(self.path / 'predictions.parq', R[False]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.concat([term.raw for term in self.term.values()]).dropna(axis=1, how='all').reset_index(drop=True).prep()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.concat([term.raw for term in self.term.values()]).dropna(axis=1, how='all').reset_index(drop=True).prep()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "# R['hs_qrtl'] = \n",
    "R['A'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False)\n",
    "R['B'] = R['apdc_code'].map(repl)\n",
    "A\n",
    "# R['hs_qrtl'] = R['A'].combine_first(R['B'])\n",
    "# pd.concat([A,B],axis=1)\n",
    "R\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('stvapdc', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "idx = ['pidm','styp_code','apdc_code','apdc_desc']\n",
    "# P = self.X.set_index(idx)[['hs_pctl']]\n",
    "P = where(self.X).filter([*idx, 'hs_pctl'])\n",
    "repl = {\n",
    "    # 'a2':pd.NA,\n",
    "    # 'aa':pd.NA,\n",
    "    # 'ac':pd.NA,\n",
    "    # 'ad':pd.NA,\n",
    "    'ag':pd.NA,\n",
    "    'ai':pd.NA,\n",
    "    'at':pd.NA,\n",
    "    'ae':0,\n",
    "    'n1':1,\n",
    "    'n2':2,\n",
    "    'n3':3,\n",
    "    'n4':4,\n",
    "    'r1':1,\n",
    "    'r2':2,\n",
    "    'r3':3,\n",
    "    'r4':4,\n",
    "}\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "\n",
    "# bins = [100,89.9,74.9,49.9,24.9,0]\n",
    "# bool, default False\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "P['hs_qrtl'] = pd.cut(P['hs_pctl'], right=False, bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0]).combine_first(P['apdc_code'].map(repl))\n",
    "# P.query('hs_qrtl==2')\n",
    "# P.query(\"apdc_code=='n2'\")\n",
    "# P.vc(['apdc_desc','hs_qrtl']).disp(200)\n",
    "# Q = P.query(\"hs_qrtl.isnull()\")\n",
    "# P.groupby(['apdc_code','hs_qrtl']).size()\n",
    "P.groupby(['apdc_code','apdc_desc'])['hs_qrtl'].value_counts(normalize=True, dropna=False).round(2).sort_index().to_frame().disp(200)\n",
    "# Q.vc(['styp_code','apdc_code','apdc_desc']).disp(200)\n",
    "# P['hs_qrtl'].isnull().sum()\n",
    "# P.query(\"hs_qrtl.isnull()\").vc('apdc_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [100,89.9,74.9,49.9,24.9,0]\n",
    "np.arange(4,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P.query(\"apdc_code=='n2' & hs_pctl.notnull()\" ).disp(2000)\n",
    "P.query(\"apdc_code=='n2'\" ).disp(2000)\n",
    "# P.query(\"apdc_code=='n2'\").vc('hs_qrtl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.query(\"apdc_desc=='admitted (nr1)' & hs_qrtl==2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.query('hs_pctl.isnull()').vc('apdc_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    'a2':pd.NA,\n",
    "    'aa':pd.NA,\n",
    "    'ac':pd.NA,\n",
    "    'ad':pd.NA,\n",
    "    'ae':5,\n",
    "    'ag':pd.NA,\n",
    "    'ai':pd.NA,\n",
    "    'at':pd.NA,\n",
    "    'n1':1,\n",
    "    'n2':3,\n",
    "    'n3':4,\n",
    "    'n4':4,\n",
    "    'r1':1,\n",
    "    'r2':2,\n",
    "    'r3':3,\n",
    "    'r4':4,\n",
    "}\n",
    "P['q'] = P['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.vc(['apdc_code','apdc_desc'])\n",
    "# {'n1':1}\n",
    "# set(P.reset_index()['apdc_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.filter(like='_hs_pctl').query('_hs_pctl.isnull()').vc('apdc_desc')\n",
    "# # self.X.groupby('apdc_desc')['hs_pctl'].describe()\n",
    "# P = self.X[['apdc_desc','hs_pctl']]\n",
    "# pd.cut(self.X['hs_pctl'],4)\n",
    "# P = pd.cut(self.X.set_index(['pidm','apdc_desc'])['hs_pctl'], bins=[-1,25,50,75,100], labels=[1,2,3,4])\n",
    "P.vc(['apdc_desc','hs_qrtl']).disp(200)\n",
    "# P.groupby('apdc_desc').describe()\n",
    "# (P==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt'][('_total', 'n')]['proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A['summary'].query(\"pred_term!=202408 & styp_code=='n' & pred_term!=train_term\")#['err%']\n",
    "import seaborn as sns\n",
    "sns.boxplot(M, hue='train_term', y='err%', x='pred_term',\n",
    "    # fill=False,\n",
    "    whis=(0, 100),\n",
    "    dodge = True,\n",
    "    palette='tab10',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['Pmodel'].feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R[False]['rslt']['_total','n']['err%']\n",
    "R[False]['rslt']['_total','n'].keys()#['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P['rslt']['model'].feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_df(self, dataset, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(datset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_feature_importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = self.pred[0]['rslt']['model']\n",
    "# model.plot_feature_importance??\n",
    "imputed_var_names = [model._get_variable_name(int(i)) for i in np.sort(model.imputation_order)]\n",
    "predictor_var_names = [model._get_variable_name(int(i)) for i in np.sort(model.predictor_vars)]\n",
    "# model.\n",
    "c = '_total_end'\n",
    "I = pd.DataFrame(model.get_feature_importance(0), index=imputed_var_names, columns=predictor_var_names).T\n",
    "I *= 100 / I.sum()\n",
    "I[c].sort_values(ascending=False)\n",
    "# I.T['_total_end']\n",
    "# (0).shape\n",
    "#(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt']['_total','n'].keys()\n",
    "\n",
    "# ['rslt']['_total','n'].keys()\n",
    "# model = R[False]['rslt']['_total','n']\n",
    "#['model']\n",
    "# model.plot_feature_importance?\n",
    "# (dataset=0, annot=True,cmap=\"YlGnBu\",vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((len(f[-1]) for f in self.feat))\n",
    "L = [x for f in self.feat for x in f[-1]]\n",
    "len(L), len(set(L))\n",
    "# {x for f in self.feat for x in f[-1]}\n",
    "# {*self.feat[0][-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/flags/parq/flg_202308.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.columns\n",
    "F['styp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.isnull().sum().sort_index().disp(1000)\n",
    "# self.Z.dtypes\n",
    "# .vc('oriented')\n",
    "# hs_pctlact_equiv\n",
    "mask = self.Z['birth_day'].isnull()\n",
    "self.Z[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"select * from spbpers where spbpers_pidm=1115874\"\n",
    "db.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.select_dtypes('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.isnull().sum().sort_values(ascending=False).to_frame('missing').query('missing>0')\n",
    "# self.Z.vc('writing')\n",
    "# self.Z.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "feat = [\n",
    "    ('scl', make_pipeline(StandardScaler(), PowerTransformer()), [\n",
    "        'distance',\n",
    "        'birth_day',\n",
    "    ]),\n",
    "    # ('nom', FunctionTransformer(lambda x: x.astype('category')), [\n",
    "    ('nom', 'passthrough', [\n",
    "        'gender',\n",
    "        'oriented',\n",
    "        'styp_code',\n",
    "        # 'camp_code',\n",
    "        'coll_code',\n",
    "        # 'verified',\n",
    "    ]),\n",
    "    ('pass', 'passthrough', [\n",
    "        'term_code',\n",
    "        'math',\n",
    "        'reading',\n",
    "        'writing',\n",
    "        'hs_pctl',\n",
    "        'appl_day',\n",
    "        'apdc_day',\n",
    "        'act_equiv',\n",
    "    ]),\n",
    "    ('false', SimpleImputer(strategy='constant', fill_value=False), [\n",
    "        'camp_main',\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        # 'fafsa_app',\n",
    "        'schlship_app',\n",
    "        # 'finaid_accepted',\n",
    "        'ssb',\n",
    "    ]),\n",
    "    ('0', SimpleImputer(strategy='constant', fill_value=0), [\n",
    "        'gap_score',\n",
    "    ]),\n",
    "    # ('n', SimpleImputer(strategy='constant', fill_value='n'), [\n",
    "    #     'oriented',\n",
    "    # ]),\n",
    "\n",
    "]\n",
    "\n",
    "# trf = make_pipeline(ColumnTransformer(feat,remainder='drop',verbose_feature_names_out = False), ft)\n",
    "# trf = ColumnTransformer(feat,remainder='drop',verbose_feature_names_out = False)\n",
    "# Z = trf.fit_transform(self.X).binarize()\n",
    "# # Z = Z.apply(f)\n",
    "# # Z.isnull().sum()\n",
    "# Z.dtypes\n",
    "self.X.fillna({c:'' for c in self.X.select_dtypes('string').columns}, inplace=True)\n",
    "self.X.select_dtypes('string').isnull().sum().disp(300)\n",
    "# self.X.select_dtypes('string').fillna('')\n",
    "# self.X.select_dtypes('string').isnull().sum()\n",
    "\n",
    "# .fillna('')\n",
    "# Z\n",
    "# pd.api.types.is_string_dtype(Z['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('opeir.admissions_fall2022',2).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.waiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query(\"waiver.isnull()\").vc(['cycle_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.isnull().sum().disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt']['_total','n']['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in R[False]['rslt'].keys():\n",
    "    for b, v in R.items():\n",
    "        print(k, b)\n",
    "        v['rslt'][k]['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {k:v for k,v in R.items() if k[1]!='all'}.keys()\n",
    "R = {True:[], False:[]}\n",
    "for k,v in P.items():\n",
    "    R[k[1]=='all'].append(v)\n",
    "# q[True][0]['rslt'].keys()\n",
    "# for b,L in R.items():\n",
    "    # print(type(v))\n",
    "    # print(v[0]['rslt'].keys())\n",
    "\n",
    "S = {b: {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']} for b,L in R.items()}\n",
    "S[False]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def predict(self, crse='_total', train_term=202208, iterations=3, opts=dict()):\n",
    "    #     for styp_code in [\"n\",\"r\",\"t\",\"all\"]:\n",
    "    #         print(crse,train_term,styp_code, end=\": \")\n",
    "    #         prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "    #         for P in self.pred:\n",
    "    #             if P['meta'] == prediction['meta']:\n",
    "    #                 print('reusing')\n",
    "    #                 return P\n",
    "    #         print(f'creating')\n",
    "\n",
    "    #         d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "    #         end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "    #         Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "    #         T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "    #         if styp_code != \"all\":\n",
    "    #             T = T.query(\"styp_code==@styp_code\")\n",
    "    #         X = T.copy()\n",
    "    #         X.loc[X.eval(\"term_code!=@train_term or term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "    #         imp = ImputationKernel(X, **opts)\n",
    "    #         imp.mice(iterations)\n",
    "    #         # with warnings.catch_warnings(action='ignore'):\n",
    "    #         #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "    #         #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "    #         #     # imp.plot_correlations()\n",
    "\n",
    "    #         g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "    #         P = pd.concat([imp.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(imp.dataset_count())])\n",
    "    #         Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query('term_code != train_term').prep()\n",
    "    #         grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "    #         agg = lambda x: pd.Series({\n",
    "    #             'pred': x['pred'].sum(min_count=1),\n",
    "    #             'true': x['true'].sum(min_count=1),\n",
    "    #             'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    #             'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "    #         })\n",
    "    #         S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "    #         for x in ['pred','true']:\n",
    "    #             S[x] = S[x] * S['mlt']\n",
    "    #         S.insert(2, 'err', S['pred'] - S['true'])\n",
    "    #         S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "    #         prediction['rslt'] = {'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "    #         self.pred.append(prediction)\n",
    "    #         self.dump()\n",
    "    #     return prediction\n",
    "\n",
    "# class MM():\n",
    "#     def __init__(self, func, candidates):\n",
    "#         assert func in [mean_match_kdtree_classification, default_mean_match]\n",
    "#         self.func = func\n",
    "#         self.candidates = candidates\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return self.func(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return join([x for x in ['kdtree','default'] if x in self.func.__name__]+[self.candidates], \"_\")\n",
    "\n",
    "# class kdtree():\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return mean_match_kdtree_classification(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return 'kdtree__mean_match'\n",
    "\n",
    "# class default():\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return default_mean_match(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return 'default_mean_match'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = it.product(self.crse, ['n','r','t','all'])\n",
    "[[crse, styp_code, train_term] for crse, styp_code in Z for train_term in self.term_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = it.product(self.crse, ['n','r','t','all'])\n",
    "list(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    ('a','b'):7,\n",
    "    ('a','c'):71}\n",
    "d['a','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select\n",
    "        A.sfrstcr_term_code,\n",
    "        A.sfrstcr_pidm,\n",
    "        B.ssbsect_subj_code,\n",
    "        B.ssbsect_crse_numb,\n",
    "        B.ssbsect_credit_hrs,\n",
    "        A.sfrstcr_credit_hr\n",
    "from sfrstcr A, ssbsect B\n",
    "where\n",
    "        A.sfrstcr_term_code = B.ssbsect_term_code\n",
    "        and A.sfrstcr_crn = B.ssbsect_crn\n",
    "        and A.sfrstcr_term_code = 202308\n",
    "        and A.sfrstcr_ptrm_code not in ('28','R3')\n",
    "        and  trunc(to_date('18-Sep-23')) - trunc(A.sfrstcr_add_date) >= 197  -- added before cycle_day\n",
    "        and (trunc(to_date('18-Sep-23')) - trunc(A.sfrstcr_rsts_date) < 197 or A.sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "        and B.ssbsect_subj_code <> 'INST'\n",
    "        and A.sfrstcr_credit_hr <> B.ssbsect_credit_hrs\n",
    "\"\"\"\n",
    "db.head(qry, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"styp_code=='n' & pred_term!={self.infer}\"\n",
    "val = \"err%\"\n",
    "q=50\n",
    "P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "for _ in range(2):\n",
    "    P = (P.assign(mean=lambda x:x.mean(axis=1)) if P.shape[1] > 1 else P).T\n",
    "P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdtree = mean_match_kdtree_classification\n",
    "kdtree.__name__ = 'a'\n",
    "setattr(kdtree,'__str__','a')\n",
    "setattr(kdtree,'__repr__','a')\n",
    "\n",
    "print(kdtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "class MM():\n",
    "    def __init__(self, func, candidates):\n",
    "        self.func = func\n",
    "        self.candidates = candidates\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    def __str__(self):\n",
    "        return join([x for x in ['kdtree','deafult'] if x in self.func.__name__]+[self.candidates], \"_\")\n",
    "\n",
    "mm = MM(mean_match_kdtree_classification, 3)\n",
    "print(mm)\n",
    "# type(mean_match_kdtree_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_match_kdtree_classification.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = default_mean_match\n",
    "x.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # A[styp_code] = {\n",
    "            #     'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "            #     **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "\n",
    "\n",
    "\n",
    "    # R = {styp_code: {\n",
    "    #         'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "    #         **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "    #     } for styp_code in [\"n\"]}\n",
    "\n",
    "        # R['n']['proj'].disp(100)\n",
    "        # R['n']['err%'].disp(100)\n",
    "# B = (\n",
    "#     A['summary']\n",
    "#     .grpby(['crse','styp_code','train_term','pred_term'])\n",
    "#     # .grpby(['crse','styp_code','pred_term'])\n",
    "#     [['pred','err%','mse%','f1_inv%']]\n",
    "#     .agg(summary)\n",
    "#     .stack(0, sort=False)\n",
    "#     .rename_axis(index={None:'kind'})\n",
    "#     .query(f\"(pred_term == {self.infer} and kind == 'pred') or (pred_term != {self.infer} and kind == 'err%')\")\n",
    "#     .reset_index()\n",
    "#     # .sort_values(['crse','styp_code','pred_term','train_term'],ascending=[True,True,False,False])\n",
    "#     .prep()\n",
    "# )\n",
    "# M = A['summary'].query(\"pred_term != @self.infer & styp_code=='n'\").pivot_table(index='train_term', columns='pred_term', values='err%', margins=True)\n",
    "# M.disp(10)\n",
    "# B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R['n']['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {k: pd.concat([p['rslt'][k] for p in P]) for k in ['full','summary']}\n",
    "def pivot(qry, val, q=50):\n",
    "    P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q), margins=True, margins_name='mean')\n",
    "    for _ in range(2):\n",
    "        P = (P.head(1) if P.shape[0] == 2 else P).T\n",
    "    return P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n",
    "\n",
    "R = {styp_code: {\n",
    "    'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "    **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "} for styp_code in [\"n\"]}\n",
    "\n",
    "R['n']['proj'].disp(100)\n",
    "R['n']['err%'].disp(100)\n",
    "# }}\n",
    "# projections = pd.concat([piv(\"pred_term == @self.infer & styp_code=='n'\", 'pred', q) for q in [25,50,75]], axis=1)\n",
    "# errors = piv(\"pred_term != @self.infer & styp_code=='n'\", 'err%', 50)\n",
    "# Q\n",
    "# M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(p):\n",
    "    f = lambda x: x.quantile(p/100)\n",
    "    f.__name__ = f'{p}%'\n",
    "    f.__str__ = f'{p}%'\n",
    "    f.__repr__ = f'{p}%'\n",
    "    return f\n",
    "print(f\"{g(25)}\")\n",
    "display(f)\n",
    "str(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pctl(50)\n",
    "f.__repr__ = 'a'\n",
    "f.__str__ = 'a'\n",
    "f'{f}'\n",
    "# print(f)\n",
    "# f.__qualname__\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pctl(50)\n",
    "hasattr(w, '__name__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'hi'\n",
    "# x.__name__ = x\n",
    "hasattr(x, '__name__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piv(qry, val, q=50):\n",
    "    P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q), margins=True, margins_name='mean')\n",
    "    for _ in range(2):\n",
    "        P = (P.head(1) if P.shape[0] == 2 else P).T\n",
    "    return P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n",
    "A = {k: pd.concat([p['rslt'][k] for p in P]) for k in ['full','summary']}\n",
    "Q = pd.concat([piv(\"pred_term == @self.infer & styp_code=='n'\", 'pred', q) for q in [25,50,75]], axis=1)\n",
    "M = piv(\"pred_term != @self.infer & styp_code=='n'\", 'err%', 50)\n",
    "Q\n",
    "M\n",
    "# q = Q[0]\n",
    "# q\n",
    "# Q[0]\n",
    "# piv(\"styp_code=='n'\", 'err%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.T.assign(a=50).set_index('a', append=True).swaplevel(0,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Q[0]\n",
    "A.rename('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = (\n",
    "    A['summary']\n",
    "    .grpby(['crse','styp_code','train_term','pred_term'])\n",
    "    [['pred','err%','mse%','f1_inv%']]\n",
    "    .agg(summary)\n",
    "    .stack(0, sort=False)\n",
    "    .rename_axis(index={None:'kind'})\n",
    "    .query(f\"(pred_term == {self.infer} and kind == 'pred') or (pred_term != {self.infer} and kind == 'err%')\")\n",
    "    .reset_index()\n",
    "    # .sort_values(['crse','styp_code','pred_term','train_term'],ascending=[True,True,False,False])\n",
    "    .prep()\n",
    ")\n",
    "\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = A['summary'].query(\"pred_term!=202408 & styp_code=='n'\")['err%'].groupby(['train_term','pred_term']).mean().reset_index()#.unstack()\n",
    "# M.pivot_table(index='train_term',columns='pred_term', margins=True)\n",
    "\n",
    "# M\n",
    "A['summary'].reset_index().query(\"pred_term!=202408 & styp_code=='n'\").pivot_table(index='train_term', columns='pred_term', values='err%', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.disp(10)\n",
    "B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = self.Z.vc('term_code')\n",
    "v = t.values\n",
    "pd.DataFrame((v / v.T - 1) * 100, index=t.index, columns=t.index).round().prep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sort_values(['train_term','pred_term'], ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.disp(10)\n",
    "B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A['summary'].query(\"pred_term!=202408 & styp_code=='n' & pred_term!=train_term\")['err%'].groupby(['train_term','pred_term']).mean().unstack()\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary'].disp(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "    # self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False))\n",
    "# agg = lambda y, g: y.groupby(g)[['credit_hr']].sum()\n",
    "# grp = ['styp_code','term_code','crse']\n",
    "# end = agg(where(self.Y[0]), grp)\n",
    "# self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "# cur = agg(self.Y[0], grp)\n",
    "# M = (end / cur).query(\"term_code != @self.infer\")\n",
    "# N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "# self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "# return self.dump()\n",
    "\n",
    "agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "grp = ['levl_code','styp_code','term_code','crse']\n",
    "end = agg(self.Y[0], grp)\n",
    "self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "cur = agg(self.Y[0], grp)\n",
    "M = (end / cur).query(\"term_code != @self.infer\")\n",
    "M\n",
    "# agg(self.Y[0], grp).disp(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
