{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get X\n",
      "get Z\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ct</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_act_equiv</th>\n",
       "      <td>19618</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_hs_qrtl</th>\n",
       "      <td>2495</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_distance</th>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_total 202008 n: creating\n",
      "_total 202108 n: creating\n",
      "_total 202208 n: creating\n"
     ]
    }
   ],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest import ImputationKernel\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer: int\n",
    "    crse: typing.List\n",
    "    feat: typing.Dict\n",
    "    attr: typing.List\n",
    "    # sch: bool = True\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.term_codes = uniquify([*listify(self.term_codes), self.infer])\n",
    "        self.crse = uniquify(['_total', *listify(self.crse)])\n",
    "        self.mlt_grp = ['crse','levl_code','styp_code','term_code']\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'X':False, 'Y':False, 'Z':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['Z'] |= self.overwrite['X'] | self.overwrite['Y']\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.path = root_path / f\"resources/rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['pred']:\n",
    "            self[k] = self[k] if k in self else list()\n",
    "        for k in ['term']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "    def get_X(self):\n",
    "        nm = 'X'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        print(f'get {nm}')\n",
    "        R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep().binarize()\n",
    "        R['remote'] = R['camp_code'] != 's'\n",
    "        R['resd'] = R['resd_code'] == 'r'\n",
    "        R['lgcy'] = ~R['lgcy_code'].isin(['n','o'])\n",
    "        repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "        R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "        R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "        R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm'})\n",
    "        R['coll_desc'] = R['coll_desc'].replace({\n",
    "            'ag & environmental sciences':'ag & natural resources',\n",
    "            'education & human development':'education',\n",
    "            'health science & human service':'health sciences',\n",
    "            'science & technology':'science & mathematics'})\n",
    "        majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "        S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "        R = R.drop(columns=majr).merge(S, on='majr_code', how='left')\n",
    "\n",
    "        checks = {\n",
    "            'cycle_day': R['cycle_day']>=0,\n",
    "            'apdc_day' : R['apdc_day' ]>=R['cycle_day'],\n",
    "            'appl_day' : R['appl_day' ]>=R['apdc_day' ],\n",
    "            'birth_day':(R['birth_day']>=R['appl_day' ]) & (R['birth_day']>=5000),\n",
    "            'distance': R['distance']>=0,\n",
    "            'hs_pctl': (R['hs_pctl']>=0) & (R['hs_pctl']<=100),\n",
    "            'act_equiv': (R['act_equiv']>=1) & (R['act_equiv']<=36),\n",
    "            'gap_score': (R['gap_score']>=0) & (R['gap_score']<=100),\n",
    "        }\n",
    "        for k, mask in checks.items():\n",
    "            if (~mask).any():\n",
    "                R[~mask].disp(10)\n",
    "                raise Exception(f'check failed - {k}')\n",
    "        self[nm] = R\n",
    "        return self.dump()\n",
    "\n",
    "    def preprocess(self):\n",
    "        nm = 'Z'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        self.get_X()\n",
    "        print(f'get {nm}')\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "        self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "        self.Z.missing().disp(100)\n",
    "\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]) for k in ['cur','end']}\n",
    "        agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "        A = agg(Y['end'])\n",
    "        Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in Y.items()}\n",
    "        B = agg(Y['end'])\n",
    "        M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(\"term_code != @self.infer\").prep()\n",
    "        N = M.assign(term_code=self.infer)\n",
    "        self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "        self.Y = pd.concat([y.squeeze().unstack().dropna(how='all', axis=1).rename(columns=lambda x:x+'_'+k) for k, y in Y.items()], axis=1).fillna(0)\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, crse='_total', styp_code='all', train_term=202208, iterations=3, opts=dict()):\n",
    "        print(crse,train_term,styp_code, end=': ')\n",
    "        prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "        for P in self.pred:\n",
    "            if P['meta'] == prediction['meta']:\n",
    "                print('reusing')\n",
    "                return P\n",
    "        print(f'creating')\n",
    "\n",
    "        targ = crse+'_end'\n",
    "        cols = uniquify(['_total_cur', crse+'_cur', targ])\n",
    "        T = self.Z.join(self.Y[cols])\n",
    "        T[targ] = T[targ] > 0\n",
    "        if styp_code != \"all\":\n",
    "            T = T.query(\"styp_code==@styp_code\")\n",
    "        def ampute(df, qry):\n",
    "            df.loc[df.eval(qry), targ] = pd.NA\n",
    "        qry = f\"term_code=={self.infer}\"\n",
    "        ampute(T, qry)\n",
    "        X = T.copy()\n",
    "        qry = f\"term_code!={train_term}\"\n",
    "        ampute(X, qry)\n",
    "        model = ImputationKernel(X, **opts)\n",
    "        model.mice(iterations)\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "            # assert 1==2\n",
    "        #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "        #     # imp.plot_correlations()\n",
    "\n",
    "        g = lambda df, nm=None: df.filter(like='_end').rename(columns=lambda x:x[:-4]).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        P = pd.concat([model.complete_data(k).assign(train_term=train_term, sim=k).set_index(['train_term','sim'], append=True) for k in range(model.dataset_count())])\n",
    "        Y = g(P,'pred').join(g(T,'true')).query(qry).prep()\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        S = Y.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            S[x] = S[x] * S['mlt']\n",
    "        S.insert(2, 'err', S['pred'] - S['true'])\n",
    "        S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "        prediction['model'] = model\n",
    "        prediction['detail'] = Y\n",
    "        prediction['summary'] = S.drop(columns='mlt').prep()\n",
    "        prediction['X'] = X\n",
    "        prediction['T'] = T\n",
    "        prediction['P'] = P\n",
    "        self.pred.append(prediction)\n",
    "        self.dump()\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def train(self, styp_codes=('n','r','t'), train_terms=None, iterations=3, opts=dict()):\n",
    "        train_terms = self.term_codes if train_terms is None else train_terms\n",
    "        def pivot(df, val, q=50):\n",
    "            Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "            for _ in range(2):\n",
    "                mr = Y.mean(axis=1)\n",
    "                ma = Y.abs().mean(axis=1)\n",
    "                Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "            return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "        \n",
    "        def analyze(df):\n",
    "            r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "            r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "            return r\n",
    "\n",
    "        P = {(crse, styp_code, train_term): self.predict(crse, styp_code, train_term, iterations, opts) for crse in self.crse for styp_code in listify(styp_codes) for train_term in listify(train_terms)}\n",
    "        R = dict()\n",
    "        for k,v in P.items():\n",
    "            R.setdefault(k[1]=='all', []).append(v)\n",
    "\n",
    "        for b, L in R.items():\n",
    "            v = {k: pd.concat([Y[k] for Y in L]) for k in ['detail', 'summary']}\n",
    "            v['opts'] = opts.copy()\n",
    "            v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "            R[b] = v\n",
    "        return R\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "simpimp = lambda fill: SimpleImputer(strategy='constant', fill_value=fill, missing_values=pd.NA)\n",
    "kwargs = {\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        *code_desc('resd'),\n",
    "        *code_desc('lgcy'),\n",
    "        'international',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_pctl',\n",
    "    ],\n",
    "    'feat': [\n",
    "        ['_term_code',np.nan],\n",
    "        ['_appl_day',np.nan],\n",
    "        ['_apdc_day',np.nan],\n",
    "        ['_birth_day','median',['term_code','styp_code']],\n",
    "        \n",
    "        # ['_levl_code',np.nan],\n",
    "        ['_styp_code',np.nan],\n",
    "        # ['_admt_code',np.nan],\n",
    "\n",
    "        # ['_camp_code',np.nan],\n",
    "        ['_remote',False],\n",
    "        ['_coll_code',np.nan],\n",
    "        \n",
    "        ['_international',False],\n",
    "        *[[f'_race_{r}',False] for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        ['_gender',np.nan],\n",
    "        ['_lgcy',False],\n",
    "        ['_resd',False],\n",
    "        \n",
    "        ['_waiver',False],\n",
    "        # ['_fafsa_app',False],\n",
    "        ['_schlship_app',False],\n",
    "        # ['_finaid_accepted',False],\n",
    "        ['_ssb',False],\n",
    "        ['_math',False],\n",
    "        ['_reading',False],\n",
    "        ['_writing',False],\n",
    "        ['_gap_score',0],\n",
    "        ['_oriented','n'],\n",
    "        \n",
    "        ['_hs_qrtl',np.nan],\n",
    "        ['_act_equiv',np.nan],\n",
    "        ['_distance',np.nan],\n",
    "        \n",
    "    ],\n",
    "    'infer': 202408,\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    # 'cycle_day': 197,\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'crse': [\n",
    "        # 'engl1301',\n",
    "        # 'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        'X': True,\n",
    "        'Y': True,\n",
    "        'Z': True,\n",
    "        'pred': True,\n",
    "    },\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    # 'sch': False,\n",
    "}\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "# self = self.get_X()\n",
    "self = self.preprocess()\n",
    "self.term_codes.remove(self.infer)\n",
    "iterations = 3\n",
    "\n",
    "opts = dict()\n",
    "opts['random_state'] = 42\n",
    "opts['save_all_iterations'] = False\n",
    "opts['datasets'] = 5\n",
    "opts['mean_match_candidates'] = 29\n",
    "# opts['mean_match_function'] = mean_match_kdtree_classification\n",
    "\n",
    "# opts['datasets'] = 2\n",
    "# opts['mean_match_candidates'] = 1\n",
    "# opts['mean_match_function'] = default_mean_match\n",
    "\n",
    "# P = self.predict(opts=opts)\n",
    "\n",
    "R = self.train(iterations=iterations, opts=opts,\n",
    "    styp_codes='n',\n",
    "    # train_terms=202208,\n",
    "    )\n",
    "for k, v in R[False]['rslt'].items():\n",
    "    print(k)\n",
    "    v['err%'].disp(100)\n",
    "\n",
    "# tune = []\n",
    "# # for func in [mean_match_kdtree_classification, default_mean_match]:\n",
    "#     # opts['mean_match_function'] = func\n",
    "# for cand in range(2,41,3):\n",
    "#     opts['mean_match_candidates'] = cand\n",
    "#     print(mysort(opts))\n",
    "#     R = self.train(\n",
    "#         styp_codes='n',\n",
    "#         iterations=iterations,\n",
    "#         opts=opts)\n",
    "#     R[False]['rslt']['_total','n']['err%'].disp(100)\n",
    "#     tune.append(R)\n",
    "#     write(self.tune, tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "        ..\n",
       "6603   NaN\n",
       "6604   NaN\n",
       "6605   NaN\n",
       "6606   NaN\n",
       "6607   NaN\n",
       "Name: zip, Length: 6608, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.Z.shape\n",
    "self.term[202208].adm['zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.binarize()['international'].dtype\n",
    "self.X['international'].dropna().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "X = where(self.X.binarize()).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "# X['_international'].disp(1)\n",
    "X.impute('_international', False)\n",
    "# X.dtypes.disp(1000)\n",
    "# self.X.dtypes.disp(100)\n",
    "# pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "34400    False\n",
       "34401    False\n",
       "34402    False\n",
       "34403    False\n",
       "34404    False\n",
       "Name: international, Length: 34405, dtype: boolean"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binarize(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    s = set(ser.dropna())\n",
    "    if s:\n",
    "        try:\n",
    "            ser = ser.str.lower()\n",
    "            if s.issubset({'y','n'}):\n",
    "                ser = (ser=='y').astype('boolean').fillna(False)\n",
    "            if s.issubset({'true','false'}):\n",
    "                ser = (ser=='true').astype('boolean').fillna(False)\n",
    "        except:\n",
    "            if s.issubset({0,1}):\n",
    "                ser = ser.astype('boolean').fillna(False)\n",
    "    return ser\n",
    "A = R['international'].str.lower()\n",
    "(A=='true').astype('boolean').fillna(False)\n",
    "# binarize(A).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "international\n",
       "true    34\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self.term[202408].adm['international'].dtypes\n",
    "# self.reg\n",
    "R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "R['international'].value_counts()#.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.term[202208].adm['international'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R['international'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.columns\n",
    "self.X['international'].value_counts()\n",
    "# self.X['natn_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"select distinct B.gorvisa_natn_code_issue, B.gorvisa_vtyp_code from gorvisa B\"\"\"\n",
    "db.execute(qry).disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adm_202008_000.parq not found - creating\n",
      "select \n",
      "    A.cycle_day,\n",
      "    trunc(to_date('11-Sep-20')) - trunc(apdc_date) as apdc_day,\n",
      "    trunc(to_date('11-Sep-20')) - trunc(appl_date) as appl_day,\n",
      "    trunc(to_date('11-Sep-20')) - trunc(birth_date) as birth_day,\n",
      "    trunc(to_date('11-Sep-20')) as end_date,\n",
      "    A.cycle_date,\n",
      "    A.apdc_date,\n",
      "    A.appl_date,\n",
      "    A.birth_date,\n",
      "    A.term_code_entry,\n",
      "    A.term_code,\n",
      "    (select B.stvterm_desc from stvterm B where B.stvterm_code = A.term_code) as term_desc,\n",
      "    A.pidm,\n",
      "    A.id,\n",
      "    A.appl_no,\n",
      "    A.levl_code,\n",
      "    (select B.stvlevl_desc from stvlevl B where B.stvlevl_code = A.levl_code) as levl_desc,\n",
      "    A.styp_code,\n",
      "    (select B.stvstyp_desc from stvstyp B where B.stvstyp_code = A.styp_code) as styp_desc,\n",
      "    A.admt_code,\n",
      "    (select B.stvadmt_desc from stvadmt B where B.stvadmt_code = A.admt_code) as admt_desc,\n",
      "    A.apst_code,\n",
      "    (select B.stvapst_desc from stvapst B where B.stvapst_code = A.apst_code) as apst_desc,\n",
      "    A.apdc_code,\n",
      "    (select B.stvapdc_desc from stvapdc B where B.stvapdc_code = A.apdc_code) as apdc_desc,\n",
      "    A.camp_code,\n",
      "    (select B.stvcamp_desc from stvcamp B where B.stvcamp_code = A.camp_code) as camp_desc,\n",
      "    case when A.camp_code = 'S' then 1 end as camp_main,\n",
      "    A.coll_code,\n",
      "    (select B.stvcoll_desc from stvcoll B where B.stvcoll_code = A.coll_code) as coll_desc,\n",
      "    A.dept_code,\n",
      "    (select B.stvdept_desc from stvdept B where B.stvdept_code = A.dept_code) as dept_desc,\n",
      "    A.majr_code,\n",
      "    (select B.stvmajr_desc from stvmajr B where B.stvmajr_code = A.majr_code) as majr_desc,\n",
      "    A.cnty_code,\n",
      "    (select B.stvcnty_desc from stvcnty B where B.stvcnty_code = A.cnty_code) as cnty_desc,\n",
      "    A.stat_code,\n",
      "    (select B.stvstat_desc from stvstat B where B.stvstat_code = A.stat_code) as stat_desc,\n",
      "    A.zip,\n",
      "    A.natn_code,\n",
      "    (select B.stvnatn_nation from stvnatn B where B.stvnatn_code = A.natn_code) as natn_desc,\n",
      "    (select distinct 1 from gorvisa B where B.gorvisa_pidm = A.pidm and B.gorvisa_vtyp_code is not null) as international,\n",
      "    (select distinct 1 from gorprac B where B.gorprac_pidm = A.pidm and B.gorprac_race_cde='IN') as race_american_indian,\n",
      "    (select distinct 1 from gorprac B where B.gorprac_pidm = A.pidm and B.gorprac_race_cde='AS') as race_asian,\n",
      "    (select distinct 1 from gorprac B where B.gorprac_pidm = A.pidm and B.gorprac_race_cde='BL') as race_black,\n",
      "    (select distinct 1 from gorprac B where B.gorprac_pidm = A.pidm and B.gorprac_race_cde='HA') as race_pacific,\n",
      "    (select distinct 1 from gorprac B where B.gorprac_pidm = A.pidm and B.gorprac_race_cde='WH') as race_white,\n",
      "    (select distinct 1 from spbpers B where B.spbpers_pidm = A.pidm and B.spbpers_ethn_cde=2   ) as race_hispanic,\n",
      "    (select B.spbpers_sex from spbpers B where B.spbpers_pidm = A.pidm) as gender,\n",
      "    A.lgcy_code,\n",
      "    (select B.stvlgcy_desc from stvlgcy B where B.stvlgcy_code = A.lgcy_code) as lgcy_desc,\n",
      "    case when A.lgcy_code is null or A.lgcy_code in ('N','O') then null else 1 end as legacy,\n",
      "    A.resd_code,\n",
      "    (select B.stvresd_desc from stvresd B where B.stvresd_code = A.resd_code) as resd_desc,\n",
      "    case when A.resd_code = 'R' then 1 else 0 end as resd,\n",
      "    A.hs_pctl\n",
      "from (\n",
      "    select \n",
      "        A.*,\n",
      "        row_number() over (partition by A.pidm order by A.appl_no desc) as r,\n",
      "        202008 as term_code,\n",
      "        (select B.cnty_code from (\n",
      "            select\n",
      "                B.spraddr_cnty_code as cnty_code,\n",
      "                B.spraddr_seqno as s,\n",
      "                case\n",
      "                    when B.spraddr_atyp_code = 'PA' then 6\n",
      "                    when B.spraddr_atyp_code = 'PR' then 5\n",
      "                    when B.spraddr_atyp_code = 'MA' then 4\n",
      "                    when B.spraddr_atyp_code = 'BU' then 3\n",
      "                    when B.spraddr_atyp_code = 'BI' then 2\n",
      "                    --when B.spraddr_atyp_code = 'P1' then 1\n",
      "                    --when B.spraddr_atyp_code = 'P2' then 0\n",
      "                    end as r\n",
      "            from spraddr B where B.spraddr_pidm = A.pidm and B.spraddr_stat_code in ('AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY')\n",
      "        ) B where B.cnty_code is not null and B.r is not null\n",
      "        order by B.r desc, B.s desc fetch first 1 row only) as cnty_code,\n",
      "        (select B.stat_code from (\n",
      "            select\n",
      "                B.spraddr_stat_code as stat_code,\n",
      "                B.spraddr_seqno as s,\n",
      "                case\n",
      "                    when B.spraddr_atyp_code = 'PA' then 6\n",
      "                    when B.spraddr_atyp_code = 'PR' then 5\n",
      "                    when B.spraddr_atyp_code = 'MA' then 4\n",
      "                    when B.spraddr_atyp_code = 'BU' then 3\n",
      "                    when B.spraddr_atyp_code = 'BI' then 2\n",
      "                    --when B.spraddr_atyp_code = 'P1' then 1\n",
      "                    --when B.spraddr_atyp_code = 'P2' then 0\n",
      "                    end as r\n",
      "            from spraddr B where B.spraddr_pidm = A.pidm and B.spraddr_stat_code in ('AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY')\n",
      "        ) B where B.stat_code is not null and B.r is not null\n",
      "        order by B.r desc, B.s desc fetch first 1 row only) as stat_code,\n",
      "        (select B.zip from (\n",
      "            select\n",
      "                to_number(substr(B.spraddr_zip, 0, 5) default null on conversion error) as zip,\n",
      "                B.spraddr_seqno as s,\n",
      "                case\n",
      "                    when B.spraddr_atyp_code = 'PA' then 6\n",
      "                    when B.spraddr_atyp_code = 'PR' then 5\n",
      "                    when B.spraddr_atyp_code = 'MA' then 4\n",
      "                    when B.spraddr_atyp_code = 'BU' then 3\n",
      "                    when B.spraddr_atyp_code = 'BI' then 2\n",
      "                    --when B.spraddr_atyp_code = 'P1' then 1\n",
      "                    --when B.spraddr_atyp_code = 'P2' then 0\n",
      "                    end as r\n",
      "            from spraddr B where B.spraddr_pidm = A.pidm and B.spraddr_stat_code in ('AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY')\n",
      "        ) B where B.zip is not null and B.r is not null\n",
      "        order by B.r desc, B.s desc fetch first 1 row only) as zip,\n",
      "        (select B.gorvisa_natn_code_issue from gorvisa B where B.gorvisa_pidm = A.pidm order by gorvisa_seq_no desc fetch first 1 row only) as natn_code,\n",
      "        (select B.spbpers_lgcy_code from spbpers B where B.spbpers_pidm = A.pidm) as lgcy_code,\n",
      "        (select B.spbpers_birth_date from spbpers B where B.spbpers_pidm = A.pidm) as birth_date\n",
      "    from (\n",
      "        select A.* from (\n",
      "            select \n",
      "                A.*,\n",
      "                case\n",
      "                    when max(case when A.cycle_day >= 0 then A.cycle_date end) over (partition by A.pidm, A.appl_no) = A.cycle_date then 1\n",
      "                    end as r1,\n",
      "                case\n",
      "                    when sum(case when A.cycle_day <  0 then 1 else 0 end) over (partition by A.pidm, A.appl_no) >= 0/2 then 1\n",
      "                    when sysdate - trunc(to_date('11-Sep-20')) < 5 then 1\n",
      "                    end as r2\n",
      "            from (\n",
      "                select \n",
      "                    trunc(to_date('11-Sep-20')) - trunc(A.current_date) as cycle_day,\n",
      "                    trunc(A.current_date) as cycle_date,\n",
      "                    min(trunc(A.current_date)) over (partition by A.pidm, A.appl_no) as appl_date,\n",
      "                    min(case when A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null) then trunc(A.current_date) end) over (partition by A.pidm, A.appl_no) as apdc_date,\n",
      "                    A.pidm,\n",
      "                    A.id,\n",
      "                    A.term_code as term_code_entry,\n",
      "                    A.levl_code,\n",
      "                    A.styp_code,\n",
      "                    A.admt_code,\n",
      "                    A.appl_no,\n",
      "                    A.apst_code,\n",
      "                    A.apdc_code,\n",
      "                    A.camp_code,\n",
      "                    A.saradap_resd_code as resd_code,\n",
      "                    A.coll_code_1 as coll_code,\n",
      "                    A.majr_code_1 as majr_code,\n",
      "                    A.dept_code,\n",
      "                    A.hs_percentile as hs_pctl\n",
      "                from opeir.admissions_summer2020 A\n",
      "            ) A where cycle_day between 0 and 0 + 14 and A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null)\n",
      "        ) A where A.r1 = 1 and A.r2 = 1\n",
      "        \n",
      "        union all\n",
      "        \n",
      "        select A.* from (\n",
      "            select \n",
      "                A.*,\n",
      "                case\n",
      "                    when max(case when A.cycle_day >= 0 then A.cycle_date end) over (partition by A.pidm, A.appl_no) = A.cycle_date then 1\n",
      "                    end as r1,\n",
      "                case\n",
      "                    when sum(case when A.cycle_day <  0 then 1 else 0 end) over (partition by A.pidm, A.appl_no) >= 0/2 then 1\n",
      "                    when sysdate - trunc(to_date('11-Sep-20')) < 5 then 1\n",
      "                    end as r2\n",
      "            from (\n",
      "                select \n",
      "                    trunc(to_date('11-Sep-20')) - trunc(A.current_date) as cycle_day,\n",
      "                    trunc(A.current_date) as cycle_date,\n",
      "                    min(trunc(A.current_date)) over (partition by A.pidm, A.appl_no) as appl_date,\n",
      "                    min(case when A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null) then trunc(A.current_date) end) over (partition by A.pidm, A.appl_no) as apdc_date,\n",
      "                    A.pidm,\n",
      "                    A.id,\n",
      "                    A.term_code as term_code_entry,\n",
      "                    A.levl_code,\n",
      "                    A.styp_code,\n",
      "                    A.admt_code,\n",
      "                    A.appl_no,\n",
      "                    A.apst_code,\n",
      "                    A.apdc_code,\n",
      "                    A.camp_code,\n",
      "                    A.saradap_resd_code as resd_code,\n",
      "                    A.coll_code_1 as coll_code,\n",
      "                    A.majr_code_1 as majr_code,\n",
      "                    A.dept_code,\n",
      "                    A.hs_percentile as hs_pctl\n",
      "                from opeir.admissions_fall2020 A\n",
      "            ) A where cycle_day between 0 and 0 + 14 and A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null)\n",
      "        ) A where A.r1 = 1 and A.r2 = 1\n",
      "    ) A\n",
      ") A where A.r = 1 and A.levl_code = 'UG' and A.styp_code in ('N','R','T')\n"
     ]
    }
   ],
   "source": [
    "from LiveAMP import *\n",
    "t = TERM(term_code=202008, overwrite={'adm':True}, show={'adm':True})\n",
    "A = t.get_adm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       76048\n",
       "1       76401\n",
       "2       76087\n",
       "3       76444\n",
       "4       76367\n",
       "        ...  \n",
       "8841    77962\n",
       "8842    76135\n",
       "8843    76117\n",
       "8844    76058\n",
       "8845    76180\n",
       "Name: zip, Length: 8846, dtype: Int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A['zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('gorvisa')\n",
    "# db.value_counts('gorvisa','gorvisa_natn_code_issue','gorvisa_pidm')\n",
    "# qry = \"select * from (select gorvisa_pidm, count(gorvisa_natn_code_issue) as ct from gorvisa group by gorvisa_pidm) where ct>1\"\n",
    "# qry = \"select gorvisa_pidm, count(distinct gorvisa_natn_code_issue) as ct from gorvisa group by gorvisa_pidm order by ct desc\"\n",
    "# db.head(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select A.* from (\n",
    "    select \n",
    "        A.*,\n",
    "        case\n",
    "            when max(case when A.cycle_day >= 0 then A.cycle_date end) over (partition by A.pidm, A.appl_no) = A.cycle_date then 1\n",
    "            end as r1,\n",
    "        case\n",
    "            when sum(case when A.cycle_day <  0 then 1 end) over (partition by A.pidm, A.appl_no) >= 0/2 then 1\n",
    "            when sysdate - trunc(to_date('11-Sep-20')) < 5 then 1\n",
    "            end as r2\n",
    "    from (\n",
    "        select \n",
    "            trunc(to_date('11-Sep-20')) - trunc(A.current_date) as cycle_day,\n",
    "            trunc(A.current_date) as cycle_date,\n",
    "            min(trunc(A.current_date)) over (partition by A.pidm, A.appl_no) as appl_date,\n",
    "            min(case when A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null) then trunc(A.current_date) end) over (partition by A.pidm, A.appl_no) as apdc_date,\n",
    "            A.pidm,\n",
    "            A.id,\n",
    "            A.term_code as term_code_entry,\n",
    "            A.levl_code,\n",
    "            A.styp_code,\n",
    "            A.admt_code,\n",
    "            A.appl_no,\n",
    "            A.apst_code,\n",
    "            A.apdc_code,\n",
    "            A.camp_code,\n",
    "            A.saradap_resd_code as resd_code,\n",
    "            A.coll_code_1 as coll_code,\n",
    "            A.majr_code_1 as majr_code,\n",
    "            A.dept_code,\n",
    "            A.hs_percentile as hs_pctl\n",
    "        from opeir.admissions_fall2020 A\n",
    "    ) A where cycle_day between 0 and 0 + 14 and A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null)\n",
    ") A where A.r1 = 1 and A.r2 = 1\n",
    "\"\"\"\n",
    "db.head(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select A.* from (\n",
    "--select A.r2, count(*) from (\n",
    "    select \n",
    "        A.*,\n",
    "        case\n",
    "            when max(case when A.cycle_day >= 0 then A.cycle_date end) over (partition by A.pidm, A.appl_no) = A.cycle_date then 1\n",
    "            end as r1,\n",
    "        case\n",
    "            when sum(case when A.cycle_day <  0 then 1 else 0 end) over (partition by A.pidm, A.appl_no) >= 0/2 then 1\n",
    "            when sysdate - trunc(to_date('11-Sep-23')) < 5 then 1\n",
    "            end as r2\n",
    "    from (\n",
    "        select \n",
    "            trunc(to_date('11-Sep-23')) - trunc(A.current_date) as cycle_day,\n",
    "            trunc(A.current_date) as cycle_date,\n",
    "            min(trunc(A.current_date)) over (partition by A.pidm, A.appl_no) as appl_date,\n",
    "            min(case when A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null) then trunc(A.current_date) end) over (partition by A.pidm, A.appl_no) as apdc_date,\n",
    "            A.pidm,\n",
    "            A.id,\n",
    "            A.term_code as term_code_entry,\n",
    "            A.levl_code,\n",
    "            A.styp_code,\n",
    "            A.admt_code,\n",
    "            A.appl_no,\n",
    "            A.apst_code,\n",
    "            A.apdc_code,\n",
    "            A.camp_code,\n",
    "            A.saradap_resd_code as resd_code,\n",
    "            A.coll_code_1 as coll_code,\n",
    "            A.majr_code_1 as majr_code,\n",
    "            A.dept_code,\n",
    "            A.hs_percentile as hs_pctl\n",
    "        from opeir.admissions_fall2023 A\n",
    "    ) A where cycle_day between 0 and 0 + 14 and A.apst_code = 'D' and A.apdc_code in (select stvapdc_code from stvapdc where stvapdc_inst_acc_ind is not null)\n",
    ") A where A.r1 = 1 and A.r2 = 1\n",
    "\"\"\"\n",
    "A = db.head(qry)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.query('r1.notnull()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = self.pred[-1]['model']\n",
    "model.mean_match_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['summary'].disp(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, d in R[False]['rslt'].items():\n",
    "    print(g)\n",
    "    d['err%'].disp(100)\n",
    "    # print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in R[False]['rslt'].keys():\n",
    "    for b, v in R.items():\n",
    "        print(k, b)\n",
    "        v['rslt'][k]['err%'].disp(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = self.train(iterations=iterations, opts=opts,\n",
    "    styp_codes='n',\n",
    "    # train_terms=202208,\n",
    "    )\n",
    "\n",
    "def pivot(df, val, q=50):\n",
    "    Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "    for _ in range(2):\n",
    "        mr = Y.mean(axis=1)\n",
    "        ma = Y.abs().mean(axis=1)\n",
    "        Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "    return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "\n",
    "def analyze(df):\n",
    "    r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "    r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "    return r\n",
    "\n",
    "for b, L in R.items():\n",
    "    v = {k: pd.concat([Y[k] for Y in L]) for k in ['detail', 'summary']}\n",
    "    # v['opts'] = opts.copy()\n",
    "    # for g, df in v['summary'].groupby(['crse', 'styp_code']):\n",
    "    #     v[g] = analyze(df)\n",
    "    v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "    # R[b] = v\n",
    "# v[False]\n",
    "# R[False]\n",
    "# R[False][0].keys()\n",
    "# v['summary'].keys()\n",
    "# v['rslt']\n",
    "v.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "yr = 23\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    sfrstcr_term_code as term_code,\n",
    "    sfrstcr_pidm as pidm,\n",
    "    (select sgbstdn_levl_code from sgbstdn where sgbstdn_pidm = sfrstcr_pidm and sgbstdn_term_code_eff <= sfrstcr_term_code order by sgbstdn_term_code_eff desc fetch first 1 rows only) as levl_code,\n",
    "    (select sgbstdn_styp_code from sgbstdn where sgbstdn_pidm = sfrstcr_pidm and sgbstdn_term_code_eff <= sfrstcr_term_code order by sgbstdn_term_code_eff desc fetch first 1 rows only) as styp_code\n",
    "from sfrstcr\n",
    "where\n",
    "    sfrstcr_term_code = 20{yr}08\n",
    "    and  trunc(sfrstcr_add_date) <= trunc(to_date('10-Sep-{yr}')) -- added before cycle_day\n",
    "    and (trunc(sfrstcr_rsts_date) > trunc(to_date('10-Sep-{yr}')) or sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "    and sfrstcr_ptrm_code not in ('28','R3')\n",
    "group by sfrstcr_term_code, sfrstcr_pidm\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    term_code, levl_code, styp_code, count(distinct pidm)\n",
    "from {subqry(qry)}\n",
    "where levl_code='UG' and styp_code in ('N','R','T')\n",
    "group by term_code, levl_code, styp_code\n",
    "order by term_code, levl_code, styp_code\n",
    "\"\"\"\n",
    "db.head(qry, 100, show=True)\n",
    "# )\n",
    "# select A.* from A\n",
    "# union all\n",
    "# select\n",
    "#     A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code,\n",
    "#     '_total' as crse,\n",
    "#     sum(A.credit_hr) as credit_hr\n",
    "# from A\n",
    "# group by A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2143-2273)/2273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "yr = 21\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    A.sfrstcr_term_code as term_code,\n",
    "    A.sfrstcr_pidm as pidm,\n",
    "    (select C.sgbstdn_levl_code from sgbstdn C where C.sgbstdn_pidm = A.sfrstcr_pidm and C.sgbstdn_term_code_eff <= A.sfrstcr_term_code order by C.sgbstdn_term_code_eff desc fetch first 1 rows only) as levl_code,\n",
    "    (select C.sgbstdn_styp_code from sgbstdn C where C.sgbstdn_pidm = A.sfrstcr_pidm and C.sgbstdn_term_code_eff <= A.sfrstcr_term_code order by C.sgbstdn_term_code_eff desc fetch first 1 rows only) as styp_code,\n",
    "    --lower(B.ssbsect_subj_code) || B.ssbsect_crse_numb as crse,\n",
    "    sum(B.ssbsect_credit_hrs) as credit_hr\n",
    "from sfrstcr A, ssbsect B\n",
    "where\n",
    "    A.sfrstcr_term_code = B.ssbsect_term_code\n",
    "    and A.sfrstcr_crn = B.ssbsect_crn\n",
    "    and A.sfrstcr_term_code = 20{yr}08\n",
    "    and A.sfrstcr_ptrm_code not in ('28','R3')\n",
    "    and  trunc(A.sfrstcr_add_date) <= trunc(to_date('10-Sep-{yr}')) -- added before cycle_day\n",
    "    and (trunc(A.sfrstcr_rsts_date) > trunc(to_date('10-Sep-{yr}')) or A.sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "    and B.ssbsect_subj_code <> 'INST'\n",
    "group by A.sfrstcr_term_code, A.sfrstcr_pidm--, B.ssbsect_subj_code, B.ssbsect_crse_numb\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    term_code, levl_code, styp_code, count(distinct pidm)\n",
    "from {subqry(qry)}\n",
    "where credit_hr > 0 and levl_code='UG' and styp_code in ('N','R','T')\n",
    "group by term_code, levl_code, styp_code\n",
    "\"\"\"\n",
    "db.head(qry, 100)\n",
    "# )\n",
    "# select A.* from A\n",
    "# union all\n",
    "# select\n",
    "#     A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code,\n",
    "#     '_total' as crse,\n",
    "#     sum(A.credit_hr) as credit_hr\n",
    "# from A\n",
    "# group by A.cycle_day, A.term_code, A.pidm, A.levl_code, A.styp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "where(self.term[202208].reg['end']).query(\"styp_code=='n'\")['pidm'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['summary'].disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_term = 202208\n",
    "styp_code = 'n'\n",
    "crse = '_total'\n",
    "model = self.pred[0]['rslt']['model']\n",
    "\n",
    "\n",
    "targ = crse+'_end'\n",
    "cols = uniquify(['_total_cur', crse+'_cur', targ])\n",
    "T = self.Z.join(self.Y[cols])\n",
    "T[targ] = T[targ] > 0\n",
    "if styp_code != \"all\":\n",
    "    T = T.query(\"styp_code==@styp_code\")\n",
    "\n",
    "\n",
    "qry = f\"term_code!={train_term}\"\n",
    "g = lambda df, nm=None: df.filter(like='_end').rename(columns=lambda x:x[:-4]).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "agg = lambda x: pd.Series({\n",
    "    'pred': x['pred'].sum(min_count=1),\n",
    "    'true': x['true'].sum(min_count=1),\n",
    "    'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "})\n",
    "S = Y.groupby(['crse','levl_code','styp_code','term_code','train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "S.insert(2, 'err', S['pred'] - S['true'])\n",
    "S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = Y.groupby(['crse','levl_code','styp_code','term_code','train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "for x in ['pred','true']:\n",
    "    S[x] = S[x] * S['mlt']\n",
    "S.insert(2, 'err', S['pred'] - S['true'])\n",
    "S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "S.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(self.Y.shape, self.Z.shape)\n",
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y.isnull().sum()\n",
    "# self.crse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.term[202208].reg['cur'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "d = {'cur':{crse}, 'end':{crse}}\n",
    "d['cur'].add('_total')\n",
    "T = self.Z.copy()\n",
    "for k, v in d.items():\n",
    "    T = T.join(self.Y[k][listify(v)].rename(columns=lambda x:x+'_'+k))\n",
    "T.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['cur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = self.X.query('distance.isnull()')\n",
    "\n",
    "Y[['pidm','distance','stat_code','natn_code','zip','international','resd_code']].disp(100)\n",
    "# self.X.query(\"pidm in [1121725,1060603,1063123,1071878]\").disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = self.X.query(\"distance.notnull() & ((natn_code.notnull() & natn_code!='us') | stat_code in ['hi','ak','pr','ae','ap'])\")\n",
    "Y[['distance','stat_code','natn_code']].disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select\n",
    "    B.spraddr_cnty_code as cnty_code,\n",
    "    B.spraddr_seqno as s,\n",
    "    case\n",
    "        when B.spraddr_atyp_code = 'PA' then 6\n",
    "        when B.spraddr_atyp_code = 'PR' then 5\n",
    "        when B.spraddr_atyp_code = 'MA' then 4\n",
    "        when B.spraddr_atyp_code = 'BU' then 3\n",
    "        when B.spraddr_atyp_code = 'BI' then 2\n",
    "        when B.spraddr_atyp_code = 'P1' then 1\n",
    "        when B.spraddr_atyp_code = 'P2' then 0\n",
    "        end as r\n",
    "from spraddr B\n",
    "where B.spraddr_pidm = 1087120\n",
    "\"\"\"\n",
    "\n",
    "qry = f\"\"\"\n",
    "select\n",
    "    B.cnty_code\n",
    "from (\n",
    "    select\n",
    "        B.spraddr_cnty_code as cnty_code,\n",
    "        B.spraddr_seqno as s,\n",
    "        case\n",
    "            when B.spraddr_atyp_code = 'PA' then 6\n",
    "            when B.spraddr_atyp_code = 'PR' then 5\n",
    "            when B.spraddr_atyp_code = 'MA' then 4\n",
    "            when B.spraddr_atyp_code = 'BU' then 3\n",
    "            when B.spraddr_atyp_code = 'BI' then 2\n",
    "            when B.spraddr_atyp_code = 'P1' then 1\n",
    "            when B.spraddr_atyp_code = 'P2' then 0\n",
    "            end as r\n",
    "    from spraddr B\n",
    "    where B.spraddr_pidm = 1087120\n",
    ") B\n",
    "where\n",
    "    B.cnty_code is not null\n",
    "    and B.r is not null\n",
    "order by\n",
    "    B.r desc,\n",
    "    B.s desc\n",
    "\"\"\"\n",
    "db.execute(qry).disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.missing()\n",
    "Y = self.X.query(\"distance.isnull() & (natn_code.isnull() | natn_code=='us') & stat_code not in ['hi','ak','pr','ae','ap']\")\n",
    "Y.sort_values('pidm').disp(1000)\n",
    "uniquify(Y['pidm'].tolist())\n",
    "# [['stat_code','natn_code']].disp(100)\n",
    "# self.X.iloc[[17412,30806]].disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"select distinct spraddr_stat_code from spraddr\"\n",
    "A = db.execute(qry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.value_counts('spbpers','spbpers_gndr_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('spbpers').columns.sort_values()\n",
    "db.head('opeir.admissions_fall2022').columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join(['AL','AR','AZ','CA','CO','CT','DC','DE','FL','GA','IA','ID','IL','IN','KS','KY','LA','MA','MD','ME','MI','MN','MO','MS','MT','NC','ND','NE','NH','NJ','NM','NV','NY','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VA','VT','WA','WI','WV','WY')\n",
    "# len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sort(A.squeeze().str.upper().unique().tolist()))\n",
    "# sort(A.squeeze().str.upper).unique().tolist())\n",
    "print(A.squeeze().str.upper().value_counts().sort_index().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"select A.* from spraddr A where A.spraddr_pidm = 1029274\"db.execute(qry).disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('opeir.admissions_fall2023',1).disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('szrsstd',1).disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute('stvatyp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = self.X.query(\"distance.isnull()\")['pidm'].tolist()\n",
    "qry = f\"select A.* from spraddr A where A.spraddr_pidm in ({join(L)}) and spraddr_stat_code='TX' order by spraddr_pidm\"\n",
    "# qry = f\"select A.* from sarappd A where A.sarappd_pidm in ({join(L)})\"\n",
    "# qry = f\"select A.*, (select sarappd_apdc_code from sarappd where sarappd_pidm = saradap_pidm and sarappd_appl_no = saradap_appl_no order by sarappd_seq_no desc fetch first 1 row only) as sarappd_apdc_code from saradap A where saradap_pidm in ({join(L)})\"\n",
    "A = db.execute(qry, show=True)\n",
    "A.disp(2000)\n",
    "# A['saradap_resd_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "w = pathlib.Path('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/flags/raw/old/201608_admitted_flags_report_031616.xlsx')\n",
    "w.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_ext(func):\n",
    "    def wrapper(X, *args, **kwargs):\n",
    "        try:\n",
    "            Y = func(X, *args, **kwargs)\n",
    "            print(1)\n",
    "        except:\n",
    "            Y = pd.DataFrame(X)\n",
    "            try:\n",
    "                Y = func(Y, *args, **kwargs)\n",
    "                print(2)\n",
    "            except:\n",
    "                Y = Y.apply(func, *args, **kwargs)\n",
    "                print(3)\n",
    "        if isinstance(X, pd.Series):\n",
    "            try:\n",
    "                Y = Y.squeeze()\n",
    "            except:\n",
    "                pass\n",
    "        return Y\n",
    "    wrapper.__name__ = func.__name__\n",
    "    return wrapper\n",
    "\n",
    "@pd_ext\n",
    "def binarize(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    s = set(ser.dropna())\n",
    "    if s:\n",
    "        if s.issubset({'y','Y'}):\n",
    "            ser = ser.notnull().astype('boolean')\n",
    "        elif s.issubset({0,1}):\n",
    "            ser = ser.astype('boolean')\n",
    "    return ser\n",
    "\n",
    "for func in [disp, to_numeric, prep, categorize, binarize, rnd, vc, missing, impute, unmelt]:\n",
    "    for cls in [pd.DataFrame, pd.Series]:\n",
    "        setattr(cls, func.__name__, func)\n",
    "\n",
    "# self.X['schlship_app'].value_counts()\n",
    "# self.X['fafsa_app'].value_counts()\n",
    "# self.X['schlship_app'].dtype\n",
    "# A = self.X.binarize()['schlship_app']\n",
    "# A['schlship_app']\n",
    "binarize(self.X)['schlship_app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['schlship_app'].groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "\n",
    "g = ['levl_code','styp_code','term_code','crse']\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\")[['pidm',*g,'credit_hr']].assign(credit_hr=lambda x: x['credit_hr'].fillna(0)>0) for term in self.term.values()]) for k in ['end','cur']}\n",
    "agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "A = agg(Y['end'], g)\n",
    "Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr'], how='inner') for k, y in Y.items()}\n",
    "B = agg(Y['end'], g)\n",
    "self.mlt = A / B\n",
    "\n",
    "self.Y = {k: y.squeeze().unstack().fillna(False).rename(columns=lambda x:f'{x}_{k}') for k, y in Y.items()}\n",
    "Y['end']\n",
    "# M = (end / cur).query(\"term_code != @self.infer\")\n",
    "# N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "# self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "\n",
    "\n",
    "# end\n",
    "self.Y['end']\n",
    "# Y = [self.Y[0].query(\"crse in @self.crse\").set_index('crse', append=True).unstack().droplevel(0,1).rename(columns=lambda x:f\"_{x}_end\")\n",
    "# # Y.droplevel?\n",
    "# Y.disp(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute(df, col, val=None, grp=None):\n",
    "#     val = val if val is not None else 'median' if pd.api.types.is_numeric_dtype(df[col]) else 'mode'\n",
    "#     if val in ['median']:\n",
    "#         func = lambda x: x.median()\n",
    "#     elif val in ['mean','ave','avg','average']:\n",
    "#         func = lambda x: x.mean()\n",
    "#     elif val in ['mode','most_frequent']:\n",
    "#         func = lambda x: x.mode()[0]\n",
    "#     else:\n",
    "#         func = lambda x: val\n",
    "#     df[col] = (df if grp is None else df.groupby(grp))[col].transform(lambda x: x.fillna(func(x)))\n",
    "#     return df\n",
    "# pd.DataFrame.impute = impute\n",
    "\n",
    "self.Z.reset_index(drop=True)\n",
    "A = self.Z.copy()\n",
    "c = '_birth_day'\n",
    "mask = A[c].isnull()\n",
    "# A.impute('_birth_day', val='median', grp=['term_code','styp_code'])\n",
    "# A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.loc[mask,c].disp(5)\n",
    "# A.groupby(['term_code','styp_code'])['_birth_day'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trf = ColumnTransformer(self.feat, remainder='drop',verbose_feature_names_out = False)\n",
    "# where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "# with warnings.catch_warnings(action='ignore'):\n",
    "#     self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "#     self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "\n",
    "kwargs = {\n",
    "    'feat': [\n",
    "        ['_gender',np.nan],\n",
    "        ['_appl_day',np.nan],\n",
    "        ['_apdc_day',np.nan],\n",
    "        ['_hs_qrtl',np.nan],\n",
    "        ['_act_equiv',np.nan],\n",
    "        ['_remote',False],\n",
    "        ['_resd',False],\n",
    "        ['_legacy',False],\n",
    "        *[[f'_race_{r}',False] for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        ['_waiver',False],\n",
    "        # ['_fafsa_app',False],\n",
    "        ['_schlship_app',False],\n",
    "        # ['_finaid_accepted',False],\n",
    "        ['_ssb',False],\n",
    "        ['_math',False],\n",
    "        ['_reading',False],\n",
    "        ['_writing',False],\n",
    "        ['_gap_score',0],\n",
    "        ['_oriented','n'],\n",
    "        ['_distance','max'],\n",
    "        ['_birth_day','median',['term_code','styp_code']],\n",
    "    ],\n",
    "}\n",
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "g = lambda col:'_'+col\n",
    "# cols = [x[0] for x in kwargs['feat']]\n",
    "# where(self.X).rename(columns=g)[cols].isnull().sum().disp(1000)\n",
    "X = where(self.X).set_index(self.attr, drop=False).rename(columns=g)\n",
    "Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "Z.isnull().sum().disp(1000)\n",
    "Z.dtypes\n",
    "# L = [Z.impute(col, *val)]\n",
    "# L = [[col, *listify(val)] for C, val in kwargs['feat'] for col in listify(C)]\n",
    "# L = [Z.impute(g(col), *listify(val)) for C, val in kwargs['feat'] for col in listify(C)]\n",
    "# L\n",
    "#).rename(columns=lambda x:'_'+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(Z).disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/flags/parq/flg_202308.parq', columns=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('spbpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"select spbpers_sex, count(*) from spbpers group by spbpers_sex\"\n",
    "db.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest import ImputationKernel\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer: int\n",
    "    crse: typing.List\n",
    "    feat: typing.Dict\n",
    "    attr: typing.List\n",
    "    sch: bool = True\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # check feat lists are disjoint\n",
    "        L = [x for f in self.feat for x in f[-1]]\n",
    "        assert len(L) == len(set(L))\n",
    "\n",
    "        self.term_codes = listify(self.term_codes)\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'X':False, 'Y':False, 'Z':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['Z'] |= self.overwrite['X'] | self.overwrite['Y']\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.path = root_path / f\"rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['pred']:\n",
    "            self[k] = self[k] if k in self else list()\n",
    "        for k in ['term']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "    def get_X(self):\n",
    "        nm = 'X'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        print(f'get {nm}')\n",
    "        R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "        repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "        R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "        R['camp_main'] = R['camp_code'] == 's'\n",
    "        R['distance'] = R['distance'].fillna(R['distance'].max())\n",
    "        R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "        R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm'})\n",
    "        R['coll_desc'] = R['coll_desc'].replace({\n",
    "            'ag & environmental sciences':'ag & natural resources',\n",
    "            'education & human development':'education',\n",
    "            'health science & human service':'health sciences',\n",
    "            'science & technology':'science & mathematics'})\n",
    "        majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "        S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "        R = R.drop(columns=majr).merge(S, on='majr_code', how='left')\n",
    "\n",
    "        checks = {\n",
    "            'cycle_day': R['cycle_day']>=0,\n",
    "            'apdc_day' : R['apdc_day' ]>=R['cycle_day'],\n",
    "            'appl_day' : R['appl_day' ]>=R['apdc_day' ],\n",
    "            'birth_day':(R['birth_day']>=R['appl_day' ]) & (R['birth_day']>=5000),\n",
    "            'distance': R['distance']>=0,\n",
    "            'hs_pctl': (R['hs_pctl']>=0) & (R['hs_pctl']<=100),\n",
    "            'act_equiv': (R['act_equiv']>=1) & (R['act_equiv']<=36),\n",
    "            'gap_score': (R['gap_score']>=0) & (R['gap_score']<=100),\n",
    "        }\n",
    "        for k, mask in checks.items():\n",
    "            if (~mask).any():\n",
    "                R[~mask].disp(10)\n",
    "                raise Exception(f'check failed - {k}')\n",
    "        self[nm] = R\n",
    "        return self.dump()\n",
    "\n",
    "    def preprocess(self):\n",
    "        nm = 'Z'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        self.get_X()\n",
    "        print(f'get {nm}')\n",
    "\n",
    "        trf = ColumnTransformer(self.feat, remainder='drop',verbose_feature_names_out = False)\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "            self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "            self.Z.missing().disp(100)\n",
    "            for c in ['_hs_qrtl', '_act_equiv']:\n",
    "                self.Z[c+'_missing'] = self.Z[c].isnull()\n",
    "            self.Z = self.Z.prep().binarize().categorize()\n",
    "        agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "        grp = ['levl_code','styp_code','term_code','crse']\n",
    "        end = agg(self.Y[0], grp)\n",
    "        \n",
    "        self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "        cur = agg(self.Y[0], grp)\n",
    "\n",
    "        M = (end / cur).query(\"term_code != @self.infer\")\n",
    "        N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "        self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, crse='_total', styp_code='all', train_term=202208, iterations=3, opts=dict()):\n",
    "        print(crse,train_term,styp_code, end=': ')\n",
    "        prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "        for P in self.pred:\n",
    "            if P['meta'] == prediction['meta']:\n",
    "                print('reusing')\n",
    "                return P\n",
    "        print(f'creating')\n",
    "        # d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "        d = {crse+'_cur':1, crse+'_end':0,}\n",
    "        end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "        Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "        T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "        if styp_code != \"all\":\n",
    "            T = T.query(\"styp_code==@styp_code\")\n",
    "        T.loc[T.eval(\"term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "        X = T.copy()\n",
    "        # qry = \"term_code!=@train_term\"\n",
    "        qry = \"term_code==@train_term\"\n",
    "        X.loc[X.eval(qry), end.keys()] = pd.NA\n",
    "        model = ImputationKernel(X, **opts)\n",
    "        model.mice(iterations)\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "            # assert 1==2\n",
    "        #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "        #     # imp.plot_correlations()\n",
    "\n",
    "        g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "        Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "        grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            S[x] = S[x] * S['mlt']\n",
    "        S.insert(2, 'err', S['pred'] - S['true'])\n",
    "        S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "        prediction['rslt'] = {'X':X,'T':T,'P':P,'model':model, 'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "        self.pred.append(prediction)\n",
    "        self.dump()\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def train(self, styp_codes=('n','r','t'), train_terms=None, iterations=3, opts=dict()):\n",
    "        train_terms = self.term_codes if train_terms is None else train_terms\n",
    "        def pivot(df, val, q=50):\n",
    "            Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "            for _ in range(2):\n",
    "                mr = Y.mean(axis=1)\n",
    "                ma = Y.abs().mean(axis=1)\n",
    "                Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "            return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "        \n",
    "        def analyze(df):\n",
    "            r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "            r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "            return r\n",
    "\n",
    "        P = {(crse, styp_code, train_term): self.predict(crse, styp_code, train_term, iterations, opts) for crse in self.crse for styp_code in listify(styp_codes) for train_term in listify(train_terms)}\n",
    "        R = dict()\n",
    "        for k,v in P.items():\n",
    "            R.setdefault(k[1]=='all', []).append(v)\n",
    "\n",
    "        for b, L in R.items():\n",
    "            v = {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']}\n",
    "            v['opts'] = opts.copy()\n",
    "            v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "            R[b] = v\n",
    "        return R\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "simpimp = lambda fill: SimpleImputer(strategy='constant', fill_value=fill, missing_values=pd.NA)\n",
    "kwargs = {\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_pctl',\n",
    "    ],\n",
    "    'feat': [\n",
    "        ('scl', make_pipeline(StandardScaler(), PowerTransformer()), [\n",
    "            'distance',\n",
    "            'birth_day',\n",
    "            # 'gap_score',\n",
    "            # 'hs_pctl',\n",
    "            'act_equiv',\n",
    "        ]),\n",
    "        ('pass', 'passthrough', [\n",
    "            'gender',\n",
    "            # 'styp_code',\n",
    "            # 'camp_code',\n",
    "            # 'coll_code',\n",
    "            # 'verified',\n",
    "            # 'term_code',\n",
    "            'appl_day',\n",
    "            'apdc_day',\n",
    "            'hs_qrtl',\n",
    "        ]),\n",
    "        ('false', simpimp(False), [\n",
    "            'camp_main',\n",
    "            'resd',\n",
    "            'legacy',\n",
    "            *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "            'waiver',\n",
    "            # 'fafsa_app',\n",
    "            'schlship_app',\n",
    "            # 'finaid_accepted',\n",
    "            'ssb',\n",
    "            'math',\n",
    "            'reading',\n",
    "            'writing',\n",
    "        ]),\n",
    "        ('0', simpimp(0), [\n",
    "            'gap_score',\n",
    "        ]),\n",
    "        ('n', simpimp('n'), [\n",
    "            'oriented',\n",
    "        ]),\n",
    "    ],\n",
    "    'infer': 202408,\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    # 'cycle_day': 197,\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'crse': [\n",
    "        '_total',\n",
    "        # 'engl1301',\n",
    "        # 'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'X': True,\n",
    "        # 'Y': True,\n",
    "        # 'Z': True,\n",
    "        'pred': True,\n",
    "    },\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    # 'sch': False,\n",
    "}\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "self = self.preprocess()\n",
    "self.term_codes.remove(self.infer)\n",
    "iterations = 3\n",
    "\n",
    "opts = dict()\n",
    "opts['random_state'] = 42\n",
    "opts['save_all_iterations'] = False\n",
    "opts['datasets'] = 5\n",
    "opts['mean_match_candidates'] = 10\n",
    "opts['mean_match_function'] = mean_match_kdtree_classification\n",
    "\n",
    "# # opts['datasets'] = 2\n",
    "# # opts['mean_match_candidates'] = 1\n",
    "# # opts['mean_match_function'] = default_mean_match\n",
    "\n",
    "# P = self.predict(opts=opts)\n",
    "\n",
    "R = self.train(iterations=iterations, opts=opts,\n",
    "    styp_codes='n',\n",
    "    # train_terms=202208,\n",
    "    )\n",
    "# for k in R[False]['rslt'].keys():\n",
    "#     for b, v in R.items():\n",
    "#         print(k, b)\n",
    "#         v['rslt'][k]['err%'].disp(100)\n",
    "\n",
    "# tune = []\n",
    "# for func in [mean_match_kdtree_classification, default_mean_match]:\n",
    "#     opts['mean_match_function'] = func\n",
    "#     for cand in range(2,41,3):\n",
    "#         opts['mean_match_candidates'] = cand\n",
    "#         print(sort(opts))\n",
    "#         R = self.train(\n",
    "#             styp_codes='n',\n",
    "#             iterations=iterations,\n",
    "#             opts=opts)\n",
    "#         R[False]['rslt']['_total','n']['err%'].disp(100)\n",
    "#         tune.append(R)\n",
    "#         write(self.tune, tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "match x:\n",
    "    case 2:\n",
    "        print(2)\n",
    "    case 10:\n",
    "        print(11)\n",
    "    case None:\n",
    "        print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['styp_code'].mode()\n",
    "# self.Z['_birth_day']['median']()\n",
    "df = pd.DataFrame()\n",
    "df['a'] = [1,1,2,2]\n",
    "df['b'] = ['a','a','a','a',]\n",
    "df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, col, val=None, grp=None):\n",
    "    val = val if val is not None else 'median' if pd.api.types.is_numeric_dtype(df[col]) else 'mode'\n",
    "    if val in ['median']:\n",
    "        func = lambda x: x.median()\n",
    "    elif val in ['mean','ave','avg','average']:\n",
    "        func = lambda x: x.mean()\n",
    "    elif val in ['mode','most_frequent']:\n",
    "        func = lambda x: x.mode()[0]\n",
    "    else:\n",
    "        func = lambda x: val\n",
    "    df[col] = (df if grp is None else df.groupby(grp))[col].transform(lambda x: x.fillna(func(x)))\n",
    "    return df\n",
    "pd.DataFrame.impute = impute\n",
    "\n",
    "self.Z.reset_index(drop=True)\n",
    "A = self.Z.copy()\n",
    "c = '_birth_day'\n",
    "mask = A[c].isnull()\n",
    "# A.impute('_birth_day', val='median', grp=['term_code','styp_code'])\n",
    "A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.loc[mask,c].disp(5)\n",
    "# A.groupby(['term_code','styp_code'])['_birth_day'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".102924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = self.pred[0]\n",
    "R = P['rslt']\n",
    "self.Z.dtypes\n",
    "# R['P'].dtypes#.values.astype(float)\n",
    "# model = self.pred[0]['rslt']['model']\n",
    "# model.feature_importance_df()\n",
    "# model.plot_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(self.path / 'predictions.csv', R[False]['summary'])\n",
    "write(self.path / 'predictions.parq', R[False]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.concat([term.raw for term in self.term.values()]).dropna(axis=1, how='all').reset_index(drop=True).prep()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.concat([term.raw for term in self.term.values()]).dropna(axis=1, how='all').reset_index(drop=True).prep()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "# R['hs_qrtl'] = \n",
    "R['A'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False)\n",
    "R['B'] = R['apdc_code'].map(repl)\n",
    "A\n",
    "# R['hs_qrtl'] = R['A'].combine_first(R['B'])\n",
    "# pd.concat([A,B],axis=1)\n",
    "R\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('stvapdc', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "idx = ['pidm','styp_code','apdc_code','apdc_desc']\n",
    "# P = self.X.set_index(idx)[['hs_pctl']]\n",
    "P = where(self.X).filter([*idx, 'hs_pctl'])\n",
    "repl = {\n",
    "    # 'a2':pd.NA,\n",
    "    # 'aa':pd.NA,\n",
    "    # 'ac':pd.NA,\n",
    "    # 'ad':pd.NA,\n",
    "    'ag':pd.NA,\n",
    "    'ai':pd.NA,\n",
    "    'at':pd.NA,\n",
    "    'ae':0,\n",
    "    'n1':1,\n",
    "    'n2':2,\n",
    "    'n3':3,\n",
    "    'n4':4,\n",
    "    'r1':1,\n",
    "    'r2':2,\n",
    "    'r3':3,\n",
    "    'r4':4,\n",
    "}\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "\n",
    "# bins = [100,89.9,74.9,49.9,24.9,0]\n",
    "# bool, default False\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "P['hs_qrtl'] = pd.cut(P['hs_pctl'], right=False, bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0]).combine_first(P['apdc_code'].map(repl))\n",
    "# P.query('hs_qrtl==2')\n",
    "# P.query(\"apdc_code=='n2'\")\n",
    "# P.vc(['apdc_desc','hs_qrtl']).disp(200)\n",
    "# Q = P.query(\"hs_qrtl.isnull()\")\n",
    "# P.groupby(['apdc_code','hs_qrtl']).size()\n",
    "P.groupby(['apdc_code','apdc_desc'])['hs_qrtl'].value_counts(normalize=True, dropna=False).round(2).sort_index().to_frame().disp(200)\n",
    "# Q.vc(['styp_code','apdc_code','apdc_desc']).disp(200)\n",
    "# P['hs_qrtl'].isnull().sum()\n",
    "# P.query(\"hs_qrtl.isnull()\").vc('apdc_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [100,89.9,74.9,49.9,24.9,0]\n",
    "np.arange(4,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P.query(\"apdc_code=='n2' & hs_pctl.notnull()\" ).disp(2000)\n",
    "P.query(\"apdc_code=='n2'\" ).disp(2000)\n",
    "# P.query(\"apdc_code=='n2'\").vc('hs_qrtl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.query(\"apdc_desc=='admitted (nr1)' & hs_qrtl==2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.query('hs_pctl.isnull()').vc('apdc_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    'a2':pd.NA,\n",
    "    'aa':pd.NA,\n",
    "    'ac':pd.NA,\n",
    "    'ad':pd.NA,\n",
    "    'ae':5,\n",
    "    'ag':pd.NA,\n",
    "    'ai':pd.NA,\n",
    "    'at':pd.NA,\n",
    "    'n1':1,\n",
    "    'n2':3,\n",
    "    'n3':4,\n",
    "    'n4':4,\n",
    "    'r1':1,\n",
    "    'r2':2,\n",
    "    'r3':3,\n",
    "    'r4':4,\n",
    "}\n",
    "P['q'] = P['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.vc(['apdc_code','apdc_desc'])\n",
    "# {'n1':1}\n",
    "# set(P.reset_index()['apdc_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.filter(like='_hs_pctl').query('_hs_pctl.isnull()').vc('apdc_desc')\n",
    "# # self.X.groupby('apdc_desc')['hs_pctl'].describe()\n",
    "# P = self.X[['apdc_desc','hs_pctl']]\n",
    "# pd.cut(self.X['hs_pctl'],4)\n",
    "# P = pd.cut(self.X.set_index(['pidm','apdc_desc'])['hs_pctl'], bins=[-1,25,50,75,100], labels=[1,2,3,4])\n",
    "P.vc(['apdc_desc','hs_qrtl']).disp(200)\n",
    "# P.groupby('apdc_desc').describe()\n",
    "# (P==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt'][('_total', 'n')]['proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A['summary'].query(\"pred_term!=202408 & styp_code=='n' & pred_term!=train_term\")#['err%']\n",
    "import seaborn as sns\n",
    "sns.boxplot(M, hue='train_term', y='err%', x='pred_term',\n",
    "    # fill=False,\n",
    "    whis=(0, 100),\n",
    "    dodge = True,\n",
    "    palette='tab10',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['Pmodel'].feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R[False]['rslt']['_total','n']['err%']\n",
    "R[False]['rslt']['_total','n'].keys()#['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P['rslt']['model'].feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_df(self, dataset, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(datset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_feature_importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = self.pred[0]['rslt']['model']\n",
    "# model.plot_feature_importance??\n",
    "imputed_var_names = [model._get_variable_name(int(i)) for i in np.sort(model.imputation_order)]\n",
    "predictor_var_names = [model._get_variable_name(int(i)) for i in np.sort(model.predictor_vars)]\n",
    "# model.\n",
    "c = '_total_end'\n",
    "I = pd.DataFrame(model.get_feature_importance(0), index=imputed_var_names, columns=predictor_var_names).T\n",
    "I *= 100 / I.sum()\n",
    "I[c].sort_values(ascending=False)\n",
    "# I.T['_total_end']\n",
    "# (0).shape\n",
    "#(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt']['_total','n'].keys()\n",
    "\n",
    "# ['rslt']['_total','n'].keys()\n",
    "# model = R[False]['rslt']['_total','n']\n",
    "#['model']\n",
    "# model.plot_feature_importance?\n",
    "# (dataset=0, annot=True,cmap=\"YlGnBu\",vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((len(f[-1]) for f in self.feat))\n",
    "L = [x for f in self.feat for x in f[-1]]\n",
    "len(L), len(set(L))\n",
    "# {x for f in self.feat for x in f[-1]}\n",
    "# {*self.feat[0][-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/flags/parq/flg_202308.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.columns\n",
    "F['styp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.isnull().sum().sort_index().disp(1000)\n",
    "# self.Z.dtypes\n",
    "# .vc('oriented')\n",
    "# hs_pctlact_equiv\n",
    "mask = self.Z['birth_day'].isnull()\n",
    "self.Z[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"select * from spbpers where spbpers_pidm=1115874\"\n",
    "db.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.select_dtypes('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.isnull().sum().sort_values(ascending=False).to_frame('missing').query('missing>0')\n",
    "# self.Z.vc('writing')\n",
    "# self.Z.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "feat = [\n",
    "    ('scl', make_pipeline(StandardScaler(), PowerTransformer()), [\n",
    "        'distance',\n",
    "        'birth_day',\n",
    "    ]),\n",
    "    # ('nom', FunctionTransformer(lambda x: x.astype('category')), [\n",
    "    ('nom', 'passthrough', [\n",
    "        'gender',\n",
    "        'oriented',\n",
    "        'styp_code',\n",
    "        # 'camp_code',\n",
    "        'coll_code',\n",
    "        # 'verified',\n",
    "    ]),\n",
    "    ('pass', 'passthrough', [\n",
    "        'term_code',\n",
    "        'math',\n",
    "        'reading',\n",
    "        'writing',\n",
    "        'hs_pctl',\n",
    "        'appl_day',\n",
    "        'apdc_day',\n",
    "        'act_equiv',\n",
    "    ]),\n",
    "    ('false', SimpleImputer(strategy='constant', fill_value=False), [\n",
    "        'camp_main',\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        # 'fafsa_app',\n",
    "        'schlship_app',\n",
    "        # 'finaid_accepted',\n",
    "        'ssb',\n",
    "    ]),\n",
    "    ('0', SimpleImputer(strategy='constant', fill_value=0), [\n",
    "        'gap_score',\n",
    "    ]),\n",
    "    # ('n', SimpleImputer(strategy='constant', fill_value='n'), [\n",
    "    #     'oriented',\n",
    "    # ]),\n",
    "\n",
    "]\n",
    "\n",
    "# trf = make_pipeline(ColumnTransformer(feat,remainder='drop',verbose_feature_names_out = False), ft)\n",
    "# trf = ColumnTransformer(feat,remainder='drop',verbose_feature_names_out = False)\n",
    "# Z = trf.fit_transform(self.X).binarize()\n",
    "# # Z = Z.apply(f)\n",
    "# # Z.isnull().sum()\n",
    "# Z.dtypes\n",
    "self.X.fillna({c:'' for c in self.X.select_dtypes('string').columns}, inplace=True)\n",
    "self.X.select_dtypes('string').isnull().sum().disp(300)\n",
    "# self.X.select_dtypes('string').fillna('')\n",
    "# self.X.select_dtypes('string').isnull().sum()\n",
    "\n",
    "# .fillna('')\n",
    "# Z\n",
    "# pd.api.types.is_string_dtype(Z['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('opeir.admissions_fall2022',2).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.waiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query(\"waiver.isnull()\").vc(['cycle_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.isnull().sum().disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt']['_total','n']['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in R[False]['rslt'].keys():\n",
    "    for b, v in R.items():\n",
    "        print(k, b)\n",
    "        v['rslt'][k]['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {k:v for k,v in R.items() if k[1]!='all'}.keys()\n",
    "R = {True:[], False:[]}\n",
    "for k,v in P.items():\n",
    "    R[k[1]=='all'].append(v)\n",
    "# q[True][0]['rslt'].keys()\n",
    "# for b,L in R.items():\n",
    "    # print(type(v))\n",
    "    # print(v[0]['rslt'].keys())\n",
    "\n",
    "S = {b: {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']} for b,L in R.items()}\n",
    "S[False]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def predict(self, crse='_total', train_term=202208, iterations=3, opts=dict()):\n",
    "    #     for styp_code in [\"n\",\"r\",\"t\",\"all\"]:\n",
    "    #         print(crse,train_term,styp_code, end=\": \")\n",
    "    #         prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "    #         for P in self.pred:\n",
    "    #             if P['meta'] == prediction['meta']:\n",
    "    #                 print('reusing')\n",
    "    #                 return P\n",
    "    #         print(f'creating')\n",
    "\n",
    "    #         d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "    #         end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "    #         Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "    #         T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "    #         if styp_code != \"all\":\n",
    "    #             T = T.query(\"styp_code==@styp_code\")\n",
    "    #         X = T.copy()\n",
    "    #         X.loc[X.eval(\"term_code!=@train_term or term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "    #         imp = ImputationKernel(X, **opts)\n",
    "    #         imp.mice(iterations)\n",
    "    #         # with warnings.catch_warnings(action='ignore'):\n",
    "    #         #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "    #         #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "    #         #     # imp.plot_correlations()\n",
    "\n",
    "    #         g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "    #         P = pd.concat([imp.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(imp.dataset_count())])\n",
    "    #         Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query('term_code != train_term').prep()\n",
    "    #         grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "    #         agg = lambda x: pd.Series({\n",
    "    #             'pred': x['pred'].sum(min_count=1),\n",
    "    #             'true': x['true'].sum(min_count=1),\n",
    "    #             'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    #             'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "    #         })\n",
    "    #         S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "    #         for x in ['pred','true']:\n",
    "    #             S[x] = S[x] * S['mlt']\n",
    "    #         S.insert(2, 'err', S['pred'] - S['true'])\n",
    "    #         S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "    #         prediction['rslt'] = {'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "    #         self.pred.append(prediction)\n",
    "    #         self.dump()\n",
    "    #     return prediction\n",
    "\n",
    "# class MM():\n",
    "#     def __init__(self, func, candidates):\n",
    "#         assert func in [mean_match_kdtree_classification, default_mean_match]\n",
    "#         self.func = func\n",
    "#         self.candidates = candidates\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return self.func(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return join([x for x in ['kdtree','default'] if x in self.func.__name__]+[self.candidates], \"_\")\n",
    "\n",
    "# class kdtree():\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return mean_match_kdtree_classification(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return 'kdtree__mean_match'\n",
    "\n",
    "# class default():\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return default_mean_match(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return 'default_mean_match'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = it.product(self.crse, ['n','r','t','all'])\n",
    "[[crse, styp_code, train_term] for crse, styp_code in Z for train_term in self.term_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = it.product(self.crse, ['n','r','t','all'])\n",
    "list(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    ('a','b'):7,\n",
    "    ('a','c'):71}\n",
    "d['a','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select\n",
    "        A.sfrstcr_term_code,\n",
    "        A.sfrstcr_pidm,\n",
    "        B.ssbsect_subj_code,\n",
    "        B.ssbsect_crse_numb,\n",
    "        B.ssbsect_credit_hrs,\n",
    "        A.sfrstcr_credit_hr\n",
    "from sfrstcr A, ssbsect B\n",
    "where\n",
    "        A.sfrstcr_term_code = B.ssbsect_term_code\n",
    "        and A.sfrstcr_crn = B.ssbsect_crn\n",
    "        and A.sfrstcr_term_code = 202308\n",
    "        and A.sfrstcr_ptrm_code not in ('28','R3')\n",
    "        and  trunc(to_date('18-Sep-23')) - trunc(A.sfrstcr_add_date) >= 197  -- added before cycle_day\n",
    "        and (trunc(to_date('18-Sep-23')) - trunc(A.sfrstcr_rsts_date) < 197 or A.sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "        and B.ssbsect_subj_code <> 'INST'\n",
    "        and A.sfrstcr_credit_hr <> B.ssbsect_credit_hrs\n",
    "\"\"\"\n",
    "db.head(qry, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"styp_code=='n' & pred_term!={self.infer}\"\n",
    "val = \"err%\"\n",
    "q=50\n",
    "P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "for _ in range(2):\n",
    "    P = (P.assign(mean=lambda x:x.mean(axis=1)) if P.shape[1] > 1 else P).T\n",
    "P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdtree = mean_match_kdtree_classification\n",
    "kdtree.__name__ = 'a'\n",
    "setattr(kdtree,'__str__','a')\n",
    "setattr(kdtree,'__repr__','a')\n",
    "\n",
    "print(kdtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "class MM():\n",
    "    def __init__(self, func, candidates):\n",
    "        self.func = func\n",
    "        self.candidates = candidates\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    def __str__(self):\n",
    "        return join([x for x in ['kdtree','deafult'] if x in self.func.__name__]+[self.candidates], \"_\")\n",
    "\n",
    "mm = MM(mean_match_kdtree_classification, 3)\n",
    "print(mm)\n",
    "# type(mean_match_kdtree_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_match_kdtree_classification.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = default_mean_match\n",
    "x.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # A[styp_code] = {\n",
    "            #     'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "            #     **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "\n",
    "\n",
    "\n",
    "    # R = {styp_code: {\n",
    "    #         'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "    #         **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "    #     } for styp_code in [\"n\"]}\n",
    "\n",
    "        # R['n']['proj'].disp(100)\n",
    "        # R['n']['err%'].disp(100)\n",
    "# B = (\n",
    "#     A['summary']\n",
    "#     .grpby(['crse','styp_code','train_term','pred_term'])\n",
    "#     # .grpby(['crse','styp_code','pred_term'])\n",
    "#     [['pred','err%','mse%','f1_inv%']]\n",
    "#     .agg(summary)\n",
    "#     .stack(0, sort=False)\n",
    "#     .rename_axis(index={None:'kind'})\n",
    "#     .query(f\"(pred_term == {self.infer} and kind == 'pred') or (pred_term != {self.infer} and kind == 'err%')\")\n",
    "#     .reset_index()\n",
    "#     # .sort_values(['crse','styp_code','pred_term','train_term'],ascending=[True,True,False,False])\n",
    "#     .prep()\n",
    "# )\n",
    "# M = A['summary'].query(\"pred_term != @self.infer & styp_code=='n'\").pivot_table(index='train_term', columns='pred_term', values='err%', margins=True)\n",
    "# M.disp(10)\n",
    "# B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R['n']['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {k: pd.concat([p['rslt'][k] for p in P]) for k in ['full','summary']}\n",
    "def pivot(qry, val, q=50):\n",
    "    P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q), margins=True, margins_name='mean')\n",
    "    for _ in range(2):\n",
    "        P = (P.head(1) if P.shape[0] == 2 else P).T\n",
    "    return P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n",
    "\n",
    "R = {styp_code: {\n",
    "    'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "    **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "} for styp_code in [\"n\"]}\n",
    "\n",
    "R['n']['proj'].disp(100)\n",
    "R['n']['err%'].disp(100)\n",
    "# }}\n",
    "# projections = pd.concat([piv(\"pred_term == @self.infer & styp_code=='n'\", 'pred', q) for q in [25,50,75]], axis=1)\n",
    "# errors = piv(\"pred_term != @self.infer & styp_code=='n'\", 'err%', 50)\n",
    "# Q\n",
    "# M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(p):\n",
    "    f = lambda x: x.quantile(p/100)\n",
    "    f.__name__ = f'{p}%'\n",
    "    f.__str__ = f'{p}%'\n",
    "    f.__repr__ = f'{p}%'\n",
    "    return f\n",
    "print(f\"{g(25)}\")\n",
    "display(f)\n",
    "str(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pctl(50)\n",
    "f.__repr__ = 'a'\n",
    "f.__str__ = 'a'\n",
    "f'{f}'\n",
    "# print(f)\n",
    "# f.__qualname__\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pctl(50)\n",
    "hasattr(w, '__name__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'hi'\n",
    "# x.__name__ = x\n",
    "hasattr(x, '__name__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piv(qry, val, q=50):\n",
    "    P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q), margins=True, margins_name='mean')\n",
    "    for _ in range(2):\n",
    "        P = (P.head(1) if P.shape[0] == 2 else P).T\n",
    "    return P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n",
    "A = {k: pd.concat([p['rslt'][k] for p in P]) for k in ['full','summary']}\n",
    "Q = pd.concat([piv(\"pred_term == @self.infer & styp_code=='n'\", 'pred', q) for q in [25,50,75]], axis=1)\n",
    "M = piv(\"pred_term != @self.infer & styp_code=='n'\", 'err%', 50)\n",
    "Q\n",
    "M\n",
    "# q = Q[0]\n",
    "# q\n",
    "# Q[0]\n",
    "# piv(\"styp_code=='n'\", 'err%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.T.assign(a=50).set_index('a', append=True).swaplevel(0,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Q[0]\n",
    "A.rename('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = (\n",
    "    A['summary']\n",
    "    .grpby(['crse','styp_code','train_term','pred_term'])\n",
    "    [['pred','err%','mse%','f1_inv%']]\n",
    "    .agg(summary)\n",
    "    .stack(0, sort=False)\n",
    "    .rename_axis(index={None:'kind'})\n",
    "    .query(f\"(pred_term == {self.infer} and kind == 'pred') or (pred_term != {self.infer} and kind == 'err%')\")\n",
    "    .reset_index()\n",
    "    # .sort_values(['crse','styp_code','pred_term','train_term'],ascending=[True,True,False,False])\n",
    "    .prep()\n",
    ")\n",
    "\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = A['summary'].query(\"pred_term!=202408 & styp_code=='n'\")['err%'].groupby(['train_term','pred_term']).mean().reset_index()#.unstack()\n",
    "# M.pivot_table(index='train_term',columns='pred_term', margins=True)\n",
    "\n",
    "# M\n",
    "A['summary'].reset_index().query(\"pred_term!=202408 & styp_code=='n'\").pivot_table(index='train_term', columns='pred_term', values='err%', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.disp(10)\n",
    "B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = self.Z.vc('term_code')\n",
    "v = t.values\n",
    "pd.DataFrame((v / v.T - 1) * 100, index=t.index, columns=t.index).round().prep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sort_values(['train_term','pred_term'], ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.disp(10)\n",
    "B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A['summary'].query(\"pred_term!=202408 & styp_code=='n' & pred_term!=train_term\")['err%'].groupby(['train_term','pred_term']).mean().unstack()\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary'].disp(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "    # self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False))\n",
    "# agg = lambda y, g: y.groupby(g)[['credit_hr']].sum()\n",
    "# grp = ['styp_code','term_code','crse']\n",
    "# end = agg(where(self.Y[0]), grp)\n",
    "# self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "# cur = agg(self.Y[0], grp)\n",
    "# M = (end / cur).query(\"term_code != @self.infer\")\n",
    "# N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "# self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "# return self.dump()\n",
    "\n",
    "agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "grp = ['levl_code','styp_code','term_code','crse']\n",
    "end = agg(self.Y[0], grp)\n",
    "self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "cur = agg(self.Y[0], grp)\n",
    "M = (end / cur).query(\"term_code != @self.infer\")\n",
    "M\n",
    "# agg(self.Y[0], grp).disp(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
