{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs, terms, 202108; complete: 1 / 4 = 25.00%; elapsed = 0.01 min; remaining = 0.02 min @ 0.0064 min per iteration\n",
      "inputs, terms, 202208; complete: 2 / 4 = 50.00%; elapsed = 0.01 min; remaining = 0.01 min @ 0.0073 min per iteration\n",
      "inputs, terms, 202308; complete: 3 / 4 = 75.00%; elapsed = 0.02 min; remaining = 0.01 min @ 0.0077 min per iteration\n",
      "inputs, terms, 202408; complete: 4 / 4 = 100.00%; elapsed = 0.03 min; remaining = 0.00 min @ 0.0080 min per iteration\n",
      "inputs, raw_df; complete: 1 / 1 = 100.00%; elapsed = 0.05 min; remaining = 0.00 min @ 0.0473 min per iteration\n",
      "inputs, X; complete: 1 / 1 = 100.00%; elapsed = 0.09 min; remaining = 0.00 min @ 0.0899 min per iteration\n",
      "inputs, reg_df; complete: 1 / 1 = 100.00%; elapsed = 0.00 min; remaining = 0.00 min @ 0.0022 min per iteration\n",
      "inputs, Y; complete: 1 / 1 = 100.00%; elapsed = 0.11 min; remaining = 0.00 min @ 0.1109 min per iteration\n"
     ]
    }
   ],
   "source": [
    "from LiveAMP import *\n",
    "# FLAGS().run()\n",
    "kwargs['styp_codes'] = ['n','t']\n",
    "self = AMP(**kwargs)\n",
    "# self.get_terms()\n",
    "# self.get_raw_df()\n",
    "# self.get_reg_df()\n",
    "# self.get_X()\n",
    "self.get_Y()\n",
    "# self.get_mlt()\n",
    "# self.get_transformed()\n",
    "# self.get_imputed()\n",
    "# self.get_predicted()\n",
    "# self.get_optimal()\n",
    "# self.get_details()\n",
    "\n",
    "# self.get_summary()\n",
    "# self.get_params()\n",
    "# self.push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ct</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crse_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>read3311</th>\n",
       "      <td>52</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read3321</th>\n",
       "      <td>52</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read3351</th>\n",
       "      <td>26</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read3356</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read4309</th>\n",
       "      <td>65</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read4384</th>\n",
       "      <td>49</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read5373</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read5376</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read5399</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reli3304</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest4303</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest4304</th>\n",
       "      <td>19</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest4305</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest4306</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnrm3301</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scma1100</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seng1100</th>\n",
       "      <td>34</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soci1301</th>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soci1306</th>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soci2303</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soci3304</th>\n",
       "      <td>19</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soci3312</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soci3330</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soci3368</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soci4302</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw2361</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw2362</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw3300</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw3306</th>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw3329</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw3339</th>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw3377</th>\n",
       "      <td>27</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw4311</th>\n",
       "      <td>28</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw4315</th>\n",
       "      <td>17</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw4622</th>\n",
       "      <td>21</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5310</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5321</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5330</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5340</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5360</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5362</th>\n",
       "      <td>27</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5371</th>\n",
       "      <td>17</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5373</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socw5376</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soil2112</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soil3101</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soil3301</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soil3302</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sosc1100</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span1303</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span1411</th>\n",
       "      <td>39</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span1412</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span2311</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span2312</th>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span3302</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span3303</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span4086</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span4302</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span4308</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teca1303</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teca1311</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teca1318</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univ0200</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univ0204</th>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univ0301</th>\n",
       "      <td>33</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univ0314</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univ0324</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univ0332</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univ0342</th>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univ1100</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vete3317</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vete4111</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vete4208</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vete4253</th>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vete4321</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vete4331</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses2322</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses2405</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses2451</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses3308</th>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses3311</th>\n",
       "      <td>43</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses3314</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses3323</th>\n",
       "      <td>22</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses3385</th>\n",
       "      <td>21</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses3406</th>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4090</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4187</th>\n",
       "      <td>22</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4301</th>\n",
       "      <td>36</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4302</th>\n",
       "      <td>19</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4309</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4311</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4318</th>\n",
       "      <td>24</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4325</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4326</th>\n",
       "      <td>40</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses4401</th>\n",
       "      <td>17</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses5085</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses5090</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses5301</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses5302</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wses5308</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = self['inputs']['reg_df']['cur']\n",
    "Y = self['inputs']['terms'][202208]['reg']['cur']\n",
    "Y.vc('crse_code').tail(100).disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "']\n",
    "Y.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['outputs']['params'].disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = self.predicted['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = self.outputs['summary'][['predicted','actual']].copy()\n",
    "S.loc[S.eval(\"styp_code=='all'\")] *= -1\n",
    "S.groupby(['crse_code','pred_code','train_code','mlt_code','imp','sim']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal\n",
    "D = pd.concat([getattr(C, 'details') for S in self.optimal.values() for T in S.values() for C in T.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "A = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/167/predicted/n/202208/_allcrse/0/0/0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haA.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_mlt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.summarize(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.predicted['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = D.query('pred_code != train_code').join(self['inputs']['mlt']).reset_index()\n",
    "# for k in ['train','mlt']:\n",
    "#     P[k+'_desc'] = 'fall ' + P[k+'_code'].astype('string').str[:4]\n",
    "# for k in ['predicted','actual']:\n",
    "#     P[k+'_mlt'] = P[k] * P['mlt']\n",
    "# Q = P.copy().assign(styp_code='all', styp_desc='all incoming')\n",
    "# # with warnings.catch_warnings(action='ignore'):\n",
    "# S = (\n",
    "#     pd.concat([P,Q])\n",
    "#     .groupby(['crse_code','levl_code','levl_desc','styp_code','styp_desc','pred_code','pred_desc','train_code','train_desc','mlt_code','mlt_desc','imp','sim'])\n",
    "#     .apply(lambda x: pd.Series({\n",
    "#         'mlt': x['mlt'].mean(),\n",
    "#         'predicted': x['predicted_mlt'].sum(),\n",
    "#         'actual': x['actual_mlt'].sum(),\n",
    "#         # 'error': x['predicted_mlt'].sum() - x['actual_mlt'].sum(),\n",
    "#         # 'error_pct': (x['predicted_mlt'].sum() - x['actual_mlt'].sum()) / x['actual_mlt'].sum() * 100,\n",
    "#         'acc_pct': accuracy_score(x['actual'], x['predicted']) * 100,\n",
    "#         'bal_acc_pct': balanced_accuracy_score(x['actual'], x['predicted']) * 100,\n",
    "#         # 'f1_pct': f1_score(x['actual'], x['predicted'], zero_division=np.nan)*100,\n",
    "#     }), include_groups=False)\n",
    "# )\n",
    "# S.insert(3, 'error', S['predicted'] - S['actual'])\n",
    "# S.insert(4, 'error_pct', S['error'] / S['actual'] * 100)\n",
    "# mask = S['actual'] == 0\n",
    "# if mask.any():\n",
    "#     S.loc[mask, 'error_pct':] = pd.NA\n",
    "#     S.loc[mask].disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame()\n",
    "A['a'] = [0,1,2]\n",
    "A['b'] = [0,0,1]\n",
    "A['c'] = (A['a'] / A['b']).replace(np.inf,pd.NA)\n",
    "# A = A.prep()\n",
    "# A.dtypes\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = {'nm': 'clf', 'styp_code': 'n', 'train_code': 202108, 'crse_code': '_allcrse', 'trf_idx': 0, 'imp_idx': 0, 'clf_idx': 0}\n",
    "P = self.get(path)\n",
    "P.keys()\n",
    "# self['predicted']['n']['202108']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_filename(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/167/predicted/n/202208/_allcrse/0/0/0.pkl')\n",
    "A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.trf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.styp_codes), len(self.term_codes), len(self.crse_codes), len(self.trf_list), len(self.imp_list), len(self.clf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.ImputationKernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.outputs['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [{'crse_code':crse_code, 'styp_code':styp_code, 'train_code':train_code, 'trf_idx': trf_idx, 'imp_idx': imp_idx, 'clf_idx': clf_idx,\n",
    "     **{f'trf_{key}': stringify(val) for key, val in clf.imp.trf.par.items()},\n",
    "     **{f'imp_{key}': stringify(val) for key, val in clf.imp.par.items()},\n",
    "     **{f'clf_{key}': stringify(val) for key, val in clf.par.items()},\n",
    "     'score': clf.score,\n",
    "    } for styp_code, S in self.predicted.items() for train_code, T in S.items() for crse_code, C in T.items() for trf_idx, trf in C.items() for imp_idx, imp in trf.items() for clf_idx, clf in imp.items()]\n",
    "df = pd.DataFrame(L)\n",
    "df.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [{'crse_code':crse_code, 'styp_code':styp_code, 'train_code':train_code, 'trf_idx': C.imp.trf.idx, 'imp_idx': C.imp.idx, 'clf_idx': C.idx,\n",
    "     **{f'trf_{key}': stringify(val) for key, val in C.imp.trf.par.items()},\n",
    "     **{f'imp_{key}': stringify(val) for key, val in C.imp.par.items()},\n",
    "     **{f'clf_{key}': stringify(val) for key, val in C.par.items()},\n",
    "     'score': C.score,\n",
    "    #  **{f'{step}_{key}': stringify(val) for step, D in C.params.items() for key, val in D.items()},\n",
    "    } for styp_code, S in self.optimal.items() for train_code, T in S.items() for crse_code, C in T.items()]\n",
    "df = pd.DataFrame(L)\n",
    "df.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['n'][202208]['_allcrse'].imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['outputs']['summary_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A():\n",
    "    pass\n",
    "a = A()\n",
    "a.x = 7\n",
    "b = A()\n",
    "b.x = 2\n",
    "L = [a,b]\n",
    "A = min(L, key=lambda z:z.x)\n",
    "# A = min(L, key=getattr(A,'x'))\n",
    "A.x\n",
    "getattr(A,'x')\n",
    "# L[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = self.predicted['n'][202208]['_allcrse'][2][0][0]\n",
    "a.imp.trf.par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dependancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.transformed['n']['all']['all'][1]#.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop(x, key):\n",
    "    y = x.copy()\n",
    "    y.pop(key)\n",
    "    return y\n",
    "L = [1,2]\n",
    "L = {'a':2,'b':5}\n",
    "pop(L,'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.transformed['n']['all']['all'][0].par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = [{'crse_code':crse_code, 'styp_code':styp_code, 'train_code':train_code} | {f'{step}_{key}': stringify(val) for step, D in C.params.items() for key, val in D.items()} for styp_code, S in self.predicted.items() for train_code, T in S.items() for crse_code, C in T.items()]\n",
    "# return pd.DataFrame(L).set_index(['crse_code', 'styp_code', 'train_code'])\n",
    "# L = [{'crse_code':crse_code, 'styp_code':styp_code, 'train_code':train_code, 'score':P.metric} | {f'{step}_{key}': stringify(val) for step, D in P.params.items() for key, val in D.items()} for styp_code, S in self.predicted.items() for train_code, T in S.items() for crse_code, C in T.items() for par, P in C.items()]\n",
    "# L = [{'crse_code':crse_code, 'styp_code':styp_code, 'train_code':train_code, **{f'{step}_{key}': stringify(val) for step, D in P.params.items() for key, val in D.items()}, 'score':P.metric} for styp_code, S in self.predicted.items() for train_code, T in S.items() for crse_code, C in T.items() for par, P in C.items()]\n",
    "L = [{\n",
    "        'crse_code':crse_code,\n",
    "        'styp_code':styp_code,\n",
    "        'train_code':train_code,\n",
    "        # 'params_idx': [stringify(x) for x in self.clf_imp_trf_list].index(stringify(P.params)),\n",
    "        # **{f'{step}_{key}': stringify(val) for step, D in P.params.items() for key, val in D.items()},\n",
    "        **{f'{step}': stringify(D) for step, D in P.params.items()},\n",
    "        # 'params':str(P.params),\n",
    "        'score':P.score,\n",
    "    } for styp_code, S in self.predicted.items() for train_code, T in S.items() for crse_code, C in T.items() for par, P in C.items()]\n",
    "df = pd.DataFrame(L)\n",
    "df\n",
    "# L[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in it.product(*enumerate(A), *enumerate(B), *enumerate(B)):\n",
    "    idx = x[0::2]\n",
    "    val = x[1::2]\n",
    "    print(idx)\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [10,11]\n",
    "B = [20,21]\n",
    "for (i, a), (j, b), (k, c) in it.product(enumerate(A), enumerate(B), enumerate(B)):\n",
    "    print(i, a, j, b, k, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['outputs']['summary_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = self['outputs']['params_df']\n",
    "A[A.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysort({f'{step}_{key}': stringify(val) for step, d in self.optimal['n'][202108]['_allcrse'].params.items() for key, val in d.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['outputs']['params_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/168/inputs/terms/202108.pkl')\n",
    "A.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.summary_df['all']#[0]['summary']\n",
    "# self.optimal['n'][202208]['_allcrse'].details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = stringify(self.optimal['n'][202208]['_allcrse'].params)\n",
    "# par = self.clf_imp_trf_list[2]\n",
    "[stringify(x) for x in self.clf_imp_trf_list].index(par)\n",
    "# par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "path = {'nm':'imputed', 'styp_code':'n', 'train_code':'all', 'crse_code':'all'}\n",
    "I = list(self.get(path).values())[0]\n",
    "path['crse_code'] = '_allcrse'\n",
    "path['train_code'] = 202208\n",
    "cols = uniquify(['_allcrse_cur', path['crse_code']+'_cur', path['crse_code']], False)\n",
    "Z = I.imputed.join(self.Y['all'][cols]).prep().prep_bool().prep_category().sort_index()\n",
    "Z.loc[Z.eval(f\"pred_code!=@path['train_code']\"), path['crse_code']] = pd.NA\n",
    "Z = Z.reset_index(drop=True)\n",
    "write(self.root / 'mice.parquet', Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.complete_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_raw_prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, miceforest as mf\n",
    "root = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/168/'\n",
    "Z = pd.read_parquet(root+'mice.parquet').apply(lambda ser: ser.astype('category') if pd.api.types.is_string_dtype(ser) else ser)\n",
    "targ = '_allcrse'\n",
    "clf = mf.ImputationKernel(Z, save_all_iterations=True, save_models=2)\n",
    "clf.mice(10)\n",
    "A = pd.DataFrame()\n",
    "d=0\n",
    "i=5\n",
    "A['label'] = clf.complete_data(dataset=d, iteration=i)[targ]\n",
    "A['proba'] = clf.get_raw_prediction(variable=targ, imp_dataset=d, imp_iteration=i)\n",
    "A.groupby('label')['proba'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.ImputationKernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.predicted['n'][202208]['_allcrse'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.get_raw_prediction(path['crse'], k)\n",
    "# ('_allcrse'\n",
    "# v.imputation_values?\n",
    "# v.\n",
    "# v.complete_data()\n",
    "# ('_allcrse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.imputation_values[0,27,1]\n",
    "v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = v.details\n",
    "A['trn'] = A.eval('pred_code==train_code')\n",
    "A.groupby(['predicted','trn'])['proba'].describe()\n",
    "B = A.query('predicted').sort_values('proba').head(10)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in self.predicted['n'][202208]['_allcrse'].items():\n",
    "    # v.details.disp(1)\n",
    "    # print(v.performance)\n",
    "    v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for par, df in self.performance['n'][202108]['_allcrse'].items():\n",
    "    df.disp(2)\n",
    "    df['zero'].describe().disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "df = load_iris(as_frame=True).frame\n",
    "df['target'] = df['target']==0\n",
    "df = df.prep().prep_bool()\n",
    "df.dtypes\n",
    "# d.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "import numpy as np, pandas as pd, miceforest as mf\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "df = load_iris(as_frame=True).frame\n",
    "df['target'] = df['target']==2\n",
    "df = df.prep().prep_bool()\n",
    "df_amp = mf.ampute_data(df,variables=['target'], perc=0.25, random_state=1991)\n",
    "\n",
    "ker = mf.ImputationKernel(\n",
    "  df_amp,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1991\n",
    ")\n",
    "ker.mice(2)\n",
    "A = pd.DataFrame()\n",
    "A['label'] = ker.complete_data()['target']\n",
    "A['proba'] = ker.get_raw_prediction('target')\n",
    "A.groupby('label')['proba'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.imputed['n']['all']['all'].keys()\n",
    "# self.transformed['n']['all'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.terms['all'][202108].reg['cur'].query(f\"crse_code in {self.crse_codes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.reg_df['all']['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['all'].disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['all'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['reg_df']['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.raw_df.disp(1)#.vc('styp_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a':7}\n",
    "bool(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {'nm':['a','b'], 'val':[1,2], 'w':7}\n",
    "cartesian(A)\n",
    "# B = \n",
    "# list(it.product(A,B,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a':4}\n",
    "if not d:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.terms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.imp_trf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_raw_prediction(crse, imp_dataset=4, model_dataset=1)\n",
    "clf.complete_data(0)[crse].disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_allcrse'\n",
    "clf = P['clf']\n",
    "k = 0\n",
    "# Y = clf.complete_data(k)[crse].rename('label').to_frame().assign(proba=clf.get_raw_prediction(crse,k))\n",
    "# Y.groupby('label').describe()\n",
    "# clf.get_raw_prediction\n",
    "# clf.com\n",
    "mod = clf.get_model(0,crse)\n",
    "X = P['input'].copy()\n",
    "Y = X.pop(crse)\n",
    "# mod.predict(X,raw_score=False)\n",
    "Y = Y.rename('label').to_frame().assign(proba=mod.predict(X))\n",
    "Y.groupby('label').describe()\n",
    "# Y.disp(1)\n",
    "# mod.predict?\n",
    "# P['input'].disp(1)\n",
    "# mod.feature_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P['input'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.outputs['details'].disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.details_df.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(X):\n",
    "    g = lambda Y: [g(k) for k in Y] if isinstance(Y, list) else {g(k): g(v) for k,v in Y.items()} if isinstance(Y, dict) else str(Y).replace('\\n','').replace(' ','')\n",
    "    # return str(g(X))\n",
    "    return str(g(X))\n",
    "\n",
    "# self.transformed['_allcrse']['n']['all'].keys()\n",
    "# print(stringify(self.trf_list))\n",
    "# stringify(self.trf_list)\n",
    "str(self.trf_list).replace('\\n','').replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in self.transformed['_allcrse']['n']['all'].keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(X):\n",
    "    return [stringify(k) for k in X] if isinstance(X, list) else {stringify(k): stringify(v) for k,v in X.items()} if isinstance(X, dict) else str(X).replace('\\n','').replace(' ','')\n",
    "    # return str(y)#.replace('\\n','').replace(' ','')\n",
    "    # return str(Y)#.replace('\\n','').replace(' ','')\n",
    "\n",
    "stringify(self.trf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [{'crse':crse, 'styp_code':styp_code, 'train_code':train_code, 'idx': self.trf_list.index(T['par']['trf'])} | T['par']['trf'] for crse, C in self.optimal.items() for styp_code, S in C.items() for train_code, T in S.items()]\n",
    "Z = pd.DataFrame(L).prep().set_index(['crse','styp_code','train_code'])\n",
    "Z.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "for crse, C in self.optimal.items():\n",
    "    for styp_code, S in C.items():\n",
    "        for train_term, T in S.items():\n",
    "            self.trf_list.index(T['par']['trf'])\n",
    "\n",
    "            idx = [stringify(x) for x in self.clf_imp_trf_list].index(T)\n",
    "            trf = self.clf_imp_trf_list[idx]['trf']\n",
    "            idx = self.trf_list.index(trf)\n",
    "            # idx = [x for x in self.trf_list].index(trf)\n",
    "            L.append({'idx':idx}|trf)\n",
    "            # print(self.trf_list.index(trf), stringify(trf))\n",
    "            # idx = [x for x in self.trf_list].index(trf)\n",
    "            \n",
    "pd.DataFrame(L).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.optimal.values())[0]\n",
    "L = [str(x) for x in self.clf_list]\n",
    "idx = L.index(self.optimal['_allcrse']['n'][202108])\n",
    "self.clf_list[idx]['trf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(x):\n",
    "    if isinstance(x, dict):\n",
    "        return {stringify(k): stringify(v) for k,v in x.items()}\n",
    "    elif isinstance(x, list):\n",
    "        return [stringify(k) for k in x]\n",
    "    else:\n",
    "        return str(x).replace('\\n','').replace(' ','')\n",
    "# g(eval(g(self.clf_list)[1])['trf']['distance'])\n",
    "# list(self.clf_list.values())[0]\n",
    "# eval(g(self.clf_list)[1])['trf']\n",
    "stringify(self.clf_imp_trf_list)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.trf_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(T) in self.clf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "for crse, C in self.optimal.items():\n",
    "    for styp_code, S in C.items():\n",
    "        for train_term, T in S.items():\n",
    "            print(T)\n",
    "            # print(train_term)\n",
    "            d = ast.literal_eval(str(T))\n",
    "            # d = eval(T)\n",
    "            # d = {'trf':eval(T)['trf']}\n",
    "            print(d in self.clf_list, d)\n",
    "            \n",
    "            # print(train_term, self.trf_list.index(d))\n",
    "            # for k, v in eval(T)['trf'].items():\n",
    "            #     print(k, str(v).replace('\\n','').replace(' ',''))\n",
    "            # print()\n",
    "            # assert 1==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k,v in self.transformed['_allcrse']['n']['all'].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = {'nm': 'transformed', 'crse': '_allcrse', 'styp_code': 'n', 'train_code': 'all'}\n",
    "for k,v in self.get(path)[0].items():\n",
    "    print(k)\n",
    "# self.get(path)[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.trf_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in self.transformed['_allcrse']['n']['all'].items():\n",
    "    print(k)\n",
    "# .keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.trf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.trf_list),len(self.imp_list),len(self.par_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.params_list[0]\n",
    "{p['imp'] for p in self.params_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.trf_list = cartesian({k: uniquify(v, key=str) for k,v in self.trf_grid.items()})\n",
    "A = [{'trf': uniquify({k:v for k,v in t.items() if v not in ['drop',None,'']}) for t in self.trf_list}]\n",
    "A[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysort([uniquify({'imp':imp, 'trf':trf}) for imp, trf in it.product(self.imp_list, self.trf_list)], key=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = subdct(params, ['trf'], True)\n",
    "{subdct(params, ['trf'], True) for params in self.params_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.trf_list)\n",
    "len(self.crse) * len(self.styp_codes) * len(self.term_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = list(self.predicted['_allcrse']['n'][202108].values())[0]#.reset_index()\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = self.details['_allcrse']['n'][202108].join(self.mlt).reset_index()\n",
    "T = D[['pred_code','pred_desc']].drop_duplicates()\n",
    "for k in ['train','mlt']:\n",
    "    D = D.merge(T.rename(columns=lambda x:x.replace('pred',k)))\n",
    "for k in ['predicted','actual']:\n",
    "    D[k+'_mlt'] = D[k] * D['mlt']\n",
    "E = D.copy().assign(styp_code='all', styp_desc='all incoming')\n",
    "A = (\n",
    "    pd.concat([D,E])\n",
    "    .groupby(['crse','levl_code','styp_code','styp_desc','pred_code','pred_desc','train_code','train_desc','mlt_code','mlt_desc','imp','sim'])\n",
    "    .apply(lambda x: pd.Series({\n",
    "        'predicted': x['predicted_mlt'].sum(),\n",
    "        'actual': x['actual_mlt'].sum(),\n",
    "        'error': x['predicted_mlt'].sum() - x['actual_mlt'].sum(),\n",
    "        'error_pct': (x['predicted_mlt'].sum() - x['actual_mlt'].sum()) / x['actual_mlt'].sum() * 100,\n",
    "        'mse_pct': ((1*x['predicted'] - x['actual'])**2).mean()*100,\n",
    "        'f1_inv_pct': (1-f1_score(x['actual'], x['predicted'], zero_division=np.nan))*100,\n",
    "    }), include_groups=False)\n",
    ")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#         agg, include_groups=False)\n",
    "#     # .apply(agg, include_groups=True)\n",
    "# )\n",
    "\n",
    "\n",
    "# agg = lambda x: pd.Series({\n",
    "#     'predicted': x['predicted_mlt'].sum(),\n",
    "#     'actual': x['actual_mlt'].sum(),\n",
    "#     'error': x['predicted_mlt'].sum() - x['actual_mlt'].sum(),\n",
    "#     'error_pct': (x['predicted_mlt'].sum() - x['actual_mlt'].sum()) / x['actual_mlt'].sum() * 100,\n",
    "#     'mse_pct': ((1*x['predicted'] - x['actual'])**2).mean()*100,\n",
    "#     'f1_inv_pct': (1-f1_score(x['actual'], x['predicted'], zero_division=np.nan))*100,\n",
    "# })\n",
    "# # A = pd.concat([D,E]).groupby(['crse','levl_code','styp_code','styp_desc','pred_code','pred_desc','train_code','train_desc','mlt_code','mlt_desc','imp','sim']).apply(agg)\n",
    "# A = (\n",
    "#     pd.concat([D,E])\n",
    "#     .groupby(['crse','levl_code','styp_code','styp_desc','pred_code','pred_desc','train_code','train_desc','mlt_code','mlt_desc','imp','sim'])\n",
    "#     # [['predicted_mlt']].sum()\n",
    "#     # .apply(agg)\n",
    "#     .apply(agg, include_groups=False)\n",
    "#     # .apply(agg, include_groups=True)\n",
    "# )\n",
    "print(A.shape)\n",
    "A\n",
    "# # A.disp(20)\n",
    "# B = A[['pred_code','pred_desc']].drop_duplicates()\n",
    "# for k in ['train','mlt']:\n",
    "# # C = B.rename(columns=lambda x:x.replace('pred','train'))\n",
    "#     A = A.merge(B.rename(columns=lambda x:x.replace('pred',k)))\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = self.Y['_allcrse'].copy()\n",
    "Z = Y.copy().rename('predicted').to_frame().assign(actual=Y)\n",
    "# Z = pd.DataFrame(Y.values).assign(actual=Y)\n",
    "Z.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlt.insert?\n",
    "# self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[p] = pd.concat([actual.assign(predicted=predicted.complete_data(k)[path['crse']]).addlevel('crse', path['crse']).addlevel('sim', k) for k in range(predicted.dataset_count())]).prep_bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S['_allcrse'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.imputed['_allcrse']['n']['all'].values())[0].reset_index().dtypes.sort_index().disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.predicted['_allcrse']['n'][202108].values())[0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = self.details['_allcrse']['n'][202108]#.join(self.mlt)#.reset_index().rename(columns={'term_code':'pred_code', 'term_desc':'pred_desc'})\n",
    "# for k in ['predicted','actual']:\n",
    "#     D[k+'_mlt'] = D[k] * D['mlt']\n",
    "\n",
    "D.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = list(self.imputed['_allcrse']['n']['all'].values())[0]\n",
    "Y = self.Y[['_allcrse']]\n",
    "Z = I.join(Y)\n",
    "Z.vc('train_code')\n",
    "# Z['_allcrse'].sum()\n",
    "# Z.loc[Z.eval(f\"pred_code!=train_code\"), path['crse']] = pd.NA\n",
    "# Z['_allcrse'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd_ext\n",
    "def addlevel(df, level, val):\n",
    "    return df.assign(**{level:val}).set_index(level, append=True)\n",
    "\n",
    "self.mlt.addlevel('test',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.reset_index().dtypes.sort_index().disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.reg_df['end'].dtypes.sort_index().disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlevel(df, level, val):\n",
    "    return def.assign(level=val).set_index(level, append=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame()\n",
    "A['s']=[1,2]\n",
    "A\n",
    "A.droplevel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = self.details['_allcrse']['n'][202108]\n",
    "A = D.join(self.mlt).reset_index().rename(columns={'train_term':'train_code', 'mlt_term':'mlt_code'})\n",
    "# A.join()\n",
    "# A.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.disp(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = A[['term_code','term_desc']].drop_duplicates()\n",
    "B = T.rename(columns=lambda x:x.replace('term','train'))\n",
    "B\n",
    "# pd.merge(A,T.rename(columns=lambda x:x.replace('term','train'))).disp(6)\n",
    "# pd.merge(left_on right_on='train_code', right_on)\n",
    "C = A.merge(T.rename(columns=lambda x:x.replace('term','train'))).merge(T.rename(columns=lambda x:x.replace('term','mlt')))\n",
    "C.disp(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{str(100*(2000+yr)+8): f\"Fall {yr}\" for yr in range(20,24)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP_copy import *\n",
    "orig = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/174/details_df'\n",
    "# orig = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/details_df'\n",
    "new = orig+'_new.csv'\n",
    "orig += '.csv'\n",
    "B = read(orig)\n",
    "B\n",
    "A = B.copy()\n",
    "A['styp_code'] = 'all'\n",
    "cols = A.columns.to_list()\n",
    "a = cols.index('predicted')\n",
    "b = cols.index('error_pct')\n",
    "idx = cols[:a]\n",
    "val = cols[a:b]\n",
    "A = A.groupby(idx)[val].sum().reset_index()\n",
    "A['error_pct'] = A['error'] / A['actual'] * 100\n",
    "C = (\n",
    "    pd.concat([A,B])\n",
    "    .drop(columns=['imp'])\n",
    "    .rename(columns={'predicted':'predict'})\n",
    "    .replace({\n",
    "        'styp_code':{'n':'new first time', 't':'transfer', 'r':'returning'},\n",
    "        'crse':{'_allcrse':'_total'}\n",
    "    })\n",
    ")\n",
    "for col in ['term_code', 'train_term', 'mlt_term']:\n",
    "    C[col] = C[col].astype('string').replace({str(100*(2000+yr)+8): f\"Fall {yr}\" for yr in range(0,40)})\n",
    "C\n",
    "C.to_csv(new, index=False)\n",
    "target_url = 'https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M'\n",
    "with open(new, 'rb') as target_file:\n",
    "    response = requests.post(target_url, files = {\"amp_summary.csv\": target_file})\n",
    "print('file pushed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_filename(['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3670 - 2785) / 2785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.summary['_allcrse'].keys()\n",
    "# {nm: pd.concat([C for C in B.values() for B in A.values() for A in self[nm].values()]) for nm in ['details', 'summary']}\n",
    "W = {nm: pd.concat([C for A in self[nm].values() for B in A.values() for C in B.values()]) for nm in ['details', 'summary']}\n",
    "W.keys()\n",
    "W['summary'].disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.crse.append('hkj')\n",
    "missing = [c for c in self.crse if c not in self.Y]\n",
    "assert not missing\n",
    "# self.crse in\n",
    "# self.Y.columns.is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['optimal']['_allcrse']['n'][202108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['inputs'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.root.parents)\n",
    "join(self.root.parts[-2:],'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = self['inputs']\n",
    "# I['Y'].disp(1)\n",
    "# I['reg_df']['end'].vc('crse')\n",
    "I['term'][202208]['reg']['cur'].vc('crse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.trf_list) * len(self.styp_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {'a':1,'b':2}\n",
    "B = A | {'a':111}\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['inputs']['term'][202108]#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get('reg_df')\n",
    "self.get_terms()\n",
    "self.term\n",
    "{k: pd.concat([term.reg[k].query(f\"crse in {self.crse}\") for term in self.term.values()]).prep() for k in ['cur','end']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_filename('imputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/175/X.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rslt\n",
    "self.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def get_filename(self, path):\n",
    "    #     return self.root / join(path.values() if isinstance(path, dict) else path, '/') + '.parq'\n",
    "\n",
    "path = ['predicted','_total','n',202108]\n",
    "(self.root / join(path.values() if isinstance(path, dict) else path, '/')).with_suffix('.parq')\n",
    "A, b, path = self.get(path)\n",
    "A.keys()\n",
    "# self.get_filename(path)\n",
    "# self['transformed']['_total']['n'].keys()#[202108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nm in ['transformed', 'imputed', 'predicted', 'performance', 'optimal', 'details', 'summary']:\n",
    "    for crse, C in self[nm].items():\n",
    "        for styp_code, S in C.items():\n",
    "            for train_term, T in S.items():\n",
    "                path = {'nm':nm, 'crse':crse, 'styp_code':styp_code, 'train_term':train_term}\n",
    "                self.set(path)#[0].disp(1)\n",
    "                # self.set(path)\n",
    "                assert 1==2\n",
    "                # for params in self.params_list:\n",
    "                #     c = getattr(self, 'get_'+nm)(path, params)[1]\n",
    "                #     progress[c] += (2*c-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get(path)[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A\n",
    "b\n",
    "self.get_filename(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.optimal_params['_total']['n'][202308])\n",
    "{nm: pd.concat([C for C in B.values() for B in A.values() for A in self[nm].values()]) for nm in ['details', 'summary']}\n",
    "for nm in 'optimal_predicted':\n",
    "    # [C for A in self[nm].values() for B in A.values() for C in B.values()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.predicted['_total']['n'][202208])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.summary['_total']['n'][202108]#.shape[0]/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query(\"styp_code=='n'\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal_params['_total']['n'][202108]#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "if d:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.styp_codes) * len(self.trf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self['term'][202108]\n",
    "self.get(['term',202108])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x=dict()):\n",
    "    return x\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ['imputed','_total',None]\n",
    "self.get(path)\n",
    "# self['imputed']['_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d = {'a':2,'b':1}\n",
    "str(d), \n",
    "json.loads(json.dumps(d))['b']\n",
    "# sorted(d, key=.value)\n",
    "# min(d, key=d.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ['_total', 'n', 202208]\n",
    "nest(path, self.predicted).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = list(self.predicted['_total']['n'][202208].values())[0]\n",
    "(A['actual'] == A['predicted']).mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a':7,'b':10,'c':11}\n",
    "def subdct(X, keys, sort=False, **kwargs):\n",
    "    Y = {k: X[k] for k in keys}\n",
    "    return mysort(Y, **kwargs) if sort else Y\n",
    "\n",
    "subdct(d, ['b','a'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.performance['_total']['n'].values())[0][202108]#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.__dict__.keys()\n",
    "self.get('Y')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ['X']\n",
    "nest(path, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.crse) * len(self.styp_codes) * len(self.styp_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [0,1]\n",
    "x = 3\n",
    "L[x>0] += x\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.X.dtypes.disp(1000)\n",
    "list(self.transformed['_total']['n'].values())[0]['all'].missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = \"pidm.notnull()\"\n",
    "self.raw_df.eval(\"pidm.notnull()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dict()\n",
    "path['crse'] = '_total'\n",
    "path['train_term'] = 202308\n",
    "cols = uniquify(['_total_cur', path['crse']+'_cur', path['crse']], False)\n",
    "I.disp(1)\n",
    "Z = I.join(self.Y[cols]).prep().prep_bool().prep_category().sort_index()\n",
    "y = Z[path['crse']].copy().rename('actual').to_frame()\n",
    "Z.loc[Z.eval(f\"term_code!=202108\"), path['crse']] = pd.NA\n",
    "# Z.loc[Z.eval(f\"term_code!={path['train_term']}\"), path['crse']] = pd.NA\n",
    "Z.missing()\n",
    "# Z.dtypes\n",
    "# self.Y[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.missing(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [uniquify({'clf':clf, 'imp':imp, 'trf':trf}) for clf, imp, trf in it.product(self.clf_list, self.imp_list, self.trf_list)]\n",
    "B = listify(A)\n",
    "B\n",
    "# dict.fromkeys(A)\n",
    "# uniquify(A, key=str)\n",
    "\n",
    "# , key=str)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.imputed['_total']['n'].values())[0][202108]['imp'].unique()\n",
    "# path=['_total','n']\n",
    "# nest(path, self.imputed).keys()\n",
    "# self.imputed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a':1,'b':2}\n",
    "d.pop('a')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.raw_df.missing()\n",
    "# self.raw_df.query(\"majr_code.str.contains('und') or majr_code=='0000'\").vc(['majr_code','coll_code']).disp(200)\n",
    "# self.X.query(\"majr_code.str.contains('und') or majr_code=='0000'\").vc(['majr_code','coll_code']).disp(200)\n",
    "# self.X.query(\"coll_code.isnull()\")\n",
    "self.X.vc(\"majr_code\").disp(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.missing()\n",
    "# X.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "\n",
    "R = self.raw_df.copy()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "R['remote'] = R['camp_code'] != 's'\n",
    "R['resd'] = R['resd_code'] == 'r'\n",
    "R['lgcy'] = ~R['lgcy_code'].isin(['n','o'])\n",
    "R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm', '00':pd.NA})\n",
    "R['coll_desc'] = R['coll_desc'].replace({\n",
    "    'ag & environmental_sciences':'ag & natural_resources',\n",
    "    'education & human development':'education',\n",
    "    'health science & human_service':'health sciences',\n",
    "    'science & technology':'science & mathematics'})\n",
    "majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "X = where(R.drop(columns=majr).merge(S, on='majr_code', how='left')).prep().prep_bool()\n",
    "\n",
    "checks = [\n",
    "    'cycle_day >= 0',\n",
    "    'apdc_day >= cycle_day',\n",
    "    'appl_day >= apdc_day',\n",
    "    'birth_day >= appl_day',\n",
    "    'birth_day >= 5000',\n",
    "    'distance >= 0',\n",
    "    'hs_pctl >=0',\n",
    "    'hs_pctl <= 100',\n",
    "    'hs_qrtl >= 0',\n",
    "    'hs_qrtl <= 4',\n",
    "    'act_equiv >= 1',\n",
    "    'act_equiv <= 36',\n",
    "    'gap_score >= 0',\n",
    "    'gap_score <= 100',\n",
    "]\n",
    "for check in checks:\n",
    "    mask = X.eval(check)\n",
    "    assert mask.all(), [check,X[~mask].disp(5)]\n",
    "\n",
    "for k, v in self.fill.items():\n",
    "    X[k] = X.impute(k, *listify(v))\n",
    "X = X.prep().prep_bool().set_index(self.attr, drop=False)[self.trf_grid.keys()]\n",
    "for nm, msg in self.X.isnull().mean().items():\n",
    "    if msg > 0.05:\n",
    "        X[nm+'_missing'] = X[nm].isnull()\n",
    "self.X = X.prep_bool().rename(columns=lambda x:'__'+x)\n",
    "\n",
    "# self.X = X.prep().prep_bool().set_index(self.attr, drop=False)[self.trf_grid.keys()]#.rename(columns=lambda x:'__'+x)\n",
    "# for nm, msg in self.X.isnull().mean().items():\n",
    "#     if msg > 0.05:\n",
    "#         self.X[nm+'_missing'] = self.X[nm].isnull().prep_bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(d):\n",
    "    d['a'] = 3\n",
    "    return \n",
    "d = {'b':7,'a':10}\n",
    "d['b']=9\n",
    "# f(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a':3}\n",
    "listify(d.keys())\n",
    "d.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.disp()\n",
    "# self.X.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = self.optimal['summary'].query(f\"term_code<{self.infer_term}\").groupby(['crse','styp_code','term_code','train_term'])['error_pct'].agg(lambda x:x.abs().median())\n",
    "A.unstack().disp(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.trf_list = cartesian({k: sorted(setify(v), key=str) for k,v in self.trf_grid.items()})\n",
    "self.trf_list = [mysort({k:v for k,v in t.items() if v not in ['drop',None,'']}) for t in self.trf_list]\n",
    "len(self.trf_list)\n",
    "\n",
    "\n",
    "Z = self.X\n",
    "\n",
    "\n",
    "for styp_code in ['n','t']:\n",
    "    for trf_spec in self.trf_list:\n",
    "        print(trf_spec)\n",
    "        assert 1==2\n",
    "        X = self.X.copy()\n",
    "        if styp_code != 'all':\n",
    "            X = X.query(f\"styp_code=='{styp_code}'\")\n",
    "        trf = ColumnTransformer([(c,t,[\"__\"+c]) for c,t in trf_spec.items()], remainder='drop', verbose_feature_names_out=False)\n",
    "        Z = trf.fit_transform(X)\n",
    "        # Z[(Z.isnull().mean()>.1)].disp()\n",
    "        for nm, msg in Z.isnull().mean().items():\n",
    "            if msg > 0.1:\n",
    "                print(nm)\n",
    "        # M[M>0.1].disp()\n",
    "        # Z.missing().disp(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(self.X.groupby(['term_code','styp_code']).agg(lambda x:x.isnull().mean())*100).round().prep().replace(0,pd.NA).dropna(how='all',axis=1).T.disp(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crse, C in self.pred.items():\n",
    "    for styp_code, S in C.items():\n",
    "        for params, P in S.items():\n",
    "            for train_term, T in P.items():\n",
    "                assert 'details' in T\n",
    "                # try:\n",
    "                #     y = T['details']\n",
    "                #     self.aggregate(y)\n",
    "                # except:\n",
    "                #     print(crse)\n",
    "                # print(T.keys())\n",
    "                # assert 1==2\n",
    "            # E = P['summary'].query(f\"term_code!=train_term & term_code!={self.infer_term}\")[\"error_pct\"].abs()\n",
    "            # print(E.max())\n",
    "            # assert 1==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a':3}\n",
    "d.pop('a', 9)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def main(self, styp_codes=('n','t','r')):\n",
    "        self.preprocess()\n",
    "        styp_codes = listify(styp_codes)\n",
    "        g = lambda Y: Y | {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "        L = len(self.crse) * len(styp_codes) * len(self.params_list)\n",
    "        k = 0\n",
    "        start_time = time.perf_counter()\n",
    "        self.optimal = dict()\n",
    "        for crse in self.crse:\n",
    "            for styp_code in listify(styp_codes):\n",
    "                for params_idx, params in enumerate(self.params_list):\n",
    "                    print(\"\\n========================================================================================================\\n\")\n",
    "                    print(ljust(crse,8),styp_code,params_idx)\n",
    "                    new = False\n",
    "                    for train_term in self.term_codes:\n",
    "                        path = [crse,styp_code,str(params),train_term,'details']\n",
    "                        try:\n",
    "                            details = nest(path, self.pred)\n",
    "                        except:\n",
    "                            new = True\n",
    "                            nest(path[:-1], self.pred, dict())\n",
    "                            details = self.predict(crse, styp_code, copy.deepcopy(params), train_term)\n",
    "                            nest(path, self.pred, details)\n",
    "                        path[-1] = 'summary'\n",
    "                        try:\n",
    "                            summary = nest(path, self.pred)\n",
    "                        except:\n",
    "                            summary = self.aggregate(details)\n",
    "                            nest(path, self.pred, summary)\n",
    "                            self.dump()\n",
    "                    Y = nest(path[:-2], self.pred)\n",
    "                    for key in ['details', 'summary']:\n",
    "                        Y[key] = pd.concat([y[key] for y in Y.values() if isinstance(y, dict) and key in y.keys()]).sort_index()\n",
    "                    Y['rslt'] = self.analyze(Y['summary'])\n",
    "                    if new:\n",
    "                        # self.dump()\n",
    "                        k += 1\n",
    "                    else:\n",
    "                        L -= 1\n",
    "                    # Y['rslt']['error_pct'].query(\"error_pct == ' 50%'\").round(decimals=2).disp(100)\n",
    "                    E = Y['summary'].query(f\"term_code!=train_term & term_code!={self.infer_term}\")[\"error_pct\"].abs()\n",
    "                    # E.describe().to_frame().T.round(decimals=2).disp(200)\n",
    "                    new = Y | {'params_idx':params_idx, 'params':params, 'score':E.median()}\n",
    "                    print(f\"new score = {new['score']:.2f}\")\n",
    "                    if pd.notnull(new['score']) and new['score'] < 30:\n",
    "                        try:\n",
    "                            old = nest(path[:-3], self.optimal)\n",
    "                            print(f\"old score = {old['score']:.2f}\")\n",
    "                            if new['score'] < old['score']:\n",
    "                                print('replacing')\n",
    "                                nest(path[:-3], self.optimal, new)\n",
    "                            else:\n",
    "                                print('keeping')\n",
    "                        except:\n",
    "                            nest(path[:-3], self.optimal, new)\n",
    "                    elapsed = (time.perf_counter() - start_time) / 60\n",
    "                    complete = k / L if L > 0 else 1\n",
    "                    rate = elapsed / k if k > 0 else 0\n",
    "                    remaining = rate * (L - k)\n",
    "                    print(f\"{k} / {L} = {complete*100:.2f}% complete, elapsed = {elapsed:.2f} min, remaining = {remaining:.2f} min @ {rate:.2f} min per model\")\n",
    "            self.dump()\n",
    "        self.push()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary'].vc('crse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, plotly.express as px\n",
    "df = pd.read_csv('amp_summary.csv')\n",
    "df['train_term'] = df['train_term'].astype('string')\n",
    "X = df.query(\"crse=='_total' & styp_code=='new first time' & term_code==202308\").copy()\n",
    "px.violin(X,\n",
    "       y = 'error',\n",
    "       x = 'train_term',\n",
    "       box=True,)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1516/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary'].query(\"crse=='_total' & term_code==202408\")['predict'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        target_url = 'https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M'\n",
    "        with open(self.summary, 'rb') as target_file:\n",
    "            response = requests.post(target_url, files = {\"amp_summary.csv\": target_file})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary'].groupby(['crse','levl_code','styp_code','term_code','train_term','sim']).size().disp(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary']#.query(\"styp_code=='all'\")['predict'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['_total']['n']['summary'].disp(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    A = pd.concat([S[key] for crse, C in self.optimal.items() for styp_code, S in C.items() if isinstance(S, dict) and key in S.keys()])\n",
    "    # if key == 'summary':\n",
    "    #     B = A.copy().reset_index().assign(styp_code=A.reset_index()['styp_code'].replace({'n':'new first time','t':'transfer','r':'returning'}))\n",
    "    #     C = B.assign(styp_code='all').groupby(A.index.names)[['predict','actual','error']].sum().reset_index()\n",
    "    #     C['error_pct'] = C['error'] / C['actual'] * 100\n",
    "\n",
    "idx = A.index.names\n",
    "A = A.reset_index()\n",
    "A['styp_code'] = A['styp_code'].replace({'n':'new first time','t':'transfer','r':'returning'})\n",
    "B = A.copy()\n",
    "# B['styp_code'] = 'all'\n",
    "# B = B.groupby(['crse', 'levl_code','term_code', 'train_term', 'sim'])[['predict','actual','error']].sum()#.reset_index()\n",
    "# B.disp(200)\n",
    "# idx\n",
    "A.query(\"term_code==202408\").disp(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse= [\n",
    "        'engl1301',\n",
    "        'biol1406',\n",
    "        'math1314',\n",
    "        'biol2401',\n",
    "        'math2412',\n",
    "        'agri1419',\n",
    "        'psyc2301',\n",
    "        'ansc1319',\n",
    "        'comm1311',\n",
    "        'hist1301',\n",
    "        'govt2306',\n",
    "        'math1324',\n",
    "        # 'chem1411',\n",
    "        'univ0301',\n",
    "        'univ0204',\n",
    "        'univ0304',\n",
    "        'agri1100',\n",
    "        'comm1315',\n",
    "        'agec2317',\n",
    "        'govt2305',\n",
    "        'busi1301',\n",
    "        'arts1301',\n",
    "        'math1342',\n",
    "        'math2413',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(crse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "x = 3.14159265\n",
    "x = np.nan\n",
    "x = pd.NA\n",
    "print(f'pi = {x:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = {1,2}\n",
    "w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted({'_total', *listify(self.crse)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crse, C in mysort(self.optimal).items():\n",
    "    for styp, S in mysort(C).items():\n",
    "        print(crse, styp, S['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['biol1406']['n'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crse, C in self.pred.items():\n",
    "    for styp, S in C.items():\n",
    "        for params, P in S.items():\n",
    "            details = P['details']\n",
    "            agg = lambda x: pd.Series({\n",
    "                'pred': x['pred'].sum(min_count=1),\n",
    "                'true': x['true'].sum(min_count=1),\n",
    "                'mse_pct': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "                'f1_inv_pct': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "            })\n",
    "            summary = details.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "            for x in ['pred','true']:\n",
    "                summary[x] = summary[x] * summary['mlt']\n",
    "            summary.insert(2, 'err', summary['pred'] - summary['true'])\n",
    "            summary.insert(3, 'err_pct', summary['err'] / summary['true'] * 100)\n",
    "            # try:\n",
    "            E = summary.query(f\"pred_term!={self.infer_term} & pred_term!=train_term\")['err_pct'].abs().median()\n",
    "            print(crse, styp, E)\n",
    "            # print(crse, styp, round(E,2))\n",
    "            # except:\n",
    "                # summary.query(f\"pred_term!={self.infer_term} & pred_term!=train_term\").disp(50)\n",
    "            \n",
    "    #         break\n",
    "    #     break\n",
    "    # break\n",
    "            # print(crse, styp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P['details'].sum()\n",
    "self.__dict__.keys()\n",
    "self.reg_df['cur'].query(\"styp_code=='r' & crse=='engl1301'\").groupby('term_code')['credit_hr'].sum()\n",
    "# self.mlt\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['__distance'].astype('Float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred['_total']['n'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup import *\n",
    "X = pd.read_parquet('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/flags/sheet/202406/flg_202406_2023-08-07.parq')\n",
    "X.prep()\n",
    "# I = X[[]].reset_index().prep_string()\n",
    "# I\n",
    "# pd.api.types.is_string_dtype(I)\n",
    "# pd.MultiIndex.from_frame(I)\n",
    "\n",
    "# pd.MultiIndex.from_frame(X[[]].reset_index().prep_number().prep_string())\n",
    "# df.prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = df['hs_gpa']#.astype('string')\n",
    "pd.api.types.is_string_dtype(ser)\n",
    "pd.api.types.is_object_dtype(ser)\n",
    "ser.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd_ext\n",
    "def prep_number(ser, dtype_backend='numpy_nullable'):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    if pd.api.types.is_string_dtype(ser) or pd.api.types.is_object_dtype(ser):\n",
    "        ser = ser.astype('string')\n",
    "        try:\n",
    "            ser = pd.to_datetime(ser)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                ser = pd.to_numeric(ser, downcast='integer')\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return ser.astype('Int64') if pd.api.types.is_integer_dtype(ser) else ser.convert_dtypes(dtype_backend)\n",
    "\n",
    "@pd_ext\n",
    "def prep_string(ser, cap=\"casefold\"):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    ser = ser.prep_number()\n",
    "    return getattr(ser.str, cap)().replace('',pd.NA) if pd.api.types.is_string_dtype(ser) else ser\n",
    "\n",
    "@pd_ext\n",
    "def prep_category(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    ser = ser.prep_string()\n",
    "    return ser.astype('category') if pd.api.types.is_string_dtype(ser) else ser\n",
    "\n",
    "@pd_ext\n",
    "def prep_bool(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    ser = ser.prep_string()\n",
    "    vals = ser.dropna().unique()\n",
    "    if len(vals) in [1, 2]:\n",
    "        vals = set(vals)\n",
    "        for s in [['false','true'], ['n','y'], [0, 1]]:\n",
    "            if vals.issubset(s):\n",
    "                ser = (ser == s[1]).astype('boolean').fillna(False)\n",
    "    return ser\n",
    "\n",
    "@pd_ext\n",
    "def prep(X, cap='casefold'):\n",
    "    if isinstance(X, str):\n",
    "        if cap:\n",
    "            X = getattr(X, cap)()\n",
    "        return X.strip()\n",
    "    elif isinstance(X, (list, tuple, set, np.ndarray, pd.Index)):\n",
    "        return type(X)((prep(x, cap) for x in X))\n",
    "    elif isinstance(X, dict):\n",
    "        return {prep(k,cap):prep(v,cap) for k,v in X.items()}\n",
    "    elif isinstance(X, pd.DataFrame):\n",
    "        g = lambda x: prep(x, cap).replace(' ','_').replace('-','_') if isinstance(x, str) else x\n",
    "        X = X.rename(columns=g).rename_axis(index=g)\n",
    "        idx = pd.MultiIndex.from_frame(X[[]].reset_index().prep_number().prep_string())\n",
    "        return X.prep_number().prep_string().set_index(idx).rename_axis(X.index.names)\n",
    "    elif isinstance(X, pd.Series):\n",
    "        assert 1==2\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "X = df.prep()\n",
    "\n",
    "# write(dst, pd.concat(L).prep())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd_ext\n",
    "def disp(df, max_rows=4, max_cols=200, **kwargs):\n",
    "    display(HTML(df.to_html(max_rows=max_rows, max_cols=max_cols, **kwargs)))\n",
    "\n",
    "\n",
    "X.convert_dtypes().dtypes.disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    write(self[key], self.optimal[key], index=False)\n",
    "# target_url = 'https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M'\n",
    "# with open(self.summary, 'rb') as target_file:\n",
    "#     response = requests.post(target_url, files = {\"amp_summary.csv\": target_file})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    A = pd.concat([S[key] for crse, C in self.optimal.items() for styp_code, S in C.items() if isinstance(S, dict) and key in S.keys()])\n",
    "    if key == 'summary':\n",
    "        B = A.copy().reset_index().assign(styp_code=A.reset_index()['styp_code'].replace({'n':'new first time','t':'transfer','r':'returning'}))\n",
    "        C = B.assign(styp_code='all').groupby(A.index.names)[['pred','true','err']].sum().reset_index()\n",
    "        C['err_pct'] = C['err'] / C['true'] * 100\n",
    "        A = pd.concat([B,C])\n",
    "    self.optimal[key] = A\n",
    "    write(self[key], self.optimal[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    A = pd.concat([S[key] for crse, C in self.optimal.items() for styp_code, S in C.items() if isinstance(S, dict) and key in S.keys()])\n",
    "    if key == 'summary':\n",
    "        B = A.copy().reset_index().assign(styp_code=A.reset_index()['styp_code'].replace({'n':'new first time','t':'transfer','r':'returning'}))\n",
    "        C = B.assign(styp_code='all').groupby(A.index.names)[['pred','true','err']].sum().reset_index()\n",
    "        C['err_pct'] = C['err'] / C['true'] * 100\n",
    "        A = pd.concat([B,C])\n",
    "    self.optimal[key] = A\n",
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['details', 'summary']:\n",
    "    A = pd.concat([S[key] for crse, C in self.optimal.items() for styp_code, S in C.items() if isinstance(S, dict) and key in S.keys()])\n",
    "    if key == 'summary':\n",
    "        B = A.copy().reset_index().assign(styp_code=A.reset_index()['styp_code'].replace({'n':'new first time','t':'transfer','r':'returning'}))\n",
    "        C = B.assign(styp_code='all').groupby(A.index.names)[['pred','true','err']].sum()\n",
    "        C['err_pct'] = C['err'] / C['true'] * 100\n",
    "        A = pd.concat([B.set_index(A.index.names),C])\n",
    "    self.optimal[key] = A\n",
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = self.optimal['summary'][[]].droplevel('styp_code').reset_index()\n",
    "A.drop_duplicates().shape\n",
    "108/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = self.optimal['summary'].index.names\n",
    "A = self.optimal['summary'].reset_index()\n",
    "A['styp_code'] = A['styp_code'].replace({'n':'FTIC','t':'Transfer','r':'Returning'})\n",
    "B = A.copy().assign(styp_code='all').groupby(idx)[['pred','true','err']].sum().reset_index()\n",
    "B['err_pct'] = B['err'] / B['true'] * 100\n",
    "C = pd.concat([A,B])\n",
    "\n",
    "# C.vc('styp_code')\n",
    "# C\n",
    "# B\n",
    "# idx = [n for n in df.index.names if n != 'styp_code']\n",
    "# B = (\n",
    "#     A.groupby(idx)[['pred','true','err']].sum()\n",
    "#     .assign(styp_code='all', err_pct=lambda x:x['err']/x['true']*100)\n",
    "#     .reset_index().set_index(df.index.names)\n",
    "# )\n",
    "# B\n",
    "\n",
    "# n.\n",
    "# list(n)\n",
    "# remove('styp_code')\n",
    "# A = df.droplevel('styp_code')\n",
    "# A = A.groupby(A.index.names).sum()\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.vc('styp_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = self.optimal['summary']\n",
    "B = (\n",
    "    A.copy().reset_index()\n",
    "    .assign(styp_code='all')\n",
    "    .groupby(A.index.names)\n",
    "    [['pred','true','err']].sum()\n",
    ")\n",
    "B['err_pct'] = B['err'] / B['true'] * 100\n",
    "pd.concat([A,B]).reset_index()\n",
    "B\n",
    "# idx = [n for n in df.index.names if n != 'styp_code']\n",
    "# B = (\n",
    "#     A.groupby(idx)[['pred','true','err']].sum()\n",
    "#     .assign(styp_code='all', err_pct=lambda x:x['err']/x['true']*100)\n",
    "#     .reset_index().set_index(df.index.names)\n",
    "# )\n",
    "# B\n",
    "\n",
    "# n.\n",
    "# list(n)\n",
    "# remove('styp_code')\n",
    "# A = df.droplevel('styp_code')\n",
    "# A = A.groupby(A.index.names).sum()\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "target_url = 'https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M'\n",
    "with open(self.summary, 'rb') as target_file:\n",
    "    response = requests.post(target_url, files = {\"amp_summary.csv\": target_file})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([b['summary'] for a in self.optimal.values() for b in a.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimal['engl1301']['n']['summary']#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = nest(path, self.pred)\n",
    "Y.keys()\n",
    "for k in ['details', 'summary']:\n",
    "    Y[k] = pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(self.pred.values())[0]['n'].values())[0][202108]['summary']#.keys()#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]).prep() for k in ['cur','end']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(202208, self.term_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "d.setdefault('a', dict()).setdefault('b',4)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal = dict()\n",
    "stat = 'err_pct'\n",
    "for params, v in self.pred.items():\n",
    "    A = v['summary'].query(\"pred_term in @self.term_codes & train_term in @self.term_codes & pred_term!=train_term\")[stat]\n",
    "    B = A.abs().groupby(['crse','styp_code']).median()\n",
    "    for key, val in B.items():\n",
    "        new = {'params':params, stat:val}\n",
    "        optimal.setdefault(key, new)\n",
    "        if val < optimal[key][stat]:\n",
    "            optimal[key] = new\n",
    "for key, val in optimal.items():\n",
    "    print(key[0])\n",
    "    self.pred[val['params']][key[0]][key[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in C[0].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C[0].ge(C[1])\n",
    "# np.minimum(*C[:2])\n",
    "C[0].to_dict('list')\n",
    "\n",
    "# (orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v['rslt']['err_pct']..disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "import miceforest as mf\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer, KBinsDiscretizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, iteration=None, normalize=True):\n",
    "    targ = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    feat = [self._get_var_name_from_scalar(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=targ, columns=feat).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "mf.ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "def inspect(self, **kwargs):\n",
    "    self.plot_imputed_distributions(wspace=0.3,hspace=0.3)\n",
    "    plt.show()\n",
    "    self.plot_mean_convergence(wspace=0.3, hspace=0.4)\n",
    "    plt.show()\n",
    "    I = self.feature_importance_df(**kwargs)\n",
    "    I.disp(100)\n",
    "    return I\n",
    "mf.ImputationKernel.inspect = inspect\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer_term: int\n",
    "    crse: typing.List\n",
    "    attr: typing.List\n",
    "    fill: typing.Dict = None\n",
    "    trf_grid: typing.Dict = None\n",
    "    imp_grid: typing.Dict = None\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "    inspect: bool = False\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.rslt = root_path / f\"resources/rslt/{rjust(self.cycle_day,3,0)}/rslt2.pkl\"\n",
    "        D = {'trm':False, 'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'raw_df':False, 'reg_df':False, 'X':False, 'Y':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.overwrite['raw_df'] |= self.overwrite['term']\n",
    "        self.overwrite['reg_df'] |= self.overwrite['term']\n",
    "        self.overwrite['X'] |= self.overwrite['raw_df']\n",
    "        self.overwrite['Y'] |= self.overwrite['reg_df'] | self.overwrite['X']\n",
    "        self.overwrite['pred'] |= self.overwrite['Y']\n",
    "\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        print(self.__dict__.keys())\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['fill','term','pred','trf_grid','imp_grid']:\n",
    "            if k not in self:\n",
    "                self[k] = dict()\n",
    "\n",
    "        self.term_codes = uniquify([*listify(self.term_codes), self.infer_term])\n",
    "        self.crse = uniquify(['_total', *listify(self.crse)])\n",
    "        self.mlt_grp = ['crse','levl_code','styp_code','term_code']\n",
    "        self.trf_list = cartesian({k: sorted(setify(v), key=str) for k,v in self.trf_grid.items()})\n",
    "        self.trf_list = [mysort({k:v for k,v in t.items() if v not in ['drop',None,'']}) for t in self.trf_list]\n",
    "        imp_default = {'iterations':3, 'mmc':0, 'mmf':'mean_match_default', 'datasets':5, 'tune':True}\n",
    "        self.imp_list = cartesian(self.imp_grid)\n",
    "        self.imp_list = [mysort(imp_default | v) for v in self.imp_list]\n",
    "        self.params_list = sorted([mysort({'imp':imp, 'trf':trf}) for trf, imp in it.product(self.trf_list,self.imp_list)], key=str)\n",
    "        return self\n",
    "\n",
    "    def get_terms(self):\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "\n",
    "\n",
    "    def preprocess(self):\n",
    "        def get(nm):\n",
    "            if nm in self:\n",
    "                return False\n",
    "            print(f'get {nm}')\n",
    "            return True\n",
    "\n",
    "        if get('raw_df') or get('reg_df'):\n",
    "            self.get_terms()\n",
    "\n",
    "        if get('raw_df'):\n",
    "            with warnings.catch_warnings(action='ignore'):\n",
    "                self.raw_df = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "\n",
    "        if get('reg_df'):\n",
    "            with warnings.catch_warnings(action='ignore'):\n",
    "                self.reg_df = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\") for term in self.term.values()]).prep() for k in ['cur','end']}\n",
    "\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        if get('X'):\n",
    "            R = self.raw_df.copy()\n",
    "            repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "            R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "            R['remote'] = R['camp_code'] != 's'\n",
    "            R['resd'] = R['resd_code'] == 'r'\n",
    "            R['lgcy'] = ~R['lgcy_code'].isin(['n','o'])\n",
    "            R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "            R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm', '00':pd.NA})\n",
    "            R['coll_desc'] = R['coll_desc'].replace({\n",
    "                'ag & environmental_sciences':'ag & natural_resources',\n",
    "                'education & human development':'education',\n",
    "                'health science & human_service':'health sciences',\n",
    "                'science & technology':'science & mathematics'})\n",
    "            majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "            S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "            X = where(R.drop(columns=majr).merge(S, on='majr_code', how='left')).prep().prep_bool()\n",
    "\n",
    "            checks = [\n",
    "                'cycle_day >= 0',\n",
    "                'apdc_day >= cycle_day',\n",
    "                'appl_day >= apdc_day',\n",
    "                'birth_day >= appl_day',\n",
    "                'birth_day >= 5000',\n",
    "                'distance >= 0',\n",
    "                'hs_pctl >=0',\n",
    "                'hs_pctl <= 100',\n",
    "                'hs_qrtl >= 0',\n",
    "                'hs_qrtl <= 4',\n",
    "                'act_equiv >= 1',\n",
    "                'act_equiv <= 36',\n",
    "                'gap_score >= 0',\n",
    "                'gap_score <= 100',\n",
    "            ]\n",
    "            for check in checks:\n",
    "                mask = X.eval(check)\n",
    "                assert mask.all(), [check,X[~mask].disp(5)]\n",
    "            \n",
    "            for k, v in self.fill.items():\n",
    "                X[k] = X.impute(k, *listify(v))\n",
    "            self.X = X.prep().prep_bool().set_index(self.attr, drop=False).rename(columns=lambda x:'__'+x)\n",
    "            self.X.missing().disp(100)\n",
    "\n",
    "        if get('Y'):\n",
    "            Y = {k: self.X[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr']) for k, y in self.reg_df.items()}\n",
    "            agg = lambda y: where(y).groupby(self.mlt_grp)['credit_hr'].agg(lambda x: (x>0).sum())\n",
    "            A = agg(self.reg_df['end'])\n",
    "            B = agg(Y['end'])\n",
    "            M = (A / B).replace(np.inf, pd.NA).rename('mlt').reset_index().query(f\"term_code != {self.infer_term}\").prep()\n",
    "            N = M.assign(term_code=self.infer_term)\n",
    "            self.mlt = pd.concat([M, N], axis=0).set_index(self.mlt_grp)\n",
    "            Y = {k: y.squeeze().unstack().dropna(how='all', axis=1).fillna(0) for k, y in Y.items()}\n",
    "            self.Y = Y['cur'].rename(columns=lambda x:x+'_cur').join(Y['end']>0).prep()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, params, crse, train_term, styp_code='all'):\n",
    "        # for p, P in self.pred.items():\n",
    "        #     if p == str(params):\n",
    "        #         for c, C in P.items():\n",
    "        #             if c == crse:\n",
    "        #                 for t, T in C.items():\n",
    "        #                     if t == train_term:\n",
    "        #                         for s, S in T.items():\n",
    "        #                             if s == styp_code:\n",
    "        #                                 # print(ljust(crse,8), train_term, styp_code, 'reusing')\n",
    "        #                                 return S, False\n",
    "\n",
    "        print(ljust(crse,8), train_term, styp_code, 'creating')\n",
    "        X = self.X.copy()\n",
    "        if styp_code != 'all':\n",
    "            X = X.query(f\"styp_code==@styp_code\")\n",
    "        trf = ColumnTransformer([(c,t,[\"__\"+c]) for c,t in params['trf'].items()], remainder='drop', verbose_feature_names_out=False)\n",
    "        cols = uniquify(['_total_cur',crse+'_cur',crse])\n",
    "        Z = trf.fit_transform(X).join(self.Y[cols]).prep().prep_bool().prep_category().sort_index()\n",
    "        y = Z[crse].copy().rename('true').to_frame()\n",
    "        Z.loc[Z.eval(\"term_code!=@train_term\"), crse] = pd.NA\n",
    "\n",
    "        iterations = params['imp'].pop('iterations')\n",
    "        datasets = params['imp'].pop('datasets')\n",
    "        tune = params['imp'].pop('tune')\n",
    "        mmc = params['imp'].pop('mmc')\n",
    "        mmf = params['imp'].pop('mmf')\n",
    "        if mmc > 0 and mmf is not None:\n",
    "            params['imp']['mean_match_scheme'] = getattr(mf, mmf).copy()\n",
    "            params['imp']['mean_match_scheme'].set_mean_match_candidates(mmc)\n",
    "        \n",
    "        if tune:\n",
    "            # print('tuning')\n",
    "            imp = mf.ImputationKernel(Z, datasets=1, **params['imp'])\n",
    "            imp.mice(iterations=1)\n",
    "            optimal_parameters, losses = imp.tune_parameters(dataset=0, optimization_steps=5)\n",
    "        else:\n",
    "            # print('not tuning')\n",
    "            optimal_parameters = None\n",
    "        imp = mf.ImputationKernel(Z, datasets=datasets, **params['imp'])\n",
    "        imp.mice(iterations=iterations, variable_parameters=optimal_parameters)\n",
    "        if self.inspect:\n",
    "            imp.inspect()\n",
    "\n",
    "        Z.loc[:, crse] = pd.NA\n",
    "        P = imp.impute_new_data(Z)\n",
    "        details = pd.concat([y\n",
    "                .assign(pred=P.complete_data(k)[crse], train_term=train_term, crse=crse, sim=k)\n",
    "                .set_index(['train_term','crse','sim'], append=True)\n",
    "            for k in range(P.dataset_count())]).prep_bool()\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse_pct': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv_pct': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        summary = details.groupby([*self.mlt_grp,'train_term','sim']).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            summary[x] = summary[x] * summary['mlt']\n",
    "        summary.insert(2, 'err', summary['pred'] - summary['true'])\n",
    "        summary.insert(3, 'err_pct', (summary['err'] / summary['true']).clip(-1, 1) * 100)\n",
    "        S = {'details':details, 'summary':summary.drop(columns='mlt').prep()}#, 'trf':trf, 'imp':imp}\n",
    "        # S['summary'].disp(5)\n",
    "        return S\n",
    "        # return S, True\n",
    "\n",
    "\n",
    "    def analyze(self, df):\n",
    "        def pivot(df, val):\n",
    "            Y = (\n",
    "                df\n",
    "                .reset_index()\n",
    "                .pivot_table(columns='train_term', index=['crse','styp_code','pred_term'], values=val, aggfunc=['count',pctl(0),pctl(25),pctl(50),pctl(75),pctl(100)])\n",
    "                .rename_axis(columns=[val,'train_term'])\n",
    "                .stack(0, future_stack=True)\n",
    "                .assign(abs_mean = lambda x: x.abs().mean(axis=1))\n",
    "            )\n",
    "            return Y\n",
    "        mask = df.eval(f\"pred_term!={self.infer_term}\")\n",
    "        return {stat: pivot(df[mask], stat) for stat in [\"pred\",\"err\",\"err_pct\",\"mse_pct\",\"f1_inv_pct\"]} | {\"proj\": pivot(df[~mask], \"pred\")}\n",
    "\n",
    "    def main(self, styp_codes=('n','t','r')):\n",
    "        self = self.preprocess()\n",
    "        g = lambda Y: {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "        start_time = time.perf_counter()\n",
    "        L = len(self.params_list)\n",
    "        k = 0\n",
    "        for params in self.params_list:\n",
    "            new = False\n",
    "            Y = []\n",
    "            for crse in self.crse:\n",
    "                for train_term in self.term_codes:\n",
    "                    for styp_code in listify(styp_codes):\n",
    "                        path = [str(params),crse,train_term,styp_code]\n",
    "                        try:\n",
    "                            y = nest(path, self.pred)\n",
    "                        except:\n",
    "                            if not new:\n",
    "                                print(str(params))\n",
    "                            y = self.predict(copy.deepcopy(params), crse, train_term, styp_code)\n",
    "                            nest(path, self.pred, y)\n",
    "                            new = True\n",
    "                        Y.append(y)\n",
    "            P = self.pred[str(params)]\n",
    "            if new:\n",
    "                for key in ['details', 'summary']:\n",
    "                    P[key] = pd.concat([y[key] for y in Y])\n",
    "                P['rslt'] = self.analyze(P['summary'])\n",
    "                self.dump()\n",
    "                k += 1\n",
    "            else:\n",
    "                L -= 1\n",
    "            P['rslt']['err_pct'].query(\"err_pct == ' 50%'\").disp(100)\n",
    "            P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "            elapsed = (time.perf_counter() - start_time) / 60\n",
    "            complete = k / L if L > 0 else 1\n",
    "            rate = elapsed / k if k > 0 else 0\n",
    "            remaining = rate * (L - k)\n",
    "            print(f\"{k} / {L} = {round(complete*100,1)}% complete, elapsed = {round(elapsed,1)} min, remaining = {round(remaining,1)} min @ {round(rate,1)} min per model\")\n",
    "            print(\"\\n========================================================================================================\\n\")\n",
    "        # return self\n",
    "    \n",
    "\n",
    "    # def main(self, styp_codes=('n','t','r')):\n",
    "    #     self = self.preprocess()\n",
    "    #     g = lambda Y: {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "    #     start_time = time.perf_counter()\n",
    "    #     L = len(self.params_list)\n",
    "    #     k = 0\n",
    "    #     for params in self.params_list:\n",
    "    #         # print(str(params))\n",
    "    #         try:\n",
    "    #             P = self.pred[str(params)]\n",
    "    #             S = P['summary']\n",
    "    #             L -= 1\n",
    "    #         except:\n",
    "    #             print(str(params))\n",
    "    #             P = dict()\n",
    "    #             for crse in self.crse:\n",
    "    #                 for train_term in self.term_codes:\n",
    "    #                     for styp_code in listify(styp_codes):\n",
    "    #                         S = self.predict(copy.deepcopy(params), crse, train_term, styp_code)\n",
    "    #                         path = [crse,train_term,styp_code]\n",
    "    #                         nest(path, P, S)\n",
    "    #                     path.pop(-1)\n",
    "    #                     nest(path, P, g(nest(path, P)))\n",
    "    #                 path.pop(-1)\n",
    "    #                 nest(path, P, g(nest(path, P)))\n",
    "    #             P = g(P)\n",
    "    #             S = P['summary']\n",
    "    #             k += 1\n",
    "    #         if 'rslt' not in P:\n",
    "    #             P['rslt'] = self.analyze(S)\n",
    "    #             self.pred[str(params)] = P\n",
    "    #             self.dump()\n",
    "    #         S.query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "    #         elapsed = (time.perf_counter() - start_time) / 60\n",
    "    #         complete = k / L if L > 0 else 1\n",
    "    #         rate = elapsed / k if k > 0 else 0\n",
    "    #         remaining = rate * (L - k)\n",
    "    #         print(f\"{k} / {L} = {round(complete*100,1)}% complete, elapsed = {round(elapsed,1)} min, remaining = {round(remaining,1)} min @ {round(rate,1)} min per model\")\n",
    "    #         print(\"\\n========================================================================================================\\n\")\n",
    "    #     return self\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "passthru = ['passthrough']\n",
    "passdrop = ['passthrough', 'drop']\n",
    "# passthru = passdrop\n",
    "bintrf = lambda n_bins: KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform', subsample=None)\n",
    "pwrtrf = make_pipeline(StandardScaler(), PowerTransformer())\n",
    "kwargs = {\n",
    "    # 'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'term_codes': np.arange(2021,2025)*100+8,\n",
    "    'infer_term': 202408,\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    'fill': {\n",
    "        'birth_day': ['median',['term_code','styp_code']],\n",
    "        'remote': False,\n",
    "        'international': False,\n",
    "        **{f'race_{r}': False for r in ['american_indian','asian','black','pacific','white','hispanic']},\n",
    "        'lgcy': False,\n",
    "        'resd': False,\n",
    "        'waiver': False,\n",
    "        'fafsa_app': False,\n",
    "        'schlship_app': False,\n",
    "        'finaid_accepted': False,\n",
    "        'ssb': False,\n",
    "        'math': False,\n",
    "        'reading': False,\n",
    "        'writing': False,\n",
    "        'gap_score': 0,\n",
    "        'oriented': 'n',\n",
    "    },\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        *code_desc('resd'),\n",
    "        *code_desc('lgcy'),\n",
    "        'international',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_qrtl',\n",
    "    ],\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    'cycle_day': 184,\n",
    "    'crse': [\n",
    "        'engl1301',\n",
    "        'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'trf_grid': {\n",
    "        'appl_day': passdrop,\n",
    "        'apdc_day': passdrop,\n",
    "        'birth_day': [*passthru, pwrtrf],#, ],\n",
    "        # 'levl_code': passthru,\n",
    "        # 'styp_code': passthru,\n",
    "        # 'admt_code': passdrop,\n",
    "        # 'camp_code': passdrop,\n",
    "        'remote': passthru,\n",
    "        'coll_code': passdrop,\n",
    "        'international': passthru,\n",
    "        **{f'race_{r}': passthru for r in ['american_indian','asian','black','pacific','white','hispanic']},\n",
    "        'gender': passthru,\n",
    "        'lgcy': passdrop,\n",
    "        'resd': passthru,\n",
    "        'waiver': passdrop,\n",
    "        # 'fafsa_app': passthru,\n",
    "        'schlship_app': passthru,\n",
    "        # 'finaid_accepted': passthru,\n",
    "        'ssb': passthru,\n",
    "        'math': passthru,\n",
    "        'reading': passthru,\n",
    "        'writing': passthru,\n",
    "        'gap_score': passthru,\n",
    "        'oriented': passthru,\n",
    "        'hs_qrtl': passthru,\n",
    "        'act_equiv': passthru,\n",
    "        'distance': [*passthru, pwrtrf],#, bintrf(5)],\n",
    "        },\n",
    "    'imp_grid': {\n",
    "        'mmc': 10,\n",
    "        # 'datasets': 25,\n",
    "        'datasets': 1,\n",
    "        'iterations': 1,\n",
    "        'tune': False,\n",
    "    },\n",
    "    'overwrite': {\n",
    "        # # 'trm':True,\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'raw_df': True,\n",
    "        'reg_df': True,\n",
    "        # 'X': True,\n",
    "        # 'Y': True,\n",
    "        # 'pred': True,\n",
    "    },\n",
    "    # 'inspect': True,\n",
    "}\n",
    "\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "self = self.preprocess()\n",
    "# self.term_codes.remove(self.infer_term)\n",
    "self.params_list = self.params_list[1:2]\n",
    "self.main(styp_codes='n')\n",
    "# len(self.params_list)\n",
    "# for x in self.params_list:\n",
    "#     print(x)\n",
    "# T = TERM(202008, cycle_day=184, show={'adm':True}).get_adm(184)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['A'] = [1,2,3]\n",
    "df['B'] = ['a','b','c']\n",
    "fn = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/admitted_matriculation_predictor/test.csv'\n",
    "df.to_csv(fn)\n",
    "with open(fn, 'rb') as f:\n",
    "    r = requests.post('https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M', files={'test.csv': f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# define the relative path of the sample file\n",
    "file_path = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/admitted_matriculation_predictor/test.csv'\n",
    "target_url = 'https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M'\n",
    "with open(file_path, \"rb\") as target_file:\n",
    "    response = requests.post(target_url, files = {\"form_field_name\": target_file})\n",
    "if response.ok:\n",
    "    print(\"Upload complete\")\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl'\n",
    "fn = pathlib.Path(fn)\n",
    "with open(fn, 'rb') as f:\n",
    "    # return joblib.load(f, **kwargs)\n",
    "    s = pickle.load(f)\n",
    "\n",
    "# s = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl')\n",
    "# s.X\n",
    "# self.term_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.pred.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M\n",
    "with open('report.xls', 'rb') as f:\n",
    "    r = requests.post('http://httpbin.org/post', files={'report.xls': f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl', 'rb') as f:\n",
    "    A = pickle.load(f)\n",
    "list(A.pred.values())[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('report.xls', 'rb') as f:\n",
    "    r = requests.post('https://prod-121.westus.logic.azure.com:443/workflows/784fef9d36024a6abf605d1376865784/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=1Yrr4tE1SwYZ88SU9_ixG-WEdN1GFicqJwH_KiCZ70M', files={'report.xls': f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl'\n",
    "fn = pathlib.Path(fn)\n",
    "fn.unlink(missing_ok=True)\n",
    "with open(fn, 'wb') as f:\n",
    "    joblib.dump(self, f)\n",
    "with open(fn, 'rb') as f:\n",
    "    Q = joblib.load(f)\n",
    "print(Q.pred)\n",
    "Q.pred['hi'] = 3\n",
    "with open(fn, 'wb') as f:\n",
    "    joblib.dump(Q, f)\n",
    "with open(fn, 'rb') as f:\n",
    "    R = joblib.load(f)\n",
    "print(Q.pred)\n",
    "\n",
    "# self.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl'\n",
    "# f2 = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt2.pkl'\n",
    "A = read(f)\n",
    "print(A.pred)\n",
    "A.pred['hi'] = 3\n",
    "# print(A.pred)\n",
    "# write(f, A, overwrite=True)\n",
    "# B = read(f)\n",
    "# print(B.pred)\n",
    "# A.pred\n",
    "# len(self.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, pickle, joblib\n",
    "def write(fn, obj, overwrite=False, **kwargs):\n",
    "    fn = pathlib.Path(fn)\n",
    "    suf = ['.parq','.parquet','.pkl','.csv']\n",
    "    assert fn.suffix in suf, f'Unknown suffix {fn.suffix} - must be one of {suf}'\n",
    "    if overwrite:\n",
    "        fn.unlink(missing_ok=True)\n",
    "    if not fn.is_file():\n",
    "        mkdir(fn.parent)\n",
    "        if fn.suffix == '.pkl':\n",
    "            with open(fn, 'wb') as f:\n",
    "                joblib.dump(obj, f, **kwargs)\n",
    "                # pickle.dump(obj, f, **kwargs)\n",
    "        else:\n",
    "            obj = pd.DataFrame(obj).prep()\n",
    "            if fn.suffix in ['.parq','.parquet']:\n",
    "                obj.to_parquet(fn, **kwargs)\n",
    "            elif fn.suffix == '.csv':\n",
    "                obj.to_csv(fn, **kwargs)\n",
    "    return obj\n",
    "\n",
    "def read(fn, overwrite=False, **kwargs):\n",
    "    fn = pathlib.Path(fn)\n",
    "    suf = ['.parq','.parquet','.pkl','.csv']\n",
    "    assert fn.suffix in suf, f'Unknown suffix {fn.suffix} - must be one of {suf}'\n",
    "    if overwrite:\n",
    "        fn.unlink(missing_ok=True)\n",
    "    try:\n",
    "        with open(fn, 'rb') as f:\n",
    "            return joblib.load(f, **kwargs)\n",
    "            # return pickle.load(f, **kwargs)\n",
    "    except:\n",
    "        try:\n",
    "            return pd.read_parquet(fn, **kwargs).prep()\n",
    "        except:\n",
    "            try:\n",
    "                return pd.read_csv(fn, **kwargs).prep()\n",
    "            except:\n",
    "                return None\n",
    "            \n",
    "f = '/home/scook/institutional_data_analytics/admitted_matriculation_projection/resources/rslt/183/rslt.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = list(self.pred.values())[0]\n",
    "P['rslt']['err_pct'].query(\"err_pct==' 50%'\")#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, p in enumerate(self.params_list):\n",
    "    if str(p) == q:\n",
    "        j = k\n",
    "        print(j)\n",
    "str(self.params_list[j]) == q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params, P in self.pred.items():\n",
    "    A = P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().median()#.describe()[].to_frame().T.disp(200)\n",
    "    if A < 3:\n",
    "        P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "        q = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.params_list[0] == q\n",
    "str(self.params_list[0]) == q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, (params, P) in enumerate(self.pred.items()):\n",
    "    A = P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().median()#.describe()[].to_frame().T.disp(200)\n",
    "    if A < 3:\n",
    "        P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "        q = params\n",
    "\n",
    "# str(self.params_list[26]) == q\n",
    "[k for k, p in enumerate(self.params_list) if str(p)==q]\n",
    "# for s in self.params_list:\n",
    "#     print(str(s)==q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = str(list(self.pred.keys())[25])\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, (params, P) in enumerate(self.pred.items()):\n",
    "    A = P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().median()#.describe()[].to_frame().T.disp(200)\n",
    "    if A < 3:\n",
    "        print(k)\n",
    "        P['summary'].query(f\"train_term==202308 & pred_term!=202408\")[\"err_pct\"].abs().describe().to_frame().T.disp(200)\n",
    "        q = params\n",
    "    \n",
    "    # print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.params_list[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = {\n",
    "    '_total': {\n",
    "        202008: {\n",
    "            'n': {\n",
    "                'summary': 1,\n",
    "                'full': 2,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 3,\n",
    "                'full': 4,\n",
    "            },\n",
    "        },\n",
    "        202108: {\n",
    "            'n': {\n",
    "                'summary': 5,\n",
    "                'full': 6,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 7,\n",
    "                'full': 8,\n",
    "            },\n",
    "        },\n",
    "        202208: {\n",
    "            'n': {\n",
    "                'summary': 9,\n",
    "                'full': 10,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 11,\n",
    "                'full': 12,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    'engl1301': {\n",
    "        202008: {\n",
    "            'n': {\n",
    "                'summary': 21,\n",
    "                'full': 22,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 23,\n",
    "                'full': 24,\n",
    "            },\n",
    "        },\n",
    "        202108: {\n",
    "            'n': {\n",
    "                'summary': 25,\n",
    "                'full': 26,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 27,\n",
    "                'full': 28,\n",
    "            },\n",
    "        },\n",
    "        202208: {\n",
    "            'n': {\n",
    "                'summary': 29,\n",
    "                'full': 30,\n",
    "            },\n",
    "            'r': {\n",
    "                'summary': 31,\n",
    "                'full': 32,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "d = np.array(0)\n",
    "n/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(self.pred.keys())[10]\n",
    "self.pred[k].keys()#['rslt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.raw_df.query('pidm==1121725').disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in self.pred.values():\n",
    "    print(v.keys())\n",
    "    # pass\n",
    "# A = list(self.pred.values())[0]\n",
    "# A.keys()\n",
    "# self.analyze(A['summary'])\n",
    "# v['rslt']['proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crse = '_total'\n",
    "train_term = 202308\n",
    "styp_code = 'n'\n",
    "A = list(self.pred.values())[0]['summary'].query(f\"crse==@crse & train_term==@train_term & styp_code==@styp_code & pred_term!=202408\")\n",
    "A['err_pct'].abs().describe().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda Y: {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "Q = dict()\n",
    "for params, P in self.pred.items():\n",
    "    print(str(params))\n",
    "    for crse, C in P.items():\n",
    "        if crse in self.crse:\n",
    "            for train_term, T in C.items():\n",
    "                if train_term in self.term_codes:\n",
    "                    for styp_code, S in T.items():\n",
    "                        if styp_code in ['n','r','t']:\n",
    "                            path = [str(params),crse,train_term,styp_code]\n",
    "                            nest(path, Q, S)\n",
    "                    path.pop(-1)\n",
    "                    nest(path, Q, g(nest(path, Q)))\n",
    "            path.pop(-1)\n",
    "            nest(path, Q, g(nest(path, Q)))\n",
    "    path.pop(-1)\n",
    "    nest(path, Q, g(nest(path, Q)))\n",
    "    # nest(path, self.pred[params], g(nest(path, Q)))\n",
    "    # self.pred[params] = g(Q)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda Y: {k: pd.concat([y[k] for y in Y.values() if isinstance(y, dict) and k in y.keys()]).sort_index() for k in ['details','summary']}\n",
    "for params, P in self.pred.items():\n",
    "    print(str(params))\n",
    "    for crse in self.crse:\n",
    "        for train_term in self.term_codes:\n",
    "            for styp_code in ['n']:\n",
    "                S, new = self.predict(copy.deepcopy(params), crse, train_term, styp_code)\n",
    "                assert new is False\n",
    "                path = [str(params),crse,train_term,styp_code]\n",
    "                P = nest(path, P, S)\n",
    "                dump |= new\n",
    "            path.pop(-1)\n",
    "            P = nest(path, P, g(nest(path, P)))\n",
    "        path.pop(-1)\n",
    "        P = nest(path, P, g(nest(path, P)))\n",
    "    path.pop(-1)\n",
    "    self.pred[str(params)] = nest(path, P, g(nest(path, P)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25\n",
    "params = list(self.pred.keys())[k]\n",
    "rslt = self.pred[params]\n",
    "rslt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25\n",
    "params = list(self.pred.keys())[k]\n",
    "rslt = self.pred[params]\n",
    "df = rslt['summary']\n",
    "# df.query(f\"train_term==202308 & pred_term!=202408\")['err_pct'].abs().describe().to_frame().T.disp(200)\n",
    "\n",
    "def analyze(df):\n",
    "    def pivot(df, val):\n",
    "        Y = (\n",
    "            df\n",
    "            .reset_index()\n",
    "            .pivot_table(columns='train_term', index=['crse','styp_code','pred_term'], values=val, aggfunc=['count',pctl(0),pctl(25),pctl(50),pctl(75),pctl(100)])\n",
    "            .rename_axis(columns=[val,'train_term'])\n",
    "            .stack(0, future_stack=True)\n",
    "            .assign(abs_mean = lambda x: x.abs().mean(axis=1))\n",
    "        )\n",
    "        return Y\n",
    "    # v = self.pred[params]\n",
    "    # df = v['summary']\n",
    "    mask = df.eval(f\"pred_term!={self.infer_term}\")\n",
    "    rslt = {stat: pivot(df[mask], stat) for stat in [\"pred\",\"err\",\"err_pct\",\"mse_pct\",\"f1_inv_pct\"]} | {'pred': pivot(df[~mask], \"pred\")}\n",
    "    \n",
    "    return rslt\n",
    "    # R = v['rslt']['err_pct'].query(\"err_pct in [' 50%']\")\n",
    "    # R.disp(200)\n",
    "    # # R[['abs_mean']].describe().T.disp(200)\n",
    "    # # df.query(f\"crse==@crse & train_term==@train_term & styp_code==@styp_code & pred_term!=202408\")\n",
    "    # df.query(f\"train_term==202308 & pred_term!=202408\")['err_pct'].abs().describe().to_frame().T.disp(200)\n",
    "    # return self.dump()\n",
    "\n",
    "rslt = analyze(df)\n",
    "rslt['pred']\n",
    "# rslt.keys()\n",
    "# for k, (params, rslt) in enumerate(self.pred.items()):\n",
    "#     print(k, params)\n",
    "#     df = rslt['summary']\n",
    "#     df.query(f\"train_term==202308 & pred_term!=202408\")['err_pct'].abs().describe().to_frame().T.disp(200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
