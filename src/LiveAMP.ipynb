{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get 202008\n",
      "raw_202008_192.parq not found - creating\n",
      "flg_202008_192.parq not found - creating\n",
      "202006 flags cycle day 198 >= 192 on 2020-02-26 00:00:00 missing columns: ['gap_score', 'app_date', 'ftic_gap_score', 't_gap_score']\n",
      "202008 flags cycle day 198 >= 192 on 2020-02-26 00:00:00 missing columns: ['app_date', 'ftic_gap_score', 't_gap_score']\n",
      "get 202108\n",
      "raw_202108_192.parq not found - creating\n",
      "flg_202108_192.parq not found - creating\n",
      "202106 flags cycle day 198 >= 192 on 2021-02-24 00:00:00 missing columns: ['app_date']\n",
      "202108 flags cycle day 198 >= 192 on 2021-02-24 00:00:00 missing columns: []\n",
      "get 202208\n",
      "raw_202208_192.parq not found - creating\n",
      "flg_202208_192.parq not found - creating\n",
      "202206 flags cycle day 198 >= 192 on 2022-02-23 00:00:00 missing columns: ['gap_score']\n",
      "202208 flags cycle day 198 >= 192 on 2022-02-23 00:00:00 missing columns: ['gap_score']\n",
      "get 202308\n",
      "raw_202308_192.parq not found - creating\n",
      "flg_202308_192.parq not found - creating\n",
      "202306 flags cycle day 194 >= 192 on 2023-03-08 00:00:00 missing columns: ['gap_score']\n",
      "202308 flags cycle day 194 >= 192 on 2023-03-08 00:00:00 missing columns: ['gap_score']\n",
      "get 202408\n",
      "raw_202408_192.parq not found - creating\n",
      "flg_202408_192.parq not found - creating\n",
      "202406 flags cycle day 208 >= 192 on 2024-02-21 00:00:00 missing columns: ['gap_score', 'registered']\n",
      "202408 flags cycle day 208 >= 192 on 2024-02-21 00:00:00 missing columns: ['fafsa_app', 'finaid_accepted', 'disb_req_complete', 'gap_score', 'ver_complete', 'selected_for_ver']\n",
      "get Z\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>_cycle_day</th>\n",
       "      <th>_apdc_day</th>\n",
       "      <th>_appl_day</th>\n",
       "      <th>_birth_day</th>\n",
       "      <th>_end_date</th>\n",
       "      <th>_cycle_date</th>\n",
       "      <th>_apdc_date</th>\n",
       "      <th>_appl_date</th>\n",
       "      <th>_birth_date</th>\n",
       "      <th>_term_code_entry</th>\n",
       "      <th>_term_code</th>\n",
       "      <th>_term_desc</th>\n",
       "      <th>_pidm</th>\n",
       "      <th>_id</th>\n",
       "      <th>_appl_no</th>\n",
       "      <th>_levl_code</th>\n",
       "      <th>_levl_desc</th>\n",
       "      <th>_styp_code</th>\n",
       "      <th>_styp_desc</th>\n",
       "      <th>_admt_code</th>\n",
       "      <th>_admt_desc</th>\n",
       "      <th>_apst_code</th>\n",
       "      <th>_apst_desc</th>\n",
       "      <th>_apdc_code</th>\n",
       "      <th>_apdc_desc</th>\n",
       "      <th>_camp_code</th>\n",
       "      <th>_camp_desc</th>\n",
       "      <th>_camp_main</th>\n",
       "      <th>_cnty_code</th>\n",
       "      <th>_cnty_desc</th>\n",
       "      <th>_stat_code</th>\n",
       "      <th>_stat_desc</th>\n",
       "      <th>_zip</th>\n",
       "      <th>_natn_code</th>\n",
       "      <th>_natn_desc</th>\n",
       "      <th>_resd_code</th>\n",
       "      <th>_resd_desc</th>\n",
       "      <th>_resd</th>\n",
       "      <th>_majr_code</th>\n",
       "      <th>_gender</th>\n",
       "      <th>_lgcy_code</th>\n",
       "      <th>_lgcy_desc</th>\n",
       "      <th>_legacy</th>\n",
       "      <th>_race_american_indian</th>\n",
       "      <th>_race_asian</th>\n",
       "      <th>_race_black</th>\n",
       "      <th>_race_pacific</th>\n",
       "      <th>_race_white</th>\n",
       "      <th>_race_hispanic</th>\n",
       "      <th>_hs_pctl</th>\n",
       "      <th>_flg_date</th>\n",
       "      <th>_fafsa_app</th>\n",
       "      <th>_finaid_accepted</th>\n",
       "      <th>_disb_req_complete</th>\n",
       "      <th>_schlship_app</th>\n",
       "      <th>_math</th>\n",
       "      <th>_reading</th>\n",
       "      <th>_writing</th>\n",
       "      <th>_ssb</th>\n",
       "      <th>_waiver</th>\n",
       "      <th>_oriented</th>\n",
       "      <th>_verified</th>\n",
       "      <th>_act_equiv</th>\n",
       "      <th>_distance</th>\n",
       "      <th>_gap_score</th>\n",
       "      <th>_hs_qrtl</th>\n",
       "      <th>_remote</th>\n",
       "      <th>_majr_desc</th>\n",
       "      <th>_dept_code</th>\n",
       "      <th>_dept_desc</th>\n",
       "      <th>_coll_code</th>\n",
       "      <th>_coll_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pidm</th>\n",
       "      <th>term_code</th>\n",
       "      <th>term_desc</th>\n",
       "      <th>apdc_code</th>\n",
       "      <th>apdc_desc</th>\n",
       "      <th>levl_code</th>\n",
       "      <th>levl_desc</th>\n",
       "      <th>styp_code</th>\n",
       "      <th>styp_desc</th>\n",
       "      <th>admt_code</th>\n",
       "      <th>admt_desc</th>\n",
       "      <th>camp_code</th>\n",
       "      <th>camp_desc</th>\n",
       "      <th>coll_code</th>\n",
       "      <th>coll_desc</th>\n",
       "      <th>dept_code</th>\n",
       "      <th>dept_desc</th>\n",
       "      <th>majr_code</th>\n",
       "      <th>majr_desc</th>\n",
       "      <th>cnty_code</th>\n",
       "      <th>cnty_desc</th>\n",
       "      <th>stat_code</th>\n",
       "      <th>stat_desc</th>\n",
       "      <th>natn_code</th>\n",
       "      <th>natn_desc</th>\n",
       "      <th>resd</th>\n",
       "      <th>legacy</th>\n",
       "      <th>gender</th>\n",
       "      <th>race_american_indian</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_pacific</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>waiver</th>\n",
       "      <th>birth_day</th>\n",
       "      <th>distance</th>\n",
       "      <th>hs_pctl</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25534</th>\n",
       "      <th>202008</th>\n",
       "      <th>fall 2020</th>\n",
       "      <th>a2</th>\n",
       "      <th>admit, probation (readmit)</th>\n",
       "      <th>ug</th>\n",
       "      <th>undergraduate</th>\n",
       "      <th>r</th>\n",
       "      <th>returning</th>\n",
       "      <th>r</th>\n",
       "      <th>readmit student, undergraduate</th>\n",
       "      <th>s</th>\n",
       "      <th>stephenville</th>\n",
       "      <th>an</th>\n",
       "      <th>ag &amp; natural resources</th>\n",
       "      <th>wlnr</th>\n",
       "      <th>wildlife &amp; natural resources</th>\n",
       "      <th>wses</th>\n",
       "      <th>wildlife sus &amp; ecosystem sci</th>\n",
       "      <th>25</th>\n",
       "      <th>brown</th>\n",
       "      <th>tx</th>\n",
       "      <th>texas</th>\n",
       "      <th>&lt;NA&gt;</th>\n",
       "      <th>&lt;NA&gt;</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>m</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>&lt;NA&gt;</th>\n",
       "      <th>13286</th>\n",
       "      <th>4504.84</th>\n",
       "      <th>65</th>\n",
       "      <td>192</td>\n",
       "      <td>196</td>\n",
       "      <td>198</td>\n",
       "      <td>13286</td>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>1984-04-27</td>\n",
       "      <td>202006</td>\n",
       "      <td>202008</td>\n",
       "      <td>fall 2020</td>\n",
       "      <td>25534</td>\n",
       "      <td>50238</td>\n",
       "      <td>3</td>\n",
       "      <td>ug</td>\n",
       "      <td>undergraduate</td>\n",
       "      <td>r</td>\n",
       "      <td>returning</td>\n",
       "      <td>r</td>\n",
       "      <td>readmit student, undergraduate</td>\n",
       "      <td>d</td>\n",
       "      <td>decision made</td>\n",
       "      <td>a2</td>\n",
       "      <td>admit, probation (readmit)</td>\n",
       "      <td>s</td>\n",
       "      <td>stephenville</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>brown</td>\n",
       "      <td>tx</td>\n",
       "      <td>texas</td>\n",
       "      <td>76801</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>r</td>\n",
       "      <td>texas resident</td>\n",
       "      <td>1</td>\n",
       "      <td>wses</td>\n",
       "      <td>m</td>\n",
       "      <td>u</td>\n",
       "      <td>uncle</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4504.84</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wildlife sus &amp; ecosystem sci</td>\n",
       "      <td>wlnr</td>\n",
       "      <td>wildlife &amp; natural resources</td>\n",
       "      <td>an</td>\n",
       "      <td>ag &amp; natural resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "No axis named _schlship_app for object type DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:299\u001b[0m, in \u001b[0;36mApply.transform_str_or_callable\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03mInvoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03mdtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4764\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/base.py:919\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m--> 919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/base.py:2188\u001b[0m, in \u001b[0;36mExtensionArray.map\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;124;03mMap values using an input mapping or function.\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2186\u001b[0m \u001b[38;5;124;03m    a MultiIndex will be returned.\u001b[39;00m\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py:214\u001b[0m, in \u001b[0;36mimpute.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    213\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: val\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (df \u001b[38;5;28;01mif\u001b[39;00m grp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(grp))[col]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m(func(x)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NAType' object has no attribute 'fillna'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/internals/blocks.py:2002\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[0;34m(self, value, limit, inplace, downcast, using_cow)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2002\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/_mixins.py:359\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[0;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[1;32m    358\u001b[0m             new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/string_.py:450\u001b[0m, in \u001b[0;36mStringArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 450\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set non-string value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m into a StringArray.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot set non-string value 'False' into a StringArray.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py:118\u001b[0m, in \u001b[0;36mpd_ext.<locals>.wrapper\u001b[0;34m(X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py:214\u001b[0m, in \u001b[0;36mimpute\u001b[0;34m(df, col, val, grp)\u001b[0m\n\u001b[1;32m    213\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: val\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/series.py:4626\u001b[0m, in \u001b[0;36mSeries.transform\u001b[0;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m ser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 4626\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:231\u001b[0m, in \u001b[0;36mApply.transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_str_or_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:301\u001b[0m, in \u001b[0;36mApply.transform_str_or_callable\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py:214\u001b[0m, in \u001b[0;36mimpute.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    213\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: val\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (df \u001b[38;5;28;01mif\u001b[39;00m grp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(grp))[col]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/generic.py:7212\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   7206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   7207\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameter must be a scalar, dict \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   7208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Series, but you passed a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   7209\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   7210\u001b[0m         )\n\u001b[0;32m-> 7212\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\n\u001b[1;32m   7214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7216\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/internals/base.py:173\u001b[0m, in \u001b[0;36mDataManager.fillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m    171\u001b[0m     limit \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mvalidate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfillna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/internals/blocks.py:2008\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[0;34m(self, value, limit, inplace, downcast, using_cow)\u001b[0m\n\u001b[1;32m   2007\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2008\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/_mixins.py:359\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[0;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[1;32m    358\u001b[0m             new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/string_.py:450\u001b[0m, in \u001b[0;36mStringArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 450\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set non-string value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m into a StringArray.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot set non-string value 'False' into a StringArray.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:299\u001b[0m, in \u001b[0;36mApply.transform_str_or_callable\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03mInvoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03mdtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4764\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/base.py:919\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m--> 919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/base.py:2188\u001b[0m, in \u001b[0;36mExtensionArray.map\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;124;03mMap values using an input mapping or function.\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2186\u001b[0m \u001b[38;5;124;03m    a MultiIndex will be returned.\u001b[39;00m\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py:214\u001b[0m, in \u001b[0;36mimpute.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    213\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: val\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (df \u001b[38;5;28;01mif\u001b[39;00m grp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(grp))[col]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m(func(x)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NAType' object has no attribute 'fillna'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/internals/blocks.py:2002\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[0;34m(self, value, limit, inplace, downcast, using_cow)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2002\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/_mixins.py:359\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[0;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[1;32m    358\u001b[0m             new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/string_.py:450\u001b[0m, in \u001b[0;36mStringArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 450\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set non-string value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m into a StringArray.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot set non-string value 'False' into a StringArray.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py:122\u001b[0m, in \u001b[0;36mpd_ext.<locals>.wrapper\u001b[0;34m(X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py:214\u001b[0m, in \u001b[0;36mimpute\u001b[0;34m(df, col, val, grp)\u001b[0m\n\u001b[1;32m    213\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: val\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/series.py:4626\u001b[0m, in \u001b[0;36mSeries.transform\u001b[0;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m ser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 4626\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:231\u001b[0m, in \u001b[0;36mApply.transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_str_or_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py:301\u001b[0m, in \u001b[0;36mApply.transform_str_or_callable\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py:214\u001b[0m, in \u001b[0;36mimpute.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    213\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: val\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (df \u001b[38;5;28;01mif\u001b[39;00m grp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(grp))[col]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/generic.py:7212\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   7206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   7207\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameter must be a scalar, dict \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   7208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Series, but you passed a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   7209\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   7210\u001b[0m         )\n\u001b[0;32m-> 7212\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\n\u001b[1;32m   7214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7216\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/internals/base.py:173\u001b[0m, in \u001b[0;36mDataManager.fillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m    171\u001b[0m     limit \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mvalidate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfillna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/internals/blocks.py:2008\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[0;34m(self, value, limit, inplace, downcast, using_cow)\u001b[0m\n\u001b[1;32m   2007\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2008\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/_mixins.py:359\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[0;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[1;32m    358\u001b[0m             new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/arrays/string_.py:450\u001b[0m, in \u001b[0;36mStringArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 450\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set non-string value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m into a StringArray.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot set non-string value 'False' into a StringArray.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mNo axis named \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m for object type \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '_schlship_app'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4087505/1954453008.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;31m# FLAGS().run()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAMP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;31m# self = self.get_X()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;31m# self.term_codes.remove(self.infer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;31m# iterations = 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4087505/1954453008.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mwhere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"levl_code == 'ug' and styp_code in ('n','r','t')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'levl_code'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'styp_code'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'term_code'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'crse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0magg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'credit_hr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/src/setup.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10020\u001b[0m         \u001b[0;36m2\u001b[0m  \u001b[0;36m1\u001b[0m  \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10021\u001b[0m         \"\"\"\n\u001b[1;32m  10022\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mframe_apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10024\u001b[0;31m         op = frame_apply(\n\u001b[0m\u001b[1;32m  10025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10026\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10027\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(obj, func, axis, raw, result_type, by_row, args, kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFrameApply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;34m\"\"\"construct and return a row or column based frame apply object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mklass\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFrameApply\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameRowApply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my3.12/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mNo axis named \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m for object type \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: No axis named _schlship_app for object type DataFrame"
     ]
    }
   ],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest import ImputationKernel\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer: int\n",
    "    crse: typing.List\n",
    "    feat: typing.Dict\n",
    "    attr: typing.List\n",
    "    sch: bool = True\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.term_codes = listify(self.term_codes)\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'X':False, 'Y':False, 'Z':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['Z'] |= self.overwrite['X'] | self.overwrite['Y']\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.path = root_path / f\"resources/rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['pred']:\n",
    "            self[k] = self[k] if k in self else list()\n",
    "        for k in ['term']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "    def get_X(self):\n",
    "        nm = 'X'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        print(f'get {nm}')\n",
    "        R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "        repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "        R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "        R['remote'] = R['camp_code'] != 's'\n",
    "        # R['distance'] = R['distance'].fillna(R['distance'].max())\n",
    "        R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "        R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm'})\n",
    "        R['coll_desc'] = R['coll_desc'].replace({\n",
    "            'ag & environmental sciences':'ag & natural resources',\n",
    "            'education & human development':'education',\n",
    "            'health science & human service':'health sciences',\n",
    "            'science & technology':'science & mathematics'})\n",
    "        majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "        S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "        R = R.drop(columns=majr).merge(S, on='majr_code', how='left')\n",
    "\n",
    "        checks = {\n",
    "            'cycle_day': R['cycle_day']>=0,\n",
    "            'apdc_day' : R['apdc_day' ]>=R['cycle_day'],\n",
    "            'appl_day' : R['appl_day' ]>=R['apdc_day' ],\n",
    "            'birth_day':(R['birth_day']>=R['appl_day' ]) & (R['birth_day']>=5000),\n",
    "            'distance': R['distance']>=0,\n",
    "            'hs_pctl': (R['hs_pctl']>=0) & (R['hs_pctl']<=100),\n",
    "            'act_equiv': (R['act_equiv']>=1) & (R['act_equiv']<=36),\n",
    "            'gap_score': (R['gap_score']>=0) & (R['gap_score']<=100),\n",
    "        }\n",
    "        for k, mask in checks.items():\n",
    "            if (~mask).any():\n",
    "                R[~mask].disp(10)\n",
    "                raise Exception(f'check failed - {k}')\n",
    "        self[nm] = R\n",
    "        return self.dump()\n",
    "\n",
    "    def preprocess(self):\n",
    "        nm = 'Z'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        self.get_X()\n",
    "        print(f'get {nm}')\n",
    "\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "        X.disp(1)\n",
    "        self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "\n",
    "        g = ['levl_code','styp_code','term_code','crse']\n",
    "        agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\")[['pidm',*g,'credit_hr']].assign(credit_hr=lambda x: x['credit_hr'].fillna(0)>0) for term in self.term.values()]) for k in ['end','cur']}\n",
    "        A = agg(Y['end'], g)\n",
    "        Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr'], how='inner') for k, y in Y.items()}\n",
    "        B = agg(Y['end'], g)\n",
    "        M = (A / B).query(\"term_code != @self.infer\")\n",
    "        N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "        self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "        self.Y = {k: y.squeeze().unstack().fillna(False).rename(columns=lambda x:f'{x}_{k}') for k, y in Y.items()}\n",
    "\n",
    "\n",
    "        # where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        # X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "        # self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "        #     # self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "        #     # self.Z.missing().disp(100)\n",
    "        #     # for c in ['_hs_qrtl', '_act_equiv']:\n",
    "        #     #     self.Z[c+'_missing'] = self.Z[c].isnull()\n",
    "        #     # self.Z = self.Z.prep().binarize().categorize()\n",
    "        # agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "        # grp = ['levl_code','styp_code','term_code','crse']\n",
    "        # end = agg(self.Y[0], grp)\n",
    "        \n",
    "        # self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "        # cur = agg(self.Y[0], grp)\n",
    "\n",
    "        # M = (end / cur).query(\"term_code != @self.infer\")\n",
    "        # N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "        # self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, crse='_total', styp_code='all', train_term=202208, iterations=3, opts=dict()):\n",
    "        print(crse,train_term,styp_code, end=': ')\n",
    "        prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "        for P in self.pred:\n",
    "            if P['meta'] == prediction['meta']:\n",
    "                print('reusing')\n",
    "                return P\n",
    "        print(f'creating')\n",
    "        # d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "        d = {crse+'_cur':1, crse+'_end':0,}\n",
    "        end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "        Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "        T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "        if styp_code != \"all\":\n",
    "            T = T.query(\"styp_code==@styp_code\")\n",
    "        T.loc[T.eval(\"term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "        X = T.copy()\n",
    "        # qry = \"term_code!=@train_term\"\n",
    "        qry = \"term_code==@train_term\"\n",
    "        X.loc[X.eval(qry), end.keys()] = pd.NA\n",
    "        model = ImputationKernel(X, **opts)\n",
    "        model.mice(iterations)\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "            # assert 1==2\n",
    "        #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "        #     # imp.plot_correlations()\n",
    "\n",
    "        g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "        Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "        grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            S[x] = S[x] * S['mlt']\n",
    "        S.insert(2, 'err', S['pred'] - S['true'])\n",
    "        S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "        prediction['rslt'] = {'X':X,'T':T,'P':P,'model':model, 'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "        self.pred.append(prediction)\n",
    "        self.dump()\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def train(self, styp_codes=('n','r','t'), train_terms=None, iterations=3, opts=dict()):\n",
    "        train_terms = self.term_codes if train_terms is None else train_terms\n",
    "        def pivot(df, val, q=50):\n",
    "            Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "            for _ in range(2):\n",
    "                mr = Y.mean(axis=1)\n",
    "                ma = Y.abs().mean(axis=1)\n",
    "                Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "            return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "        \n",
    "        def analyze(df):\n",
    "            r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "            r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "            return r\n",
    "\n",
    "        P = {(crse, styp_code, train_term): self.predict(crse, styp_code, train_term, iterations, opts) for crse in self.crse for styp_code in listify(styp_codes) for train_term in listify(train_terms)}\n",
    "        R = dict()\n",
    "        for k,v in P.items():\n",
    "            R.setdefault(k[1]=='all', []).append(v)\n",
    "\n",
    "        for b, L in R.items():\n",
    "            v = {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']}\n",
    "            v['opts'] = opts.copy()\n",
    "            v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "            R[b] = v\n",
    "        return R\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "simpimp = lambda fill: SimpleImputer(strategy='constant', fill_value=fill, missing_values=pd.NA)\n",
    "kwargs = {\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_pctl',\n",
    "    ],\n",
    "    'feat': [\n",
    "        ['_apdc_day',np.nan],\n",
    "        ['_appl_day',np.nan],\n",
    "        ['_gender',np.nan],\n",
    "        ['_hs_qrtl',np.nan],\n",
    "        ['_act_equiv',np.nan],\n",
    "        # ['_distance','max'],\n",
    "        ['_distance',np.nan],\n",
    "        ['_remote',False],\n",
    "        ['_resd',False],\n",
    "        ['_legacy',False],\n",
    "        *[[f'_race_{r}',False] for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        ['_waiver',False],\n",
    "        # ['_fafsa_app',False],\n",
    "        ['_schlship_app',False],\n",
    "        # ['_finaid_accepted',False],\n",
    "        ['_ssb',False],\n",
    "        ['_math',False],\n",
    "        ['_reading',False],\n",
    "        ['_writing',False],\n",
    "        ['_gap_score',0],\n",
    "        ['_oriented','n'],\n",
    "        ['_birth_day','median',['term_code','styp_code']],\n",
    "    ],\n",
    "    'infer': 202408,\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    # 'cycle_day': 197,\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'crse': [\n",
    "        '_total',\n",
    "        'engl1301',\n",
    "        'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        'flg':True,\n",
    "        'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'X': True,\n",
    "        'Y': True,\n",
    "        'Z': True,\n",
    "        # 'pred': True,\n",
    "    },\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    # 'sch': False,\n",
    "}\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "# self = self.get_X()\n",
    "self = self.preprocess()\n",
    "# self.term_codes.remove(self.infer)\n",
    "# iterations = 3\n",
    "\n",
    "# opts = dict()\n",
    "# opts['random_state'] = 42\n",
    "# opts['save_all_iterations'] = False\n",
    "# opts['datasets'] = 5\n",
    "# opts['mean_match_candidates'] = 10\n",
    "# opts['mean_match_function'] = mean_match_kdtree_classification\n",
    "\n",
    "# # opts['datasets'] = 2\n",
    "# # opts['mean_match_candidates'] = 1\n",
    "# # opts['mean_match_function'] = default_mean_match\n",
    "\n",
    "# P = self.predict(opts=opts)\n",
    "\n",
    "# R = self.train(iterations=iterations, opts=opts,\n",
    "#     styp_codes='n',\n",
    "#     # train_terms=202208,\n",
    "#     )\n",
    "# for k in R[False]['rslt'].keys():\n",
    "#     for b, v in R.items():\n",
    "#         print(k, b)\n",
    "#         v['rslt'][k]['err%'].disp(100)\n",
    "\n",
    "# tune = []\n",
    "# for func in [mean_match_kdtree_classification, default_mean_match]:\n",
    "#     opts['mean_match_function'] = func\n",
    "#     for cand in range(2,41,3):\n",
    "#         opts['mean_match_candidates'] = cand\n",
    "#         print(sort(opts))\n",
    "#         R = self.train(\n",
    "#             styp_codes='n',\n",
    "#             iterations=iterations,\n",
    "#             opts=opts)\n",
    "#         R[False]['rslt']['_total','n']['err%'].disp(100)\n",
    "#         tune.append(R)\n",
    "#         write(self.tune, tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_ext(func):\n",
    "    def wrapper(X, *args, **kwargs):\n",
    "        try:\n",
    "            Y = func(X, *args, **kwargs)\n",
    "            print(1)\n",
    "        except:\n",
    "            Y = pd.DataFrame(X)\n",
    "            try:\n",
    "                Y = func(Y, *args, **kwargs)\n",
    "                print(2)\n",
    "            except:\n",
    "                Y = Y.apply(func, *args, **kwargs)\n",
    "                print(3)\n",
    "        if isinstance(X, pd.Series):\n",
    "            try:\n",
    "                Y = Y.squeeze()\n",
    "            except:\n",
    "                pass\n",
    "        return Y\n",
    "    wrapper.__name__ = func.__name__\n",
    "    return wrapper\n",
    "\n",
    "@pd_ext\n",
    "def binarize(ser):\n",
    "    assert isinstance(ser, pd.Series)\n",
    "    s = set(ser.dropna())\n",
    "    if s:\n",
    "        if s.issubset({'y','Y'}):\n",
    "            ser = ser.notnull().astype('boolean')\n",
    "        elif s.issubset({0,1}):\n",
    "            ser = ser.astype('boolean')\n",
    "    return ser\n",
    "\n",
    "for func in [disp, to_numeric, prep, categorize, binarize, rnd, vc, missing, impute, unmelt]:\n",
    "    for cls in [pd.DataFrame, pd.Series]:\n",
    "        setattr(cls, func.__name__, func)\n",
    "\n",
    "# self.X['schlship_app'].value_counts()\n",
    "# self.X['fafsa_app'].value_counts()\n",
    "# self.X['schlship_app'].dtype\n",
    "# A = self.X.binarize()['schlship_app']\n",
    "# A['schlship_app']\n",
    "binarize(self.X)['schlship_app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['schlship_app'].groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "X = where(self.X).set_index(self.attr, drop=False).rename(columns=lambda col:'_'+col)\n",
    "self.Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "\n",
    "g = ['levl_code','styp_code','term_code','crse']\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    Y = {k: pd.concat([term.reg[k].query(\"crse in @self.crse\")[['pidm',*g,'credit_hr']].assign(credit_hr=lambda x: x['credit_hr'].fillna(0)>0) for term in self.term.values()]) for k in ['end','cur']}\n",
    "agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "A = agg(Y['end'], g)\n",
    "Y = {k: self.Z[[]].join(y.set_index(['pidm','term_code','crse'])['credit_hr'], how='inner') for k, y in Y.items()}\n",
    "B = agg(Y['end'], g)\n",
    "self.mlt = A / B\n",
    "\n",
    "self.Y = {k: y.squeeze().unstack().fillna(False).rename(columns=lambda x:f'{x}_{k}') for k, y in Y.items()}\n",
    "Y['end']\n",
    "# M = (end / cur).query(\"term_code != @self.infer\")\n",
    "# N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "# self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "\n",
    "\n",
    "# end\n",
    "self.Y['end']\n",
    "# Y = [self.Y[0].query(\"crse in @self.crse\").set_index('crse', append=True).unstack().droplevel(0,1).rename(columns=lambda x:f\"_{x}_end\")\n",
    "# # Y.droplevel?\n",
    "# Y.disp(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute(df, col, val=None, grp=None):\n",
    "#     val = val if val is not None else 'median' if pd.api.types.is_numeric_dtype(df[col]) else 'mode'\n",
    "#     if val in ['median']:\n",
    "#         func = lambda x: x.median()\n",
    "#     elif val in ['mean','ave','avg','average']:\n",
    "#         func = lambda x: x.mean()\n",
    "#     elif val in ['mode','most_frequent']:\n",
    "#         func = lambda x: x.mode()[0]\n",
    "#     else:\n",
    "#         func = lambda x: val\n",
    "#     df[col] = (df if grp is None else df.groupby(grp))[col].transform(lambda x: x.fillna(func(x)))\n",
    "#     return df\n",
    "# pd.DataFrame.impute = impute\n",
    "\n",
    "self.Z.reset_index(drop=True)\n",
    "A = self.Z.copy()\n",
    "c = '_birth_day'\n",
    "mask = A[c].isnull()\n",
    "# A.impute('_birth_day', val='median', grp=['term_code','styp_code'])\n",
    "# A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.loc[mask,c].disp(5)\n",
    "# A.groupby(['term_code','styp_code'])['_birth_day'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trf = ColumnTransformer(self.feat, remainder='drop',verbose_feature_names_out = False)\n",
    "# where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "# with warnings.catch_warnings(action='ignore'):\n",
    "#     self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "#     self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "\n",
    "kwargs = {\n",
    "    'feat': [\n",
    "        ['_gender',np.nan],\n",
    "        ['_appl_day',np.nan],\n",
    "        ['_apdc_day',np.nan],\n",
    "        ['_hs_qrtl',np.nan],\n",
    "        ['_act_equiv',np.nan],\n",
    "        ['_remote',False],\n",
    "        ['_resd',False],\n",
    "        ['_legacy',False],\n",
    "        *[[f'_race_{r}',False] for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        ['_waiver',False],\n",
    "        # ['_fafsa_app',False],\n",
    "        ['_schlship_app',False],\n",
    "        # ['_finaid_accepted',False],\n",
    "        ['_ssb',False],\n",
    "        ['_math',False],\n",
    "        ['_reading',False],\n",
    "        ['_writing',False],\n",
    "        ['_gap_score',0],\n",
    "        ['_oriented','n'],\n",
    "        ['_distance','max'],\n",
    "        ['_birth_day','median',['term_code','styp_code']],\n",
    "    ],\n",
    "}\n",
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "g = lambda col:'_'+col\n",
    "# cols = [x[0] for x in kwargs['feat']]\n",
    "# where(self.X).rename(columns=g)[cols].isnull().sum().disp(1000)\n",
    "X = where(self.X).set_index(self.attr, drop=False).rename(columns=g)\n",
    "Z = pd.concat([X.impute(*x) for x in self.feat], axis=1).prep().binarize().categorize()\n",
    "Z.isnull().sum().disp(1000)\n",
    "Z.dtypes\n",
    "# L = [Z.impute(col, *val)]\n",
    "# L = [[col, *listify(val)] for C, val in kwargs['feat'] for col in listify(C)]\n",
    "# L = [Z.impute(g(col), *listify(val)) for C, val in kwargs['feat'] for col in listify(C)]\n",
    "# L\n",
    "#).rename(columns=lambda x:'_'+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(Z).disp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/flags/parq/flg_202308.parq', columns=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('spbpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"select spbpers_sex, count(*) from spbpers group by spbpers_sex\"\n",
    "db.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest import ImputationKernel\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "def feature_importance_df(self, dataset=0, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(dataset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() * 100 if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AMP(MyBaseClass):\n",
    "    cycle_day: int\n",
    "    term_codes: typing.List\n",
    "    infer: int\n",
    "    crse: typing.List\n",
    "    feat: typing.Dict\n",
    "    attr: typing.List\n",
    "    sch: bool = True\n",
    "    overwrite: typing.Dict = None\n",
    "    show: typing.Dict = None\n",
    "\n",
    "    def dump(self):\n",
    "        return write(self.rslt, self, overwrite=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # check feat lists are disjoint\n",
    "        L = [x for f in self.feat for x in f[-1]]\n",
    "        assert len(L) == len(set(L))\n",
    "\n",
    "        self.term_codes = listify(self.term_codes)\n",
    "        D = {'adm':False, 'reg':False, 'flg':False, 'raw':False, 'term':False, 'X':False, 'Y':False, 'Z':False, 'pred':False}\n",
    "        for x in ['overwrite','show']:\n",
    "            self[x] = D.copy() if self[x] is None else D.copy() | self[x]\n",
    "        self.overwrite['Z'] |= self.overwrite['X'] | self.overwrite['Y']\n",
    "        self.overwrite['raw'] |= self.overwrite['reg'] | self.overwrite['adm'] | self.overwrite['flg']\n",
    "        self.overwrite['term'] |= self.overwrite['raw']\n",
    "        self.path = root_path / f\"rslt/{rjust(self.cycle_day,3,0)}\"\n",
    "        self.rslt = self.path / f\"rslt.pkl\"\n",
    "        self.tune = self.path / f\"tune.pkl\"\n",
    "        try:\n",
    "            self.__dict__ = read(self.rslt).__dict__ | self.__dict__\n",
    "        except:\n",
    "            pass\n",
    "        for k, v in self.overwrite.items():\n",
    "            if v and k in self:\n",
    "                del self[k]\n",
    "        for k in ['pred']:\n",
    "            self[k] = self[k] if k in self else list()\n",
    "        for k in ['term']:\n",
    "            self[k] = self[k] if k in self else dict()\n",
    "\n",
    "        opts = {x:self[x] for x in ['cycle_day','overwrite','show']}\n",
    "        for nm in self.term_codes:\n",
    "            if nm not in self.term:\n",
    "                print(f'get {nm}')\n",
    "                self.term[nm] = TERM(term_code=nm, **opts).get_raw()\n",
    "        return self.dump()\n",
    "\n",
    "    def get_X(self):\n",
    "        nm = 'X'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        print(f'get {nm}')\n",
    "        R = pd.concat([term.raw for term in self.term.values()], ignore_index=True).dropna(axis=1, how='all').prep()\n",
    "        repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "        R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))\n",
    "        R['camp_main'] = R['camp_code'] == 's'\n",
    "        R['distance'] = R['distance'].fillna(R['distance'].max())\n",
    "        R['majr_code'] = R['majr_code'].replace({'0000':'und', 'eled':'eted', 'agri':'unda'})\n",
    "        R['coll_code'] = R['coll_code'].replace({'ae':'an', 'eh':'ed', 'hs':'hl', 'st':'sm'})\n",
    "        R['coll_desc'] = R['coll_desc'].replace({\n",
    "            'ag & environmental sciences':'ag & natural resources',\n",
    "            'education & human development':'education',\n",
    "            'health science & human service':'health sciences',\n",
    "            'science & technology':'science & mathematics'})\n",
    "        majr = ['majr_desc','dept_code','dept_desc','coll_code','coll_desc']\n",
    "        S = R.sort_values('cycle_date').drop_duplicates(subset='majr_code', keep='last')[['majr_code',*majr]]\n",
    "        R = R.drop(columns=majr).merge(S, on='majr_code', how='left')\n",
    "\n",
    "        checks = {\n",
    "            'cycle_day': R['cycle_day']>=0,\n",
    "            'apdc_day' : R['apdc_day' ]>=R['cycle_day'],\n",
    "            'appl_day' : R['appl_day' ]>=R['apdc_day' ],\n",
    "            'birth_day':(R['birth_day']>=R['appl_day' ]) & (R['birth_day']>=5000),\n",
    "            'distance': R['distance']>=0,\n",
    "            'hs_pctl': (R['hs_pctl']>=0) & (R['hs_pctl']<=100),\n",
    "            'act_equiv': (R['act_equiv']>=1) & (R['act_equiv']<=36),\n",
    "            'gap_score': (R['gap_score']>=0) & (R['gap_score']<=100),\n",
    "        }\n",
    "        for k, mask in checks.items():\n",
    "            if (~mask).any():\n",
    "                R[~mask].disp(10)\n",
    "                raise Exception(f'check failed - {k}')\n",
    "        self[nm] = R\n",
    "        return self.dump()\n",
    "\n",
    "    def preprocess(self):\n",
    "        nm = 'Z'\n",
    "        if nm in self:\n",
    "            return self\n",
    "        self.get_X()\n",
    "        print(f'get {nm}')\n",
    "\n",
    "        trf = ColumnTransformer(self.feat, remainder='drop',verbose_feature_names_out = False)\n",
    "        where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "            self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False)).rename(columns=lambda x:'_'+x)\n",
    "            self.Z.missing().disp(100)\n",
    "            for c in ['_hs_qrtl', '_act_equiv']:\n",
    "                self.Z[c+'_missing'] = self.Z[c].isnull()\n",
    "            self.Z = self.Z.prep().binarize().categorize()\n",
    "        agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "        grp = ['levl_code','styp_code','term_code','crse']\n",
    "        end = agg(self.Y[0], grp)\n",
    "        \n",
    "        self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "        cur = agg(self.Y[0], grp)\n",
    "\n",
    "        M = (end / cur).query(\"term_code != @self.infer\")\n",
    "        N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "        self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "        return self.dump()\n",
    "\n",
    "\n",
    "    def predict(self, crse='_total', styp_code='all', train_term=202208, iterations=3, opts=dict()):\n",
    "        print(crse,train_term,styp_code, end=': ')\n",
    "        prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "        for P in self.pred:\n",
    "            if P['meta'] == prediction['meta']:\n",
    "                print('reusing')\n",
    "                return P\n",
    "        print(f'creating')\n",
    "        # d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "        d = {crse+'_cur':1, crse+'_end':0,}\n",
    "        end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "        Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "        T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "        if styp_code != \"all\":\n",
    "            T = T.query(\"styp_code==@styp_code\")\n",
    "        T.loc[T.eval(\"term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "        X = T.copy()\n",
    "        # qry = \"term_code!=@train_term\"\n",
    "        qry = \"term_code==@train_term\"\n",
    "        X.loc[X.eval(qry), end.keys()] = pd.NA\n",
    "        model = ImputationKernel(X, **opts)\n",
    "        model.mice(iterations)\n",
    "        # with warnings.catch_warnings(action='ignore'):\n",
    "        #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "            # assert 1==2\n",
    "        #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "        #     # imp.plot_correlations()\n",
    "\n",
    "        g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "        P = pd.concat([model.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(model.dataset_count())])\n",
    "        Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query(qry).prep()\n",
    "        grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "        agg = lambda x: pd.Series({\n",
    "            'pred': x['pred'].sum(min_count=1),\n",
    "            'true': x['true'].sum(min_count=1),\n",
    "            'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "            'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "        })\n",
    "        S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "        for x in ['pred','true']:\n",
    "            S[x] = S[x] * S['mlt']\n",
    "        S.insert(2, 'err', S['pred'] - S['true'])\n",
    "        S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "        prediction['rslt'] = {'X':X,'T':T,'P':P,'model':model, 'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "        self.pred.append(prediction)\n",
    "        self.dump()\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def train(self, styp_codes=('n','r','t'), train_terms=None, iterations=3, opts=dict()):\n",
    "        train_terms = self.term_codes if train_terms is None else train_terms\n",
    "        def pivot(df, val, q=50):\n",
    "            Y = df.reset_index().pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "            for _ in range(2):\n",
    "                mr = Y.mean(axis=1)\n",
    "                ma = Y.abs().mean(axis=1)\n",
    "                Y = (Y.assign(mean=mr, abs_mean=ma) if Y.shape[1] > 1 else Y).T\n",
    "            return Y.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(2).prep().T\n",
    "        \n",
    "        def analyze(df):\n",
    "            r = {stat: pivot(df.query(f\"pred_term!={self.infer}\"), stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "            r['proj'] = pd.concat([pivot(df.query(f\"pred_term=={self.infer}\"), \"pred\", q) for q in [25,50,75]], axis=1)\n",
    "            return r\n",
    "\n",
    "        P = {(crse, styp_code, train_term): self.predict(crse, styp_code, train_term, iterations, opts) for crse in self.crse for styp_code in listify(styp_codes) for train_term in listify(train_terms)}\n",
    "        R = dict()\n",
    "        for k,v in P.items():\n",
    "            R.setdefault(k[1]=='all', []).append(v)\n",
    "\n",
    "        for b, L in R.items():\n",
    "            v = {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']}\n",
    "            v['opts'] = opts.copy()\n",
    "            v['rslt'] = {g: analyze(df) for g, df in v['summary'].groupby(['crse', 'styp_code'])}\n",
    "            R[b] = v\n",
    "        return R\n",
    "\n",
    "\n",
    "code_desc = lambda x: [x+'_code', x+'_desc']\n",
    "simpimp = lambda fill: SimpleImputer(strategy='constant', fill_value=fill, missing_values=pd.NA)\n",
    "kwargs = {\n",
    "    'attr': [\n",
    "        'pidm',\n",
    "        *code_desc('term'),\n",
    "        *code_desc('apdc'),\n",
    "        *code_desc('levl'),\n",
    "        *code_desc('styp'),\n",
    "        *code_desc('admt'),\n",
    "        *code_desc('camp'),\n",
    "        *code_desc('coll'),\n",
    "        *code_desc('dept'),\n",
    "        *code_desc('majr'),\n",
    "        *code_desc('cnty'),\n",
    "        *code_desc('stat'),\n",
    "        *code_desc('natn'),\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        'gender',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        'birth_day',\n",
    "        'distance',\n",
    "        'hs_pctl',\n",
    "    ],\n",
    "    'feat': [\n",
    "        ('scl', make_pipeline(StandardScaler(), PowerTransformer()), [\n",
    "            'distance',\n",
    "            'birth_day',\n",
    "            # 'gap_score',\n",
    "            # 'hs_pctl',\n",
    "            'act_equiv',\n",
    "        ]),\n",
    "        ('pass', 'passthrough', [\n",
    "            'gender',\n",
    "            # 'styp_code',\n",
    "            # 'camp_code',\n",
    "            # 'coll_code',\n",
    "            # 'verified',\n",
    "            # 'term_code',\n",
    "            'appl_day',\n",
    "            'apdc_day',\n",
    "            'hs_qrtl',\n",
    "        ]),\n",
    "        ('false', simpimp(False), [\n",
    "            'camp_main',\n",
    "            'resd',\n",
    "            'legacy',\n",
    "            *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "            'waiver',\n",
    "            # 'fafsa_app',\n",
    "            'schlship_app',\n",
    "            # 'finaid_accepted',\n",
    "            'ssb',\n",
    "            'math',\n",
    "            'reading',\n",
    "            'writing',\n",
    "        ]),\n",
    "        ('0', simpimp(0), [\n",
    "            'gap_score',\n",
    "        ]),\n",
    "        ('n', simpimp('n'), [\n",
    "            'oriented',\n",
    "        ]),\n",
    "    ],\n",
    "    'infer': 202408,\n",
    "    'cycle_day': (TERM(term_code=202408).cycle_date-pd.Timestamp.now()).days+1,\n",
    "    # 'cycle_day': 197,\n",
    "    'term_codes': np.arange(2020,2025)*100+8,\n",
    "    'crse': [\n",
    "        '_total',\n",
    "        # 'engl1301',\n",
    "        # 'biol1406',\n",
    "        # 'biol2401',\n",
    "        # 'math1314',\n",
    "        # 'math2412',\n",
    "        # 'agri1419',\n",
    "        # 'psyc2301',\n",
    "        # 'ansc1319',\n",
    "        # 'comm1311',\n",
    "        # 'hist1301',\n",
    "        # 'govt2306',\n",
    "        # 'math1324',\n",
    "        # 'chem1411',\n",
    "        # 'univ0301',\n",
    "        # 'univ0204',\n",
    "        # 'univ0304',\n",
    "        # 'agri1100',\n",
    "        # 'comm1315',\n",
    "        # 'agec2317',\n",
    "        # 'govt2305',\n",
    "        # 'busi1301',\n",
    "        # 'arts1301',\n",
    "        # 'math1342',\n",
    "        # 'math2413',\n",
    "        ],\n",
    "    'overwrite': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "        # 'flg':True,\n",
    "        # 'raw':True,\n",
    "        # 'term': True,\n",
    "        # 'X': True,\n",
    "        # 'Y': True,\n",
    "        # 'Z': True,\n",
    "        'pred': True,\n",
    "    },\n",
    "    'show': {\n",
    "        # 'reg':True,\n",
    "        # 'adm':True,\n",
    "    },\n",
    "    # 'sch': False,\n",
    "}\n",
    "# FLAGS().run()\n",
    "self = AMP(**kwargs)\n",
    "self = self.preprocess()\n",
    "self.term_codes.remove(self.infer)\n",
    "iterations = 3\n",
    "\n",
    "opts = dict()\n",
    "opts['random_state'] = 42\n",
    "opts['save_all_iterations'] = False\n",
    "opts['datasets'] = 5\n",
    "opts['mean_match_candidates'] = 10\n",
    "opts['mean_match_function'] = mean_match_kdtree_classification\n",
    "\n",
    "# # opts['datasets'] = 2\n",
    "# # opts['mean_match_candidates'] = 1\n",
    "# # opts['mean_match_function'] = default_mean_match\n",
    "\n",
    "# P = self.predict(opts=opts)\n",
    "\n",
    "R = self.train(iterations=iterations, opts=opts,\n",
    "    styp_codes='n',\n",
    "    # train_terms=202208,\n",
    "    )\n",
    "# for k in R[False]['rslt'].keys():\n",
    "#     for b, v in R.items():\n",
    "#         print(k, b)\n",
    "#         v['rslt'][k]['err%'].disp(100)\n",
    "\n",
    "# tune = []\n",
    "# for func in [mean_match_kdtree_classification, default_mean_match]:\n",
    "#     opts['mean_match_function'] = func\n",
    "#     for cand in range(2,41,3):\n",
    "#         opts['mean_match_candidates'] = cand\n",
    "#         print(sort(opts))\n",
    "#         R = self.train(\n",
    "#             styp_codes='n',\n",
    "#             iterations=iterations,\n",
    "#             opts=opts)\n",
    "#         R[False]['rslt']['_total','n']['err%'].disp(100)\n",
    "#         tune.append(R)\n",
    "#         write(self.tune, tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "match x:\n",
    "    case 2:\n",
    "        print(2)\n",
    "    case 10:\n",
    "        print(11)\n",
    "    case None:\n",
    "        print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X['styp_code'].mode()\n",
    "# self.Z['_birth_day']['median']()\n",
    "df = pd.DataFrame()\n",
    "df['a'] = [1,1,2,2]\n",
    "df['b'] = ['a','a','a','a',]\n",
    "df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, col, val=None, grp=None):\n",
    "    val = val if val is not None else 'median' if pd.api.types.is_numeric_dtype(df[col]) else 'mode'\n",
    "    if val in ['median']:\n",
    "        func = lambda x: x.median()\n",
    "    elif val in ['mean','ave','avg','average']:\n",
    "        func = lambda x: x.mean()\n",
    "    elif val in ['mode','most_frequent']:\n",
    "        func = lambda x: x.mode()[0]\n",
    "    else:\n",
    "        func = lambda x: val\n",
    "    df[col] = (df if grp is None else df.groupby(grp))[col].transform(lambda x: x.fillna(func(x)))\n",
    "    return df\n",
    "pd.DataFrame.impute = impute\n",
    "\n",
    "self.Z.reset_index(drop=True)\n",
    "A = self.Z.copy()\n",
    "c = '_birth_day'\n",
    "mask = A[c].isnull()\n",
    "# A.impute('_birth_day', val='median', grp=['term_code','styp_code'])\n",
    "A.impute('_birth_day', val=np.nan, grp=['term_code','styp_code'])\n",
    "A.loc[mask,c].disp(5)\n",
    "# A.groupby(['term_code','styp_code'])['_birth_day'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".102924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = self.pred[0]\n",
    "R = P['rslt']\n",
    "self.Z.dtypes\n",
    "# R['P'].dtypes#.values.astype(float)\n",
    "# model = self.pred[0]['rslt']['model']\n",
    "# model.feature_importance_df()\n",
    "# model.plot_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(self.path / 'predictions.csv', R[False]['summary'])\n",
    "write(self.path / 'predictions.parq', R[False]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.concat([term.raw for term in self.term.values()]).dropna(axis=1, how='all').reset_index(drop=True).prep()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "R['hs_qrtl'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False).combine_first(R['apdc_code'].map(repl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.concat([term.raw for term in self.term.values()]).dropna(axis=1, how='all').reset_index(drop=True).prep()\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "# R['hs_qrtl'] = \n",
    "R['A'] = pd.cut(R['hs_pctl'], bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0], right=False)\n",
    "R['B'] = R['apdc_code'].map(repl)\n",
    "A\n",
    "# R['hs_qrtl'] = R['A'].combine_first(R['B'])\n",
    "# pd.concat([A,B],axis=1)\n",
    "R\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('stvapdc', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "idx = ['pidm','styp_code','apdc_code','apdc_desc']\n",
    "# P = self.X.set_index(idx)[['hs_pctl']]\n",
    "P = where(self.X).filter([*idx, 'hs_pctl'])\n",
    "repl = {\n",
    "    # 'a2':pd.NA,\n",
    "    # 'aa':pd.NA,\n",
    "    # 'ac':pd.NA,\n",
    "    # 'ad':pd.NA,\n",
    "    'ag':pd.NA,\n",
    "    'ai':pd.NA,\n",
    "    'at':pd.NA,\n",
    "    'ae':0,\n",
    "    'n1':1,\n",
    "    'n2':2,\n",
    "    'n3':3,\n",
    "    'n4':4,\n",
    "    'r1':1,\n",
    "    'r2':2,\n",
    "    'r3':3,\n",
    "    'r4':4,\n",
    "}\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "\n",
    "# bins = [100,89.9,74.9,49.9,24.9,0]\n",
    "# bool, default False\n",
    "repl = {'ae':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'r1':1, 'r2':2, 'r3':3, 'r4':4}\n",
    "P['hs_qrtl'] = pd.cut(P['hs_pctl'], right=False, bins=[-1,25,50,75,90,101], labels=[4,3,2,1,0]).combine_first(P['apdc_code'].map(repl))\n",
    "# P.query('hs_qrtl==2')\n",
    "# P.query(\"apdc_code=='n2'\")\n",
    "# P.vc(['apdc_desc','hs_qrtl']).disp(200)\n",
    "# Q = P.query(\"hs_qrtl.isnull()\")\n",
    "# P.groupby(['apdc_code','hs_qrtl']).size()\n",
    "P.groupby(['apdc_code','apdc_desc'])['hs_qrtl'].value_counts(normalize=True, dropna=False).round(2).sort_index().to_frame().disp(200)\n",
    "# Q.vc(['styp_code','apdc_code','apdc_desc']).disp(200)\n",
    "# P['hs_qrtl'].isnull().sum()\n",
    "# P.query(\"hs_qrtl.isnull()\").vc('apdc_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [100,89.9,74.9,49.9,24.9,0]\n",
    "np.arange(4,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P.query(\"apdc_code=='n2' & hs_pctl.notnull()\" ).disp(2000)\n",
    "P.query(\"apdc_code=='n2'\" ).disp(2000)\n",
    "# P.query(\"apdc_code=='n2'\").vc('hs_qrtl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.query(\"apdc_desc=='admitted (nr1)' & hs_qrtl==2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.query('hs_pctl.isnull()').vc('apdc_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    'a2':pd.NA,\n",
    "    'aa':pd.NA,\n",
    "    'ac':pd.NA,\n",
    "    'ad':pd.NA,\n",
    "    'ae':5,\n",
    "    'ag':pd.NA,\n",
    "    'ai':pd.NA,\n",
    "    'at':pd.NA,\n",
    "    'n1':1,\n",
    "    'n2':3,\n",
    "    'n3':4,\n",
    "    'n4':4,\n",
    "    'r1':1,\n",
    "    'r2':2,\n",
    "    'r3':3,\n",
    "    'r4':4,\n",
    "}\n",
    "P['q'] = P['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.vc(['apdc_code','apdc_desc'])\n",
    "# {'n1':1}\n",
    "# set(P.reset_index()['apdc_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.filter(like='_hs_pctl').query('_hs_pctl.isnull()').vc('apdc_desc')\n",
    "# # self.X.groupby('apdc_desc')['hs_pctl'].describe()\n",
    "# P = self.X[['apdc_desc','hs_pctl']]\n",
    "# pd.cut(self.X['hs_pctl'],4)\n",
    "# P = pd.cut(self.X.set_index(['pidm','apdc_desc'])['hs_pctl'], bins=[-1,25,50,75,100], labels=[1,2,3,4])\n",
    "P.vc(['apdc_desc','hs_qrtl']).disp(200)\n",
    "# P.groupby('apdc_desc').describe()\n",
    "# (P==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt'][('_total', 'n')]['proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A['summary'].query(\"pred_term!=202408 & styp_code=='n' & pred_term!=train_term\")#['err%']\n",
    "import seaborn as sns\n",
    "sns.boxplot(M, hue='train_term', y='err%', x='pred_term',\n",
    "    # fill=False,\n",
    "    whis=(0, 100),\n",
    "    dodge = True,\n",
    "    palette='tab10',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.pred[0]['rslt']['Pmodel'].feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R[False]['rslt']['_total','n']['err%']\n",
    "R[False]['rslt']['_total','n'].keys()#['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P['rslt']['model'].feature_importance_df().sort_values('_total_end', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_df(self, dataset, normalize=True, iteration=None):\n",
    "    imputed_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.imputation_order)]\n",
    "    predictor_var_names = [self._get_variable_name(int(i)) for i in np.sort(self.predictor_vars)]\n",
    "    I = pd.DataFrame(self.get_feature_importance(datset, iteration), index=imputed_var_names, columns=predictor_var_names).T\n",
    "    return I / I.sum() if normalize else I\n",
    "ImputationKernel.feature_importance_df = feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_feature_importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = self.pred[0]['rslt']['model']\n",
    "# model.plot_feature_importance??\n",
    "imputed_var_names = [model._get_variable_name(int(i)) for i in np.sort(model.imputation_order)]\n",
    "predictor_var_names = [model._get_variable_name(int(i)) for i in np.sort(model.predictor_vars)]\n",
    "# model.\n",
    "c = '_total_end'\n",
    "I = pd.DataFrame(model.get_feature_importance(0), index=imputed_var_names, columns=predictor_var_names).T\n",
    "I *= 100 / I.sum()\n",
    "I[c].sort_values(ascending=False)\n",
    "# I.T['_total_end']\n",
    "# (0).shape\n",
    "#(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt']['_total','n'].keys()\n",
    "\n",
    "# ['rslt']['_total','n'].keys()\n",
    "# model = R[False]['rslt']['_total','n']\n",
    "#['model']\n",
    "# model.plot_feature_importance?\n",
    "# (dataset=0, annot=True,cmap=\"YlGnBu\",vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((len(f[-1]) for f in self.feat))\n",
    "L = [x for f in self.feat for x in f[-1]]\n",
    "len(L), len(set(L))\n",
    "# {x for f in self.feat for x in f[-1]}\n",
    "# {*self.feat[0][-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = read('/home/scook/institutional_data_analytics/admitted_matriculation_projection/LiveAMP/flags/parq/flg_202308.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.columns\n",
    "F['styp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Z.isnull().sum().sort_index().disp(1000)\n",
    "# self.Z.dtypes\n",
    "# .vc('oriented')\n",
    "# hs_pctlact_equiv\n",
    "mask = self.Z['birth_day'].isnull()\n",
    "self.Z[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"select * from spbpers where spbpers_pidm=1115874\"\n",
    "db.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.select_dtypes('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.isnull().sum().sort_values(ascending=False).to_frame('missing').query('missing>0')\n",
    "# self.Z.vc('writing')\n",
    "# self.Z.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "feat = [\n",
    "    ('scl', make_pipeline(StandardScaler(), PowerTransformer()), [\n",
    "        'distance',\n",
    "        'birth_day',\n",
    "    ]),\n",
    "    # ('nom', FunctionTransformer(lambda x: x.astype('category')), [\n",
    "    ('nom', 'passthrough', [\n",
    "        'gender',\n",
    "        'oriented',\n",
    "        'styp_code',\n",
    "        # 'camp_code',\n",
    "        'coll_code',\n",
    "        # 'verified',\n",
    "    ]),\n",
    "    ('pass', 'passthrough', [\n",
    "        'term_code',\n",
    "        'math',\n",
    "        'reading',\n",
    "        'writing',\n",
    "        'hs_pctl',\n",
    "        'appl_day',\n",
    "        'apdc_day',\n",
    "        'act_equiv',\n",
    "    ]),\n",
    "    ('false', SimpleImputer(strategy='constant', fill_value=False), [\n",
    "        'camp_main',\n",
    "        'resd',\n",
    "        'legacy',\n",
    "        *[f'race_{r}' for r in ['american_indian','asian','black','pacific','white','hispanic']],\n",
    "        'waiver',\n",
    "        # 'fafsa_app',\n",
    "        'schlship_app',\n",
    "        # 'finaid_accepted',\n",
    "        'ssb',\n",
    "    ]),\n",
    "    ('0', SimpleImputer(strategy='constant', fill_value=0), [\n",
    "        'gap_score',\n",
    "    ]),\n",
    "    # ('n', SimpleImputer(strategy='constant', fill_value='n'), [\n",
    "    #     'oriented',\n",
    "    # ]),\n",
    "\n",
    "]\n",
    "\n",
    "# trf = make_pipeline(ColumnTransformer(feat,remainder='drop',verbose_feature_names_out = False), ft)\n",
    "# trf = ColumnTransformer(feat,remainder='drop',verbose_feature_names_out = False)\n",
    "# Z = trf.fit_transform(self.X).binarize()\n",
    "# # Z = Z.apply(f)\n",
    "# # Z.isnull().sum()\n",
    "# Z.dtypes\n",
    "self.X.fillna({c:'' for c in self.X.select_dtypes('string').columns}, inplace=True)\n",
    "self.X.select_dtypes('string').isnull().sum().disp(300)\n",
    "# self.X.select_dtypes('string').fillna('')\n",
    "# self.X.select_dtypes('string').isnull().sum()\n",
    "\n",
    "# .fillna('')\n",
    "# Z\n",
    "# pd.api.types.is_string_dtype(Z['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head('opeir.admissions_fall2022',2).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.Z.waiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.query(\"waiver.isnull()\").vc(['cycle_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.X.isnull().sum().disp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[False]['rslt']['_total','n']['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in R[False]['rslt'].keys():\n",
    "    for b, v in R.items():\n",
    "        print(k, b)\n",
    "        v['rslt'][k]['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {k:v for k,v in R.items() if k[1]!='all'}.keys()\n",
    "R = {True:[], False:[]}\n",
    "for k,v in P.items():\n",
    "    R[k[1]=='all'].append(v)\n",
    "# q[True][0]['rslt'].keys()\n",
    "# for b,L in R.items():\n",
    "    # print(type(v))\n",
    "    # print(v[0]['rslt'].keys())\n",
    "\n",
    "S = {b: {k: pd.concat([Y['rslt'][k] for Y in L]) for k in ['full','summary']} for b,L in R.items()}\n",
    "S[False]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def predict(self, crse='_total', train_term=202208, iterations=3, opts=dict()):\n",
    "    #     for styp_code in [\"n\",\"r\",\"t\",\"all\"]:\n",
    "    #         print(crse,train_term,styp_code, end=\": \")\n",
    "    #         prediction = {'meta': {'crse':crse, 'train_term':train_term, 'styp_code':styp_code, 'iterations':iterations, 'opts':opts.copy()}}\n",
    "    #         for P in self.pred:\n",
    "    #             if P['meta'] == prediction['meta']:\n",
    "    #                 print('reusing')\n",
    "    #                 return P\n",
    "    #         print(f'creating')\n",
    "\n",
    "    #         d = {'_total_cur':1, crse+'_cur':1, crse+'_end':0}\n",
    "    #         end = {c:c[:-4] for c, i in d.items() if i==0}\n",
    "    #         Y = pd.concat([self.Y[i].query(\"crse == @crse\").rename(columns={'credit_hr':c})[c] for c, i in d.items()], axis=1, join='outer')\n",
    "    #         T = self.Z.join(Y, how='left').fillna({c:False for c in d.keys()})\n",
    "    #         if styp_code != \"all\":\n",
    "    #             T = T.query(\"styp_code==@styp_code\")\n",
    "    #         X = T.copy()\n",
    "    #         X.loc[X.eval(\"term_code!=@train_term or term_code==@self.infer\"), end.keys()] = pd.NA\n",
    "    #         imp = ImputationKernel(X, **opts)\n",
    "    #         imp.mice(iterations)\n",
    "    #         # with warnings.catch_warnings(action='ignore'):\n",
    "    #         #     imp.plot_imputed_distributions(wspace=0.2,hspace=0.4)\n",
    "    #         #     imp.plot_mean_convergence()#wspace=0.3, hspace=0.4)\n",
    "    #         #     # imp.plot_correlations()\n",
    "\n",
    "    #         g = lambda df, nm=None: df[end.keys()].rename(columns=end).melt(ignore_index=False, var_name='crse', value_name=nm).set_index('crse', append=True)\n",
    "    #         P = pd.concat([imp.complete_data(k).assign(sim=k).set_index('sim', append=True) for k in range(imp.dataset_count())])\n",
    "    #         Y = g(P,'pred').join(g(T,'true')).assign(train_term=train_term).query('term_code != train_term').prep()\n",
    "    #         grp = ['crse','styp_code','term_code','train_term','sim']\n",
    "    #         agg = lambda x: pd.Series({\n",
    "    #             'pred': x['pred'].sum(min_count=1),\n",
    "    #             'true': x['true'].sum(min_count=1),\n",
    "    #             'mse%': ((1*x['pred'] - x['true'])**2).mean()*100,\n",
    "    #             'f1_inv%': (1-f1_score(x.dropna()['true'], x.dropna()['pred'], zero_division=np.nan))*100,\n",
    "    #         })\n",
    "    #         S = Y.groupby(grp).apply(agg).join(self.mlt).rename_axis(index={'term_code':'pred_term'})\n",
    "    #         for x in ['pred','true']:\n",
    "    #             S[x] = S[x] * S['mlt']\n",
    "    #         S.insert(2, 'err', S['pred'] - S['true'])\n",
    "    #         S.insert(3, 'err%', (S['err'] / S['true']).clip(-1, 1) * 100)\n",
    "    #         prediction['rslt'] = {'full':Y, 'summary': S.drop(columns='mlt').prep()}\n",
    "    #         self.pred.append(prediction)\n",
    "    #         self.dump()\n",
    "    #     return prediction\n",
    "\n",
    "# class MM():\n",
    "#     def __init__(self, func, candidates):\n",
    "#         assert func in [mean_match_kdtree_classification, default_mean_match]\n",
    "#         self.func = func\n",
    "#         self.candidates = candidates\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return self.func(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return join([x for x in ['kdtree','default'] if x in self.func.__name__]+[self.candidates], \"_\")\n",
    "\n",
    "# class kdtree():\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return mean_match_kdtree_classification(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return 'kdtree__mean_match'\n",
    "\n",
    "# class default():\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return default_mean_match(*args, **kwargs)\n",
    "#     def __str__(self):\n",
    "#         return 'default_mean_match'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = it.product(self.crse, ['n','r','t','all'])\n",
    "[[crse, styp_code, train_term] for crse, styp_code in Z for train_term in self.term_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = it.product(self.crse, ['n','r','t','all'])\n",
    "list(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    ('a','b'):7,\n",
    "    ('a','c'):71}\n",
    "d['a','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"\"\"\n",
    "select\n",
    "        A.sfrstcr_term_code,\n",
    "        A.sfrstcr_pidm,\n",
    "        B.ssbsect_subj_code,\n",
    "        B.ssbsect_crse_numb,\n",
    "        B.ssbsect_credit_hrs,\n",
    "        A.sfrstcr_credit_hr\n",
    "from sfrstcr A, ssbsect B\n",
    "where\n",
    "        A.sfrstcr_term_code = B.ssbsect_term_code\n",
    "        and A.sfrstcr_crn = B.ssbsect_crn\n",
    "        and A.sfrstcr_term_code = 202308\n",
    "        and A.sfrstcr_ptrm_code not in ('28','R3')\n",
    "        and  trunc(to_date('18-Sep-23')) - trunc(A.sfrstcr_add_date) >= 197  -- added before cycle_day\n",
    "        and (trunc(to_date('18-Sep-23')) - trunc(A.sfrstcr_rsts_date) < 197 or A.sfrstcr_rsts_code in ('DC','DL','RD','RE','RW','WD','WF')) -- dropped after cycle_day or still enrolled\n",
    "        and B.ssbsect_subj_code <> 'INST'\n",
    "        and A.sfrstcr_credit_hr <> B.ssbsect_credit_hrs\n",
    "\"\"\"\n",
    "db.head(qry, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f\"styp_code=='n' & pred_term!={self.infer}\"\n",
    "val = \"err%\"\n",
    "q=50\n",
    "P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q))\n",
    "for _ in range(2):\n",
    "    P = (P.assign(mean=lambda x:x.mean(axis=1)) if P.shape[1] > 1 else P).T\n",
    "P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdtree = mean_match_kdtree_classification\n",
    "kdtree.__name__ = 'a'\n",
    "setattr(kdtree,'__str__','a')\n",
    "setattr(kdtree,'__repr__','a')\n",
    "\n",
    "print(kdtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiveAMP import *\n",
    "from miceforest.mean_matching_functions import default_mean_match, mean_match_kdtree_classification\n",
    "class MM():\n",
    "    def __init__(self, func, candidates):\n",
    "        self.func = func\n",
    "        self.candidates = candidates\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    def __str__(self):\n",
    "        return join([x for x in ['kdtree','deafult'] if x in self.func.__name__]+[self.candidates], \"_\")\n",
    "\n",
    "mm = MM(mean_match_kdtree_classification, 3)\n",
    "print(mm)\n",
    "# type(mean_match_kdtree_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_match_kdtree_classification.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = default_mean_match\n",
    "x.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # A[styp_code] = {\n",
    "            #     'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "            #     **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "\n",
    "\n",
    "\n",
    "    # R = {styp_code: {\n",
    "    #         'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "    #         **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "    #     } for styp_code in [\"n\"]}\n",
    "\n",
    "        # R['n']['proj'].disp(100)\n",
    "        # R['n']['err%'].disp(100)\n",
    "# B = (\n",
    "#     A['summary']\n",
    "#     .grpby(['crse','styp_code','train_term','pred_term'])\n",
    "#     # .grpby(['crse','styp_code','pred_term'])\n",
    "#     [['pred','err%','mse%','f1_inv%']]\n",
    "#     .agg(summary)\n",
    "#     .stack(0, sort=False)\n",
    "#     .rename_axis(index={None:'kind'})\n",
    "#     .query(f\"(pred_term == {self.infer} and kind == 'pred') or (pred_term != {self.infer} and kind == 'err%')\")\n",
    "#     .reset_index()\n",
    "#     # .sort_values(['crse','styp_code','pred_term','train_term'],ascending=[True,True,False,False])\n",
    "#     .prep()\n",
    "# )\n",
    "# M = A['summary'].query(\"pred_term != @self.infer & styp_code=='n'\").pivot_table(index='train_term', columns='pred_term', values='err%', margins=True)\n",
    "# M.disp(10)\n",
    "# B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R['n']['err%'].disp(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {k: pd.concat([p['rslt'][k] for p in P]) for k in ['full','summary']}\n",
    "def pivot(qry, val, q=50):\n",
    "    P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q), margins=True, margins_name='mean')\n",
    "    for _ in range(2):\n",
    "        P = (P.head(1) if P.shape[0] == 2 else P).T\n",
    "    return P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n",
    "\n",
    "R = {styp_code: {\n",
    "    'proj': pd.concat([pivot(f\"styp_code=='{styp_code}' & pred_term=={self.infer}\", \"pred\", q) for q in [25,50,75]], axis=1),\n",
    "    **{stat: pivot(f\"styp_code=='{styp_code}' & pred_term!={self.infer}\", stat) for stat in [\"err\",\"err%\",\"mse%\",\"f1_inv%\"]}\n",
    "} for styp_code in [\"n\"]}\n",
    "\n",
    "R['n']['proj'].disp(100)\n",
    "R['n']['err%'].disp(100)\n",
    "# }}\n",
    "# projections = pd.concat([piv(\"pred_term == @self.infer & styp_code=='n'\", 'pred', q) for q in [25,50,75]], axis=1)\n",
    "# errors = piv(\"pred_term != @self.infer & styp_code=='n'\", 'err%', 50)\n",
    "# Q\n",
    "# M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(p):\n",
    "    f = lambda x: x.quantile(p/100)\n",
    "    f.__name__ = f'{p}%'\n",
    "    f.__str__ = f'{p}%'\n",
    "    f.__repr__ = f'{p}%'\n",
    "    return f\n",
    "print(f\"{g(25)}\")\n",
    "display(f)\n",
    "str(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pctl(50)\n",
    "f.__repr__ = 'a'\n",
    "f.__str__ = 'a'\n",
    "f'{f}'\n",
    "# print(f)\n",
    "# f.__qualname__\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pctl(50)\n",
    "hasattr(w, '__name__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'hi'\n",
    "# x.__name__ = x\n",
    "hasattr(x, '__name__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piv(qry, val, q=50):\n",
    "    P = A['summary'].reset_index().query(qry).pivot_table(columns='train_term', index='pred_term', values=val, aggfunc=pctl(q), margins=True, margins_name='mean')\n",
    "    for _ in range(2):\n",
    "        P = (P.head(1) if P.shape[0] == 2 else P).T\n",
    "    return P.assign(**{val:f\"{q}%\"}).set_index(val, append=True).swaplevel(0,1).round(0).prep().T\n",
    "A = {k: pd.concat([p['rslt'][k] for p in P]) for k in ['full','summary']}\n",
    "Q = pd.concat([piv(\"pred_term == @self.infer & styp_code=='n'\", 'pred', q) for q in [25,50,75]], axis=1)\n",
    "M = piv(\"pred_term != @self.infer & styp_code=='n'\", 'err%', 50)\n",
    "Q\n",
    "M\n",
    "# q = Q[0]\n",
    "# q\n",
    "# Q[0]\n",
    "# piv(\"styp_code=='n'\", 'err%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.T.assign(a=50).set_index('a', append=True).swaplevel(0,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Q[0]\n",
    "A.rename('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = (\n",
    "    A['summary']\n",
    "    .grpby(['crse','styp_code','train_term','pred_term'])\n",
    "    [['pred','err%','mse%','f1_inv%']]\n",
    "    .agg(summary)\n",
    "    .stack(0, sort=False)\n",
    "    .rename_axis(index={None:'kind'})\n",
    "    .query(f\"(pred_term == {self.infer} and kind == 'pred') or (pred_term != {self.infer} and kind == 'err%')\")\n",
    "    .reset_index()\n",
    "    # .sort_values(['crse','styp_code','pred_term','train_term'],ascending=[True,True,False,False])\n",
    "    .prep()\n",
    ")\n",
    "\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = A['summary'].query(\"pred_term!=202408 & styp_code=='n'\")['err%'].groupby(['train_term','pred_term']).mean().reset_index()#.unstack()\n",
    "# M.pivot_table(index='train_term',columns='pred_term', margins=True)\n",
    "\n",
    "# M\n",
    "A['summary'].reset_index().query(\"pred_term!=202408 & styp_code=='n'\").pivot_table(index='train_term', columns='pred_term', values='err%', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.disp(10)\n",
    "B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = self.Z.vc('term_code')\n",
    "v = t.values\n",
    "pd.DataFrame((v / v.T - 1) * 100, index=t.index, columns=t.index).round().prep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sort_values(['train_term','pred_term'], ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.disp(10)\n",
    "B.disp(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A['summary'].query(\"pred_term!=202408 & styp_code=='n' & pred_term!=train_term\")['err%'].groupby(['train_term','pred_term']).mean().unstack()\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['summary'].disp(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = lambda x: x.query(\"levl_code == 'ug' and styp_code in ('n','r','t')\").copy()\n",
    "\n",
    "with warnings.catch_warnings(action='ignore'):\n",
    "    self.Y = [pd.concat([term.reg[k] for term in self.term.values()]).assign(credit_hr=lambda x:x['credit_hr'].fillna(0)>0) for k in [0,1]]\n",
    "    # self.Z = trf.fit_transform(where(self.X).set_index(self.attr, drop=False))\n",
    "# agg = lambda y, g: y.groupby(g)[['credit_hr']].sum()\n",
    "# grp = ['styp_code','term_code','crse']\n",
    "# end = agg(where(self.Y[0]), grp)\n",
    "# self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "# cur = agg(self.Y[0], grp)\n",
    "# M = (end / cur).query(\"term_code != @self.infer\")\n",
    "# N = M.reset_index().assign(term_code=self.infer).set_index(M.index.names)\n",
    "# self.mlt = pd.concat([M, N], axis=0).replace(np.inf, pd.NA).squeeze().rename('mlt').prep()\n",
    "# return self.dump()\n",
    "\n",
    "agg = lambda y, g: where(y).groupby(g)[['credit_hr']].sum()\n",
    "grp = ['levl_code','styp_code','term_code','crse']\n",
    "end = agg(self.Y[0], grp)\n",
    "self.Y = [self.Z[[]].join(y.set_index(['pidm','term_code'])[['crse','credit_hr']], how='inner') for y in self.Y]\n",
    "cur = agg(self.Y[0], grp)\n",
    "M = (end / cur).query(\"term_code != @self.infer\")\n",
    "M\n",
    "# agg(self.Y[0], grp).disp(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my3.12",
   "language": "python",
   "name": "my3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
